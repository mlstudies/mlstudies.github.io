

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Methods in Machine Learning &mdash; rst_test 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/coloring.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/eqposfix.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> rst_test
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="3_ml_methods/00_basics/00_index.html">1. Preliminaries</a></div></div></li></ul>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">rst_test</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</div></div></div></div></div></div></div></li><li>Methods in Machine Learning</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/_raw_translation.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>

          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="methods-in-machine-learning">
<h1>Methods in Machine Learning<a class="headerlink" href="#methods-in-machine-learning" title="Permalink to this headline">¶</a></h1>
<table border="1" class="docutils">
<colgroup>
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><strong>Conce
pt</strong></th>
<th class="head"><strong>Refer
ence</strong></th>
<th class="head">Cite</th>
<th class="head"><p class="first"><a href="#id1"><span class="problematic" id="id2">**</span></a>Earli
er
Concept
**</p>
<p class="last"><a href="#id3"><span class="problematic" id="id4">**</span></a>Exter
nal
Concept
**</p>
</th>
<th class="head"><a href="#id5"><span class="problematic" id="id6">**</span></a>Title
**</th>
<th class="head"><em>Hint</em></th>
<th class="head"><p class="first">Assumpt
ion</p>
<p class="last">Attenti
on</p>
</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Theorem</td>
<td>Lemma/P
roperty</td>
<td>Fact</td>
<td>Empiric
al
Fact</td>
<td><p class="first">Advanta
ge</p>
<p class="last">Limitat
ion</p>
</td>
<td>Connect
ion</td>
<td>Connect
ion</td>
</tr>
</tbody>
</table>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>RV:</td>
<td>random variable</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">bf{x}</p>
</td>
<td>single data
entry as column
vector</td>
<td><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">bf{X}</p>
</td>
<td>data matrix
with each
column as one
data entry</td>
</tr>
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">bf{w}</p>
</td>
<td>weights</td>
<td><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">bf{W}</p>
</td>
<td>weight matrix
with each
column as one
set of weights</td>
</tr>
<tr class="row-even"><td><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">bf{w}^{mathbf{
<a href="#id7"><span class="problematic" id="id8">*</span></a>}}</p>
</td>
<td>optimal
solution is
marked by
<span class="math notranslate nohighlight">\(*\)</span></td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<div class="section" id="basic-models">
<h2><strong>Basic Models</strong><a class="headerlink" href="#basic-models" title="Permalink to this headline">¶</a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>&#160;</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>Binary Logistic</td>
<td>sigmoid, i.i.d.
Bernoulli</td>
<td>closed form, gradient
ascent, Newton</td>
</tr>
</tbody>
</table>
<div class="section" id="preliminaries">
<h3>Preliminaries<a class="headerlink" href="#preliminaries" title="Permalink to this headline">¶</a></h3>
<div class="section" id="covariance-matrix">
<h4><strong>Covariance Matrix</strong><a class="headerlink" href="#covariance-matrix" title="Permalink to this headline">¶</a></h4>
<p>Given two RVs <span class="math notranslate nohighlight">\(X,Y\)</span>, then the covariance
<span class="math notranslate nohighlight">\(\operatorname{cov}\left( X,Y \right)\mathbb{= E\lbrack}\left( X - \mathbb{E}X \right)\left( Y - \mathbb{E}Y \right)\rbrack\)</span>.
Given a RV vector :math:<a href="#id9"><span class="problematic" id="id10">`</span></a>X = begin{pmatrix}
X_{1} \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>X_{M} \
end{pmatrix}`, define :math:<a href="#id11"><span class="problematic" id="id12">`</span></a>mathbb{E}X = begin{pmatrix}
mathbb{E}X_{1} \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>mathbb{E}X_{M} \
end{pmatrix}` (and similarly the expectation of a RV matrix is to take
expectation on each entry of that matrix), then the <strong>covariance
matrix</strong> is defined as the following,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\operatorname{\sigma}\left( X \right) = \begin{pmatrix}
\operatorname{cov}{(X_{1},X_{1})} &amp; \cdots &amp; \operatorname{cov}{(X_{1},X_{M})} \\
 \vdots &amp; \ddots &amp; \vdots \\
\operatorname{cov}{(X_{M},X_{1})} &amp; \cdots &amp; \operatorname{cov}{(X_{M},X_{M})} \\
\end{pmatrix} = \begin{pmatrix}
\operatorname{E}{\lbrack\left( X_{1}\mathbb{- E}X_{1} \right)\left( X_{1}\mathbb{- E}X_{1} \right)\rbrack} &amp; \cdots &amp; \operatorname{E}{\lbrack\left( X_{1}\mathbb{- E}X_{1} \right)\left( X_{M}\mathbb{- E}X_{M} \right)\rbrack} \\
 \vdots &amp; \ddots &amp; \vdots \\
\operatorname{E}{\lbrack\left( X_{M}\mathbb{- E}X_{M} \right)\left( X_{1}\mathbb{- E}X_{1} \right)\rbrack} &amp; \cdots &amp; \operatorname{E}{\lbrack\left( X_{M}\mathbb{- E}X_{M} \right)\left( X_{M}\mathbb{- E}X_{M} \right)\rbrack} \\
\end{pmatrix} = \operatorname{E}{\lbrack{\left( X - \mathbb{E}X \right)\left( X - \mathbb{E}X \right)}^{T}\rbrack}\end{split}\]</div>
<p>where the diagonal elements are variances. We <em>note</em> there is difference
that <span class="math notranslate nohighlight">\(\operatorname{cov}\left( X,Y \right)\)</span> is a value, but
<span class="math notranslate nohighlight">\(\operatorname{\sigma}\left( X,Y \right)\)</span> is a <span class="math notranslate nohighlight">\(2 \times 2\)</span>
matrix.</p>
<p>On the other hand, given two RVs <span class="math notranslate nohighlight">\(X,Y\)</span> and draw samples
<span class="math notranslate nohighlight">\(\mathbf{x =}\left( x_{1}\mathbf{,\ldots,}x_{N} \right)\sim X,\mathbf{y =}\left( y_{1},\ldots,y_{N} \right)\sim Y\)</span>,
then we define the <strong>sample</strong> <strong>covariance</strong> of them as
<span class="math notranslate nohighlight">\(\operatorname{cov}\left( \mathbf{x,y} \right) = \frac{1}{N - 1}\left( \mathbf{x} - \overline{\mathbf{x}} \right)^{T}\left( \mathbf{y} - \overline{\mathbf{y}} \right)\)</span>.
Given a RV vector :math:<a href="#id13"><span class="problematic" id="id14">`</span></a>X = begin{pmatrix}
X_{1} \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>X_{M} \
end{pmatrix}`, we can draw <strong>samples</strong>
<span class="math notranslate nohighlight">\(\mathbf{x}_{1}^{T} = \left( x_{1,1},\ldots,x_{1,N} \right)\sim X_{1},\ldots,\mathbf{x}_{M}^{T} = \left( x_{M,1},\ldots,x_{M,M} \right)\sim X_{M}\)</span>,
and form a <strong>sample matrix</strong> :math:<a href="#id15"><span class="problematic" id="id16">`</span></a>mathbf{X} = begin{pmatrix}
mathbf{x}_{1}^{T} \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>mathbf{x}_{M}^{T} \
end{pmatrix}`. In the machine learning context, the rows of
<span class="math notranslate nohighlight">\(\mathbf{X}\)</span> are also referred to as <strong>feature vectors</strong>, and the
columns of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> are called <strong>data entries</strong>. Then the
<strong>sample covariance matrix</strong> is defined w.r.t. the feature vectors as</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\Sigma\left( \math\]</div>
<p>bf{X} right) = frac
{1}{N - 1}begin{pmat
rix}</p>
<blockquote>
<div>operatorname{cov}</div></blockquote>
<p>{(mathbf{x}_{1},mat
hbf{x}_{1})} &amp; cdots</p>
<blockquote>
<div>&amp; operatorname{cov}</div></blockquote>
<p>{(mathbf{x}_{1},mat
hbf{x}_{M})} \</p>
<blockquote>
<div><blockquote>
<div>vdots &amp; ddots &amp;</div></blockquote>
<dl class="docutils">
<dt>vdots \</dt>
<dd>operatorname{cov}</dd>
</dl>
</div></blockquote>
<p>{(mathbf{x}_{M},mat
hbf{x}_{1})} &amp; cdots</p>
<blockquote>
<div>&amp; operatorname{cov}</div></blockquote>
<p>{(mathbf{x}_{M},mat
hbf{x}_{M})} \</p>
<blockquote>
<div>end{pmatrix} = f</div></blockquote>
<p>rac{1}{N - 1}begin{p
matrix}</p>
<blockquote>
<div>left( mathbf{x}_</div></blockquote>
<p>{1} - overline{math
bf{x}_{1}} right)^{T
}left( mathbf{x}_{1
} - overline{mathbf
{x}_{1}} right) &amp; c
dots &amp; left( mathbf
{x}_{1} - overline{mathbf{x}_{1}} right
)^{T}left( mathbf{x
}_{M} - overline{ma
thbf{x}_{M}} right)
\</p>
<blockquote>
<div><blockquote>
<div>vdots &amp; ddots &amp;</div></blockquote>
<dl class="docutils">
<dt>vdots \</dt>
<dd>left( mathbf{x}_</dd>
</dl>
</div></blockquote>
<p>{M} - overline{math
bf{x}_{M}} right)^{T
}left( mathbf{x}_{1
} - overline{mathbf
{x}_{1}} right) &amp; c
dots &amp; left( mathbf
{x}_{M} - overline{mathbf{x}_{M}} right
)^{T}left( mathbf{x
}_{M} - overline{ma
thbf{x}_{M}} right)
\</p>
<blockquote>
<div>end{pmatrix} = f</div></blockquote>
<p class="last">rac{1}{N - 1}left( mathbf{X} - overline
{mathbf{X}} right)left( mathbf{X} - o
verline{mathbf{X}} right)^{T}</p>
</td>
<td>&#160;</td>
<td>(1‑1)</td>
</tr>
</tbody>
</table>
<p>where
<span class="math notranslate nohighlight">\({\overline{\mathbf{x}_{i}}}^{T} = \frac{1}{N}\sum_{j = 1}^{N}x_{i,j}\mathbf{1}^{T} = \left( \frac{1}{N}\sum_{j = 1}^{N}x_{i,j},\ldots,\frac{1}{N}\sum_{j = 1}^{N}x_{i,j} \right)\)</span>
(the same mean value repeats itself for <span class="math notranslate nohighlight">\(N\)</span> times) and
:math:<a href="#id17"><span class="problematic" id="id18">`</span></a>overline{mathbf{X}} = begin{pmatrix}
overline{mathbf{x}_{1}} \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>overline{mathbf{x}_{M}} \
end{pmatrix}`, and the diagonal elements are <strong>sample variances</strong>. The
sum of variances, or the trace of the covariance matrix, is called the
<strong>total variance</strong> of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>. In addition, <em>note</em>
<span class="math notranslate nohighlight">\(\operatorname{cov}\left( \mathbf{x,y} \right)\)</span> is a value, while
<span class="math notranslate nohighlight">\(\Sigma(\mathbf{x,y})\)</span> is a <span class="math notranslate nohighlight">\(2 \times 2\)</span> matrix.</p>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><p class="first">In machine learning problems, we are often given a data matrix
<span class="math notranslate nohighlight">\(\mathbf{X} = \left( \mathbf{x}_{1},\ldots,\mathbf{x}_{N} \righ
t)\)</span>
with the columns <span class="math notranslate nohighlight">\(\mathbf{x}_{1},\ldots,\mathbf{x}_{N}\)</span> as
<strong>data entries</strong>. The symbol “<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>” very often
represents a data entry in machine learning, but in statistics it
often instead represents a feature vector. This difference sometimes
causes confusion. Therefore, we <em>note</em> it is necessary to understand
what “<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>” represents from the context.</p>
<p class="last">The other possible confusion is about the “samples”. It is possible
both the data entries and feature vectors are referred to as samples
in different contexts. We again <em>note</em> sample covariance is w.r.t.
the features, not data entries. Therefore, the “samples” in the
context (<em>1</em>‑<em>1</em>) refers to feature vectors.</p>
</td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><strong>Property</strong> <strong>1‑1</strong> Using the fact that
<span class="math notranslate nohighlight">\(\sigma\left( X,Y \right)\mathbb{= E}XY - \mathbb{E}X\mathbb{E}Y\)</span>,
the covariance matrix has another form</li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\operatorname{\sigma}\left( X \right) = \begin{pmatrix}
\operatorname{E}X_{1}^{2} - \mathbb{E}^{2}X_{1} &amp; \cdots &amp; \operatorname{E}{X_{1}X_{M}}\mathbb{- E}X_{1}\mathbb{E}X_{M} \\
 \vdots &amp; \ddots &amp; \vdots \\
\operatorname{E}{X_{M}X_{1}}\mathbb{- E}X_{M}\mathbb{E}X_{1} &amp; \cdots &amp; \operatorname{E}X_{M}^{2} - \mathbb{E}^{2}X_{M} \\
\end{pmatrix} = \mathbf{E}\mathrm{\lbrack}XX^{\mathrm{T}}\mathrm{\rbrack} - \mathbf{E}X\mathbf{E}^{T}X\end{split}\]</div>
<p>For two samples <span class="math notranslate nohighlight">\(\mathbf{x}\sim X,\mathbf{y}\sim Y\)</span> where
<span class="math notranslate nohighlight">\(\mathbf{x =}\left( x_{1}\mathbf{,\ldots,}x_{N} \right)\mathbf{,}\mathbf{y = (}y_{1}\mathbf{,\ldots,}y_{N}\mathbf{)}\)</span>,
we have</p>
<div class="math notranslate nohighlight">
\[\left( \mathbf{x} - \overline{\mathbf{x}} \right)^{T}\left( \mathbf{y} - \overline{\mathbf{y}} \right) = \mathbf{x}^{T}\mathbf{y} - \mathbf{x}^{T}\overline{\mathbf{y}} - {\overline{\mathbf{x}}}^{T}\mathbf{y} + {\overline{\mathbf{x}}}^{T}\overline{\mathbf{y}}\]</div>
<p>Let
<span class="math notranslate nohighlight">\(\overline{x} = \frac{\sum_{i = 1}^{N}{\mathbf{x(}i\mathbf{)}}}{N}\)</span>
and
<span class="math notranslate nohighlight">\(\overline{y} = \frac{\sum_{i = 1}^{N}{\mathbf{y(}i\mathbf{)}}}{N}\)</span>,
then</p>
<div class="math notranslate nohighlight">
\[{\mathbf{x}^{T}\overline{\mathbf{y}} = \sum_{i = 1}^{N}{\overline{y}\mathbf{x(}i\mathbf{)}} = \overline{y}\sum_{i = 1}^{N}{\mathbf{x(}i\mathbf{)}} = N\overline{x}\overline{y}
}{{\overline{\mathbf{x}}}^{T}\mathbf{y} = \sum_{i = 1}^{N}{\overline{x}\mathbf{y(}i\mathbf{)}} = \overline{x}\sum_{i = 1}^{N}{\mathbf{y(}i\mathbf{)}} = N\overline{x}\overline{y}
}{{\overline{\mathbf{x}}}^{T}\overline{\mathbf{y}} = \sum_{i = 1}^{N}{\overline{x}\overline{y}} = N\overline{x}\overline{y}}\]</div>
<p>Thus</p>
<div class="math notranslate nohighlight">
\[\left( \mathbf{x} - \overline{\mathbf{x}} \right)^{T}\left( \mathbf{y} - \overline{\mathbf{y}} \right) = \mathbf{x}^{T}\mathbf{x +}N\overline{x}\overline{y} - 2N\overline{x}\overline{y} = \mathbf{x}^{T}\mathbf{x -}N\overline{x}\overline{y} = \mathbf{x}^{T}\mathbf{y -}{\overline{\mathbf{x}}}^{T}\overline{\mathbf{y}}\]</div>
<p>which implies</p>
<div class="math notranslate nohighlight">
\[\begin{split}\Sigma(\mathbf{X}) = \frac{1}{m - 1}\begin{pmatrix}
\mathbf{x}_{1}^{T}\mathbf{x}_{1}\mathbf{-}{\overline{\mathbf{x}_{1}}}^{T}\overline{\mathbf{x}_{1}} &amp; \cdots &amp; \mathbf{x}_{1}^{T}\mathbf{x}_{M}\mathbf{-}{\overline{\mathbf{x}_{1}}}^{T}\overline{\mathbf{x}_{M}} \\
 \vdots &amp; \ddots &amp; \vdots \\
\mathbf{x}_{M}^{T}\mathbf{x}_{1}\mathbf{-}{\overline{\mathbf{x}_{M}}}^{T}\overline{\mathbf{x}_{1}} &amp; \cdots &amp; \mathbf{x}_{M}^{T}\mathbf{x}_{M}\mathbf{-}{\overline{\mathbf{x}_{M}}}^{T}\overline{\mathbf{x}_{M}} \\
\end{pmatrix} = \frac{1}{N - 1}\left( \mathbf{X}\mathbf{X}^{T}\mathbf{-}\overline{\mathbf{X}}{\overline{\mathbf{X}}}^{T} \right)\end{split}\]</div>
<ul class="simple">
<li><strong>Property</strong> <strong>1‑2</strong>
<span class="math notranslate nohighlight">\(\sigma\left( X - \mathbb{E}X \right) = \sigma(X)\)</span>, since
<span class="math notranslate nohighlight">\(\mathbb{E}\left\lbrack X - \mathbb{E}X \right\rbrack = \mathbf{0}\)</span>
and</li>
</ul>
<div class="math notranslate nohighlight">
\[\sigma\left( X - \mathbb{E}X \right) = \operatorname{E}{\lbrack{\left( X - \mathbb{E}X - \mathbb{E}\left\lbrack X - \mathbb{E}X \right\rbrack \right)\left( X - \mathbb{E}X - \mathbb{E}\left\lbrack X - \mathbb{E}X \right\rbrack \right)}^{T}\rbrack} = \operatorname{E}{\lbrack{\left( X - \mathbb{E}X \right)\left( X - \mathbb{E}X \right)}^{T}\rbrack} = \sigma(X)\]</div>
<p>Also
<span class="math notranslate nohighlight">\(\Sigma\left( \mathbf{X} - \overline{\mathbf{X}} \right) = \Sigma\left( \mathbf{X} \right)\)</span>,
because
<span class="math notranslate nohighlight">\(\mathbf{x} - \overline{\mathbf{x}} - \overline{\mathbf{x} - \overline{\mathbf{x}}} = \mathbf{x} - \overline{\mathbf{x}}\)</span>
for any sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, and the result following by applying
this on (<em>1</em>‑<em>1</em>).</p>
<ul class="simple">
<li><strong>Theorem</strong> <strong>1‑1</strong> Given
<span class="math notranslate nohighlight">\(X = \left( X_{1},\ldots,X_{n} \right)^{T}\)</span>,
<span class="math notranslate nohighlight">\(\sigma\left( \mathbf{\alpha}^{T}X \right) = \sigma\left( X^{T}\mathbf{\alpha} \right) = \mathbf{\alpha}^{T}\operatorname{\sigma}\left( X \right)\mathbf{\alpha}\)</span>.
Note</li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left( \mathbf{\alpha}^{T}X \right)\mathbb{= E}\left( X^{T}\mathbf{\alpha} \right) = \mathbf{\alpha}^{T}\mathbb{E}X = \left( \mathbb{E}^{T}X \right)\mathbf{\alpha}\]</div>
<p>Also <span class="math notranslate nohighlight">\(\mathbf{\alpha}^{\mathrm{T}}X\)</span> is a scalar RV, and so
<span class="math notranslate nohighlight">\(\left( \mathbf{\alpha}^{\mathrm{T}}X \right)^{2}\mathbf{=}{\left( \mathbf{\alpha}^{\mathrm{T}}X \right)\left( \mathbf{\alpha}^{\mathrm{T}}X \right)}^{T} = \mathbf{\alpha}^{\mathrm{T}}XX^{\mathrm{T}}\mathbf{\alpha}\)</span>.
Recall
<span class="math notranslate nohighlight">\(\sigma\left( X \right)\mathbb{= E}X^{2} - \mathbb{E}^{2}X\)</span>, then</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\sigma\left( \mathbf{\alpha}^{\mathrm{T}}X \right) = \mathbf{E}\mathrm{\lbrack}\mathbf{\alpha}^{\mathrm{T}}X\left( \mathbf{\alpha}^{\mathrm{T}}X \right)^{\mathrm{T}}\mathrm{\rbrack} - \mathbf{E}\left\lbrack \mathbf{\alpha}^{\mathrm{T}}X \right\rbrack\mathbf{E}^{T}\left\lbrack \mathbf{\alpha}^{\mathrm{T}}X \right\rbrack = \mathbf{\alpha}^{\mathrm{T}}\mathbf{E}\mathrm{\lbrack}XX^{\mathrm{T}}\mathrm{\rbrack}\mathbf{\alpha} - \mathbf{\alpha}^{\mathrm{T}}\mathbf{E}X\mathbf{E}^{T}X\mathbf{\alpha}\mathbf{=}\mathbf{\alpha}^{\mathrm{T}}\mathbf{(}\mathbf{E}\mathrm{\lbrack}XX^{\mathrm{T}}\mathrm{\rbrack} - \mathbf{E}X\mathbf{E}^{T}X\mathrm{)}\mathbf{\alpha}\mathbf{=}\mathbf{\alpha}^{T}\operatorname{\sigma}\left( X \right)\mathbf{\alpha}\\Similarly, using
:math:`\sigma\left( X,Y \right)\mathbb{= E}XY - \mathbb{E}X\mathbb{E}Y`,
we can have
:math:`\sigma\left( \mathbf{\alpha}^{\mathrm{T}}X,\mathbf{\beta}^{T}Y \right) = \mathbf{\alpha}^{T}\operatorname{\sigma}\left( X \right)\mathbf{\beta}`.
Further, if we let
:math:`\mathbf{A}\mathbf{= (}\mathbf{a}_{1}\mathbf{,\ldots,}\mathbf{a}_{n}\mathbf{)}`,
then
:math:`\sigma\left( \mathbf{A}^{T}X \right) = \mathbf{A}^{T}\operatorname{\sigma}\left( X \right)\mathbf{A}`,
since
:math:`\sigma\left( \mathbf{\alpha}_{i}X\mathbf{,}\mathbf{\alpha}_{j}X \right) = \mathbf{\alpha}_{i}^{T}\operatorname{\sigma}\left( X \right)\mathbf{\alpha}_{j}`.\\On the other hand, given
:math:`\mathbf{X = (}\mathbf{x}_{1},\ldots,\mathbf{x}_{n}\mathbf{)}`,
we have that
:math:`\mathcal{S}\left( \mathbf{\text{Xα}} \right) = \mathbf{\alpha}^{T}\operatorname{S}\left( \mathbf{X} \right)\mathbf{\alpha}`.
First check\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\left\{ \begin{matrix}
\overline{\mathbf{\text{Xα}}} = \overline{\sum_{i = 1}^{n}{\mathbf{\alpha}\left( i \right)\mathbf{x}_{i}}} = \frac{1}{m}\sum_{j = 1}^{m}{\sum_{i = 1}^{n}{\mathbf{\alpha}\left( i \right)\mathbf{x}_{i}(j)}} \\
\overline{\mathbf{X}}\mathbf{\alpha}\mathbf{=}\sum_{i = 1}^{n}{\mathbf{\alpha}\left( i \right)\overline{\mathbf{x}_{i}}} = \sum_{i = 1}^{n}\left( \mathbf{\alpha}\left( i \right) \times \frac{1}{m}\sum_{j = 1}^{m}{\mathbf{x}_{i}\left( j \right)} \right) = \frac{1}{m}\sum_{i = 1}^{n}\left( \sum_{j = 1}^{m}{\mathbf{\alpha}\left( i \right)\mathbf{x}_{i}\left( j \right)} \right) \\
\end{matrix} \Rightarrow \overline{\mathbf{\text{Xα}}} = \overline{\mathbf{X}}\mathbf{\alpha} \right.\\end{split}\\Then we have\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\mathcal{S}\left( \mathbf{\text{Xα}} \right) = \frac{1}{n + 1}\left( \left( \mathbf{\text{Xα}} \right)^{T}\left( \mathbf{\text{Xα}} \right)\mathbf{-}{\overline{\mathbf{\text{Xα}}}}^{T}\overline{\mathbf{\text{Xα}}} \right) = \frac{1}{n + 1}\left( \mathbf{\alpha}^{T}\mathbf{X}^{T}\mathbf{X\alpha -}\mathbf{\alpha}^{T}{\overline{\mathbf{X}}}^{T}\overline{\mathbf{X}}\mathbf{\alpha} \right) = \mathbf{\alpha}^{T}\operatorname{S}\left( \mathbf{X} \right)\mathbf{\alpha}\]</div>
<p>By similar computations,
<span class="math notranslate nohighlight">\(\mathcal{S}\left( \mathbf{X\alpha,X\beta} \right) = \mathbf{\alpha}^{T}\operatorname{S}\left( \mathbf{X} \right)\mathbf{\beta}\)</span>.
Let <span class="math notranslate nohighlight">\(\mathbf{Y} = \mathbf{\text{XA}}\)</span> for any matrix
<span class="math notranslate nohighlight">\(\mathbf{A}\mathbf{= (}\mathbf{a}_{1}\mathbf{,\ldots,}\mathbf{a}_{n}\mathbf{)}\)</span>,
then
<span class="math notranslate nohighlight">\(\mathcal{S(}\mathbf{\text{XA}}) = \mathbf{A}^{T}\mathcal{S(}\mathbf{X})\mathbf{A}\)</span>,
since<span class="math notranslate nohighlight">\(\mathcal{\text{\ S}}\left( \mathbf{X}^{T}\mathbf{\alpha}_{i}\mathbf{,}\mathbf{X}^{T}\mathbf{\alpha}_{j} \right) = \mathbf{\alpha}_{i}^{T}\operatorname{S}\left( \mathbf{X} \right)\mathbf{\alpha}_{j}\)</span>.</p>
<ul class="simple">
<li><strong>Theorem</strong> <strong>1‑2</strong> Covariance matrix is clearly symmetric, and
moreover they are semi-positive definite, since for any constant
vector <span class="math notranslate nohighlight">\(\mathbf{\alpha}\)</span></li>
</ul>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{\alpha}^{T}\left( \operatorname{\sigma}\left( X \right) \right)\mathbf{\alpha =}\sigma\left( \mathbf{\alpha}^{T}X \right)\mathbf{=}\operatorname{E}{\lbrack{\left( \mathbf{\alpha}^{T}X - \mathbb{E}\mathbf{\alpha}^{T}X \right)\left( \mathbf{\alpha}^{T}X - \mathbb{E}\mathbf{\alpha}^{T}X \right)}^{T}\rbrack}\mathbf{=}\operatorname{E}{\lbrack{\left( \mathbf{\alpha}^{T}X - \mathbf{\alpha}^{T}\mathbb{E}X \right)\left( \mathbf{\alpha}^{T}X - \mathbf{\alpha}^{T}\mathbb{E}X \right)}^{T}\rbrack}\mathbf{=}\operatorname{E}{\lbrack\mathbf{\alpha}^{T}\left( X - \mathbb{E}X \right)\left( X - \mathbb{E}X \right)^{T}\mathbf{\alpha}\rbrack} = \operatorname{E}\left\lbrack \left( \left( X - \mathbb{E}X \right)^{T}\mathbf{\alpha} \right)^{T}\left( \left( X - \mathbb{E}X \right)^{T}\mathbf{\alpha} \right) \right\rbrack \geq 0\\For sample covariance matrix, check that\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[\mathbf{\alpha}^{T}\left( \operatorname{S}\left( \mathbf{X} \right) \right)\mathbf{\alpha =}\mathcal{S}\left( \mathbf{\text{Xα}} \right) \propto \left( \mathbf{\text{Xα}} - \overline{\mathbf{\text{Xα}}} \right)^{T}\left( \mathbf{\text{Xα}} - \overline{\mathbf{\text{Xα}}} \right) \geq 0\]</div>
<ul class="simple">
<li><strong>Property</strong> <strong>1‑3</strong> Suppose
<span class="math notranslate nohighlight">\(\mathbf{X} = \left( \mathcal{x}_{1},\ldots,\mathcal{x}_{N} \right)\)</span>
where <span class="math notranslate nohighlight">\(\mathcal{x}_{1},\ldots,\mathcal{x}_{N}\)</span> are data
entries, and
<span class="math notranslate nohighlight">\(\overline{\mathcal{x}} = \frac{1}{N}\sum_{i = 1}^{N}\mathcal{x}_{i}\)</span>,
then <span class="math notranslate nohighlight">\(\Sigma\left( \mathbf{X} \right)\)</span> can be decomposed as</li>
</ul>
<div class="math notranslate nohighlight">
\[\Sigma\left( \mathbf{X} \right) = \frac{1}{N - 1}\sum_{k = 1}^{N}{\left( \mathcal{x}_{k} - \overline{\mathcal{x}} \right)\left( \mathcal{x}_{k} - \overline{\mathcal{x}} \right)^{T}}\]</div>
<p>Note
<span class="math notranslate nohighlight">\(\mathcal{x}_{j}\left( i \right) = x_{i,j} = \mathbf{x}_{i}\left( j \right)\)</span>
and
<span class="math notranslate nohighlight">\(\overline{\mathcal{x}}\left( i \right)\mathbf{=}\overline{x_{i}} = \frac{1}{N}\sum_{j = 1}^{N}x_{i,j}\)</span>,
then</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{\Si\]</div>
<p>gma}left( i,j right
) = sum_{k = 1}^{N}{
left( left( mathca
l{x}_{k} - overline{
mathcal{x}} right)left( mathcal{x}_{k}</p>
<blockquote>
<div><ul class="simple">
<li>overline{mathcal</li></ul></blockquote>
<p>{x}} right)^{T} rig
ht)left( i,j right)
} = sum_{k = 1}^{N}{
left( mathcal{x}_{k
}left( i right) - overline{x_{i}} righ
t)left( mathcal{x}_
{k}left( j right) -</p>
<blockquote>
<div>overline{x_{j}} ri</div></blockquote>
<p>ght)} = sum_{k = 1}^
{N}{left( mathbf{x}
_{i}left( k right)
- overline{x_{i}} r
ight)left( mathbf{x
}_{j}left( k right)</p>
<blockquote>
<div><ul class="simple">
<li>overline{x_{j}} </li></ul></blockquote>
<p class="last">right)} = left( mat
hbf{x}_{i} - overlin
e{mathbf{x}_{i}} ri
ght)^{T}left( mathb
f{x}_{j} - overline{
mathbf{x}_{j}} righ
t)</p>
</td>
<td>&#160;</td>
<td>(1‑2)</td>
</tr>
</tbody>
</table>
<p>The result following when comparing above with (1‑1).</p>
<p><strong>Corollary</strong> <strong>1‑1</strong>.
<span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{X}^{T} = \left( N - 1 \right)\Sigma\left( \mathbf{X} \right) + N\overline{\mathcal{x}}{\overline{\mathcal{x}}}^{T}\)</span>.
Check that :math:<a href="#id19"><span class="problematic" id="id20">`</span></a>mathbf{text{XX}}^{T} = begin{pmatrix}
mathbf{x}_{1}^{T}mathbf{x}_{1} &amp; cdots &amp; mathbf{x}_{1}^{T}mathbf{x}_{M} \</p>
<blockquote>
<div>vdots &amp; ddots &amp; vdots \</div></blockquote>
<p>mathbf{x}_{M}^{T}mathbf{x}_{1} &amp; cdots &amp; mathbf{x}_{M}^{T}mathbf{x}_{M} \
end{pmatrix}`, and by above (<em>1</em>‑<em>2</em>) we have</p>
<div class="math notranslate nohighlight">
\[\mathbf{\text{XX}}^{T} = \sum_{k = 1}^{N}{\mathcal{x}_{k}{\mathcal{x}_{k}}^{T}} = \sum_{k = 1}^{N}{\left( \mathcal{x}_{k} - \overline{\mathcal{x}} \right)({\mathcal{x}_{k} - \overline{\mathcal{x}})}^{T}} + \sum_{k = 1}^{N}\left( \overline{\mathcal{x}}\mathcal{x}_{k}^{T} + \mathcal{x}_{k}{\overline{\mathcal{x}}}^{T} - \overline{\mathcal{x}}{\overline{\mathcal{x}}}^{T} \right) = \left( N - 1 \right)\Sigma\left( \mathbf{X} \right)\mathbf{+}\overline{\mathcal{x}}\left( \sum_{k = 1}^{N}\mathcal{x}_{k}^{T} \right) + \left( \sum_{k = 1}^{N}\mathcal{x}_{k} \right){\overline{\mathcal{x}}}^{T} - N\overline{\mathcal{x}}{\overline{\mathcal{x}}}^{T} = \left( N - 1 \right)\Sigma\left( \mathbf{X} \right)\mathbf{+}N\overline{\mathcal{x}}{\overline{\mathcal{x}}}^{T} + N\overline{\mathcal{x}}{\overline{\mathcal{x}}}^{T} - N\overline{\mathcal{x}}{\overline{\mathcal{x}}}^{T} = \left( N - 1 \right)\Sigma\left( \mathbf{X} \right)\mathbf{+}N\overline{\mathcal{x}}{\overline{\mathcal{x}}}^{T}\]</div>
<p><strong>Theorem</strong> <strong>1‑3</strong><strong>Block decomposition</strong>. Again consider
<span class="math notranslate nohighlight">\(\mathbf{X} = \left( \mathcal{x}_{1},\ldots,\mathcal{x}_{N} \right)\)</span>
where <span class="math notranslate nohighlight">\(\mathcal{x}_{1},\ldots,\mathcal{x}_{N}\)</span> are data entries,
and
<span class="math notranslate nohighlight">\(\overline{\mathcal{x}} = \frac{1}{N}\sum_{i = 1}^{N}\mathcal{x}_{i}\)</span>.
Suppose <span class="math notranslate nohighlight">\(\mathcal{x}_{1},\ldots,\mathcal{x}_{N}\)</span> are categorized
into <span class="math notranslate nohighlight">\(K\)</span> non-overlapping groups <span class="math notranslate nohighlight">\(G_{1},\ldots,G_{k}\)</span>, then</p>
<div class="math notranslate nohighlight">
\[\left( N - 1 \right)\Sigma\left( \mathbf{X} \right) = \sum_{i = 1}^{K}{\left( N_{i} - 1 \right)\Sigma\left( \mathbf{X}_{i} \right)} + \sum_{i = 1}^{K}{N_{i}\left( {\overline{\mathcal{x}}}^{i} - \overline{\mathcal{x}} \right)\left( {\overline{\mathcal{x}}}^{i} - \overline{\mathcal{x}} \right)^{T}}\]</div>
</div>
<div class="section" id="multivariate-gaussian-distribution">
<h4><strong>Multivariate Gaussian Distribution</strong><a class="headerlink" href="#multivariate-gaussian-distribution" title="Permalink to this headline">¶</a></h4>
<p><span class="math notranslate nohighlight">\(m\)</span>-dimensional Multivariate Gaussian distribution is defined by
an <span class="math notranslate nohighlight">\(m\)</span>-dimensional mean <span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span> and a
<span class="math notranslate nohighlight">\(m \times m\)</span> non-singular covariance <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>,
denoted by
<span class="math notranslate nohighlight">\(\operatorname{Gaussian}\left( \mathbf{\mu},\mathbf{\Sigma} \right)\)</span>,
whose density function can be written as</p>
<div class="math notranslate nohighlight">
\[p\left( \mathbf{x} \right) = \frac{1}{\left( 2\pi \right)^{\frac{m}{2}}}\frac{1}{\left| \mathbf{\Sigma} \right|^{\frac{1}{2}}}\exp\left\{ - \frac{1}{2}\mathcal{d}_{M}\left( \mathbf{x};\mathbf{\mu,}\mathbf{\Sigma} \right) \right\} = \frac{1}{\left( 2\pi \right)^{\frac{m}{2}}}\frac{1}{\left| \mathbf{\Sigma} \right|^{\frac{1}{2}}}\exp\left\{ - \frac{1}{2}\left( \mathbf{x} - \mathbf{\mu} \right)^{T}\mathbf{\Sigma}^{- 1}\left( \mathbf{x} - \mathbf{\mu} \right) \right\}\]</div>
<p>where <span class="math notranslate nohighlight">\(\left| \mathbf{\Sigma} \right|\)</span> is the determinant of
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>, and
<span class="math notranslate nohighlight">\(\mathcal{d}_{M}\left( \mathbf{x};\mathbf{\mu,\Sigma} \right) = \left( \mathbf{x} - \mathbf{\mu} \right)^{T}\mathbf{\Sigma}^{- 1}\left( \mathbf{x} - \mathbf{\mu} \right)\)</span>
is called the <strong>Mahalanobis distance</strong>, which measures the distance
between an observation <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and a multivariate
distribution with mean <span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span> and covariance
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span> (not necessarily Gaussian). <em>Note</em>
<span class="math notranslate nohighlight">\(\mathcal{d}_{M}\)</span> is reduced to Euclidean distance from
observation <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to mean <span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span> when the
covariance is identity. Recall the basic fact that co-variance matrix is
symmetric and positive semidefinite, and in the case of Gaussian it must
be positive definite, thus
<span class="math notranslate nohighlight">\(\mathcal{d}_{M}\left( \mathbf{x};\mathbf{\mu,\Sigma} \right) \geq 0\)</span>
and
<span class="math notranslate nohighlight">\(\mathcal{d}_{M}\left( \mathbf{x};\mathbf{\mu,\Sigma} \right) = 0\)</span>
iff <span class="math notranslate nohighlight">\(\mathbf{x} = \mathbf{\mu}\)</span>. The inverse of covariance matrix
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}^{- 1}\)</span> is also named the <strong>precision matrix</strong>,
denoted by <span class="math notranslate nohighlight">\(\mathbf{Ⲗ}\)</span>, and the density can be written in terms
of precision matrix as</p>
<div class="math notranslate nohighlight">
\[p\left( \mathbf{x} \right) = \frac{\left| \mathbf{Ⲗ} \right|^{\frac{1}{2}}}{\left( 2\pi \right)^{\frac{m}{2}}}\exp\left\{ - \frac{1}{2}\left( \mathbf{x} - \mathbf{\mu} \right)^{T}\mathbf{Ⲗ}\left( \mathbf{x} - \mathbf{\mu} \right) \right\}\]</div>
<p>The <em>limitation</em> of Gaussian is its quadratic number of parameters which
could be a problem for high-dimensional computation, and its very
limited unimodal shape which could not represent complicated real-world
distributions.</p>
<ul>
<li><p class="first">We state useful gradient results from matrix derivatives, which are
frequently used in finding analytical solution for optimization
problems. They are soon applied to prove the maximum likelihood of
multivariate Gaussian.</p>
<p><strong>Fact</strong> <strong>1‑1</strong> Affine transformation
<span class="math notranslate nohighlight">\(\mathbf{a}^{T}\mathbf{x} + b\mathbf{:}\mathbb{R}^{n}\mathbb{\rightarrow R}\)</span>
where <span class="math notranslate nohighlight">\(\mathbf{a} \in \mathbb{R}^{n},b\mathbb{\in R}\)</span> has
gradient
<span class="math notranslate nohighlight">\(\nabla\left( \mathbf{a}^{T}\mathbf{x} + b \right) = \nabla\left( \mathbf{x}^{T}\mathbf{a} + b \right) = \mathbf{a}\)</span>.</p>
<p><strong>Fact</strong> <strong>1‑2</strong> Determinant
<span class="math notranslate nohighlight">\(\left| \mathbf{X} \right|:\mathbb{R}^{n \times n}\mathbb{\rightarrow R}\)</span>
is a scalar-valued matrix function, and we have
<span class="math notranslate nohighlight">\(\nabla\log\left| \mathbf{X} \right| = \mathbf{X}^{\mathbf{-}T}\)</span>.</p>
<p><strong>Fact</strong> <strong>1‑3</strong> The gradient of
<span class="math notranslate nohighlight">\(f\left( \mathbf{X} \right)\mathbf{=}\mathbf{u}^{T}\mathbf{\text{Xv}}:\mathbb{R}^{m \times n}\mathbb{\rightarrow R}\)</span>,
where
<span class="math notranslate nohighlight">\(\mathbf{u} \in \mathbb{R}^{m},\mathbf{v} \in \mathbb{R}^{n}\)</span>
are constant vectors, is
<span class="math notranslate nohighlight">\(\nabla\mathbf{u}^{T}\mathbf{\text{Xv}} \equiv \mathbf{u}\mathbf{v}^{T}\)</span>.</p>
<p><strong>Fact</strong> <strong>1‑4</strong> The gradient
of<span class="math notranslate nohighlight">\(\text{\ f}\left( \mathbf{x} \right) = \mathbf{x}^{T}\mathbf{\text{Ux}}:\mathbf{x} \in \mathbb{R}^{n}\mathbb{\rightarrow R}\)</span>,
where <span class="math notranslate nohighlight">\(\mathbf{U} \in \mathbb{R}^{n \times n}\)</span> is a constant
matrix, is
<span class="math notranslate nohighlight">\(\nabla\mathbf{x}^{T}\mathbf{\text{Ux}} = (\mathbf{U} + \mathbf{U}^{T})\mathbf{x}\)</span>.</p>
<p><strong>Theorem</strong> <strong>1‑4</strong><strong>Maximum likelihood estimators</strong>. Given
observations <span class="math notranslate nohighlight">\(\mathbf{x}_{1},\ldots,\mathbf{x}_{N}\)</span> and assume
they are i.i.d. Gaussian, the log-likelihood is</p>
</li>
</ul>
<div class="math notranslate nohighlight">
\[L \propto \sum_{i = 1}^{N}{- \frac{1}{2}\log\left| \mathbf{\Sigma} \right| - \frac{1}{2}\left( \mathbf{x}_{i} - \mathbf{\mu} \right)^{T}\mathbf{\Sigma}^{- 1}\left( \mathbf{x}_{i} - \mathbf{\mu} \right)} = \frac{N}{2}\log\left| \mathbf{\Sigma}^{- 1} \right| - \frac{1}{2}\sum_{i = 1}^{N}{\left( \mathbf{x}_{i} - \mathbf{\mu} \right)^{T}\mathbf{\Sigma}^{- 1}\left( \mathbf{x}_{i} - \mathbf{\mu} \right)}\]</div>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\frac{\part\]</div>
<p>ial L}{partialmathb
f{Sigma}^{- 1}} = f
rac{N}{2}mathbf{Sig
ma}^{T} - frac{1}{2}
sum_{i = 1}^{N}{lef
t( mathbf{x}_{i} - mathbf{mu} right)l
eft( mathbf{x}_{i} -</p>
<blockquote>
<div>mathbf{mu} right)</div></blockquote>
<dl class="docutils">
<dt>^{T}} = 0 Rightarrow</dt>
<dd>mathbf{Sigma}math</dd>
</dl>
<p class="last">bf{=}frac{1}{N}sum_
{i = 1}^{N}{left( m
athbf{x}_{i} - mathb
f{mu} right)left(
mathbf{x}_{i} - mat
hbf{mu} right)^{T}}</p>
</td>
<td>&#160;</td>
<td>(1‑3)</td>
</tr>
</tbody>
</table>
<p>Then for <span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span>, using <em>Fact 1‑4</em>,</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[L \propto \\]</div>
<p>sum_{i = 1}^{N}{math
bf{x}_{i}^{T}mathbf{
Sigma}^{- 1}mathbf{
mu} - frac{1}{2}ma
thbf{mu}^{T}mathbf{
Sigma}^{- 1}mathbf{
mu}} Rightarrow fr
ac{partial L}{parti
almathbf{mu}} = su
m_{i = 1}^{N}{mathbf
{x}_{i}^{T}mathbf{S
igma}^{- 1} - mathbf
{Sigma}^{- 1}mathbf
{mu}} = mathbf{0} Rightarrow mathbf{S
igma}^{- 1}left( su
m_{i = 1}^{N}mathbf{
x}_{i} right) = Nma
thbf{Sigma}^{- 1}ma
thbf{mu}mathbf{Rig
htarrow}mathbf{mu}_
{text{ML}}mathbf{=}
frac{sum_{i = 1}^{N
}mathbf{x}_{i}}{N} =</p>
<blockquote>
<div>overline{mathbf{x}</div></blockquote>
<p class="last">}</p>
</td>
<td>&#160;</td>
<td>(1‑4)</td>
</tr>
</tbody>
</table>
<p>Plug back to <span class="math notranslate nohighlight">\(\mathbf{\Sigma}^{- 1}\)</span> in (1‑3) and we have</p>
<div class="math notranslate nohighlight">
\[\mathbf{\Sigma}_{\text{ML}}\mathbf{=}\frac{1}{N}\sum_{i = 1}^{N}{\left( \mathbf{x}_{i} - \overline{\mathbf{x}} \right)\left( \mathbf{x}_{i} - \overline{\mathbf{x}} \right)^{T}}\]</div>
<p>By <em>Property 1‑3</em>, <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\text{ML}}\)</span> equals the biased
sample covariance, or <span class="math notranslate nohighlight">\(\frac{N}{N - 1}\mathbf{\Sigma}_{\text{ML}}\)</span>
equals the sample covariance.</p>
<ul class="simple">
<li><strong>Lemma</strong> <strong>1‑1</strong> Recall given two RVs <span class="math notranslate nohighlight">\(\mathbf{x,y}\)</span> the
<strong>covariance matrix</strong> is defined as</li>
</ul>
<div class="math notranslate nohighlight">
\[\operatorname{cov}\mathbf{x}\mathbb{= E}\left\lbrack \left( \mathbf{x}\mathbb{- E}\left\lbrack \mathbf{x} \right\rbrack \right)\left( \mathbf{x}\mathbb{- E}\left\lbrack \mathbf{x} \right\rbrack \right)^{T} \right\rbrack\]</div>
<p>Expand it and we have the generalized version of the well-known formula
“<span class="math notranslate nohighlight">\(\operatorname{cov}\left( X,Y \right)\mathbb{= E}\left\lbrack \text{XY} \right\rbrack\mathbb{- E}X\mathbb{E}Y\)</span>”
for a scalar random variable.</p>
<div class="math notranslate nohighlight">
\[\operatorname{cov}\left( \mathbf{x,y} \right)\mathbf{= E}\left\lbrack \mathbf{x}\mathbf{y}^{T} - \mathbf{x}\mathbb{E}^{T}\left\lbrack \mathbf{y} \right\rbrack - \mathbf{E}\left\lbrack \mathbf{y} \right\rbrack\mathbf{x}^{T} + \mathbf{E}\left\lbrack \mathbf{x} \right\rbrack\mathbb{E}^{T}\left\lbrack \mathbf{y} \right\rbrack \right\rbrack\mathbf{\Rightarrow}\operatorname{cov}\left( \mathbf{x,y} \right)\mathbf{=}\mathbb{E}\left\lbrack \mathbf{x}\mathbf{y}^{T} \right\rbrack\mathbf{-}\mathbf{E}\left\lbrack \mathbf{x} \right\rbrack\mathbb{E}^{T}\left\lbrack \mathbf{y} \right\rbrack\]</div>
<p>Given any RV <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, with mean <span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span> and
covariance <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>, then we have</p>
<p><span class="math notranslate nohighlight">\(\mathbf{\Sigma =}\mathbb{E}\left\lbrack \mathbf{x}\mathbf{x}^{T} \right\rbrack\mathbf{-}\mathbf{\mu}\mathbf{\mu}^{T}\)</span>
or
<span class="math notranslate nohighlight">\(\mathbb{E}\left\lbrack \mathbf{x}\mathbf{x}^{T} \right\rbrack\mathbf{=}\mathbf{\mu}\mathbf{\mu}^{T}\mathbf{+ \Sigma}\)</span></p>
<p><strong>Theorem</strong> <strong>1‑5</strong><strong>Bias of ML estimators</strong>. Given i.i.d. RVs
<span class="math notranslate nohighlight">\(\mathbf{x}_{1},\ldots,\mathbf{x}_{N}\)</span> with mean
<span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span> and covariance <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>, note
<span class="math notranslate nohighlight">\(\mathbb{E}\left\lbrack \mathbf{x}_{i}\mathbf{x}_{j}^{T} \right\rbrack = \left\{ \begin{matrix}
\mathbf{\mu}\mathbf{\mu}^{T} &amp; i \neq j \\
\mathbf{\mu}\mathbf{\mu}^{T}\mathbf{+}\mathbf{\Sigma} &amp; i = j \\
\end{matrix} \right.\ \)</span>, then we have</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left\lbrack \mathbf{x}_{i}{\overline{\mathbf{x}}}^{T} \right\rbrack = \frac{1}{N}\sum_{i = 1}^{N}{\mathbb{E}\left\lbrack \mathbf{x}_{i}\mathbf{x}_{j}^{T} \right\rbrack} = \frac{1}{N}\left( N\mathbf{\mu}\mathbf{\mu}^{T} + \mathbf{\Sigma} \right) = \mathbf{\mu}\mathbf{\mu}^{T} + \frac{\mathbf{\Sigma}}{N}\mathbb{= E}\left\lbrack \overline{\mathbf{x}}\mathbf{x}_{i}^{T} \right\rbrack\]</div>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left\lbrack \overline{\mathbf{x}}{\overline{\mathbf{x}}}^{T} \right\rbrack = \frac{1}{N^{2}}\sum_{i = 1}^{N}{\sum_{j = 1}^{N}{\mathbb{E}\left\lbrack \mathbf{x}_{i}\mathbf{x}_{j}^{T} \right\rbrack}} = \frac{1}{N^{2}}\left. （N^{2}\mathbf{\mu}\mathbf{\mu}^{T} + N\mathbf{\Sigma} \right.） = \mathbf{\mu}\mathbf{\mu}^{T} + \frac{\mathbf{\Sigma}}{N}\]</div>
<p>For Gaussian i.i.d. RVs <span class="math notranslate nohighlight">\(\mathbf{x}_{1},\ldots,\mathbf{x}_{N}\)</span> as
in</p>
<div class="math notranslate nohighlight">
\[\mathbf{E}\left\lbrack \mathbf{\Sigma}_{\text{ML}} \right\rbrack\mathbf{=}\frac{1}{N}\sum_{i = 1}^{N}{\mathbb{E}\left( \mathbf{x}_{i} - \overline{\mathbf{x}} \right)\left( \mathbf{x}_{i} - \overline{\mathbf{x}} \right)^{T}} = \frac{1}{N}\sum_{i = 1}^{N}{\mathbb{E}\left\lbrack \mathbf{x}_{i}\mathbf{x}_{i}^{T} - \mathbf{x}_{i}{\overline{\mathbf{x}}}^{T} - \overline{\mathbf{x}}\mathbf{x}_{i}^{T} + \overline{\mathbf{x}}{\overline{\mathbf{x}}}^{T} \right\rbrack} = \frac{1}{N}\sum_{i = 1}^{N}\left( \boxed{\mathbf{\mu}\mathbf{\mu}^{T}}\mathbf{+ \Sigma} - 2\left( \boxed{\mathbf{\mu}\mathbf{\mu}^{T}} + \frac{\mathbf{\Sigma}}{N} \right) + \boxed{\mathbf{\mu}\mathbf{\mu}^{T}} + \frac{\mathbf{\Sigma}}{N} \right) = \frac{N - 1}{N}\mathbf{\Sigma}\]</div>
<p>Thus,
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\text{ML}} = \frac{N - 1}{N}\mathbf{\Sigma}\)</span> is
a biased estimator. <span class="math notranslate nohighlight">\(\mathbf{\mu}_{\text{ML}}\)</span> is trivially an
unbiased estimator, since
<span class="math notranslate nohighlight">\(\mathbf{E}\left\lbrack \mathbf{\mu}_{\text{ML}} \right\rbrack\mathbf{=}\mathbb{E}\left\lbrack \overline{\mathbf{x}} \right\rbrack = \mathbf{\mu}\)</span>.</p>
<ul>
<li><p class="first"><strong>Fact</strong> <strong>1‑5</strong> Every matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> s.t.
<span class="math notranslate nohighlight">\(\operatorname{rank}\mathbf{A} = k\)</span> can be written as the sum
of <span class="math notranslate nohighlight">\(k\)</span> rank-1 matrices, i.e.
<span class="math notranslate nohighlight">\(\mathbf{A} = \sum_{i = 1}^{k}{\sigma_{i}^{2}\mathbf{u}_{i}\mathbf{v}_{i}^{T}}\)</span>,
where <span class="math notranslate nohighlight">\(\mathbf{u}_{i}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{v}_{i}\)</span> are columns
from two matrices <span class="math notranslate nohighlight">\(\mathbf{U},\mathbf{V}\)</span> that come from the
<strong>reduced SVD</strong>
<span class="math notranslate nohighlight">\(\mathbf{A} = \mathbf{\text{UΛ}}\mathbf{V}^{T}\)</span>; in particular,
if <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is symmetric and positive semidefinite, then
the singular values are eigenvalues of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>, and the
reduced SVD becomes reduced eigen-decomposition
<span class="math notranslate nohighlight">\(\mathbf{A} = \mathbf{\text{QΛ}}\mathbf{Q}^{T}\)</span> where
<span class="math notranslate nohighlight">\(\mathbf{Q}\)</span> consists of <span class="math notranslate nohighlight">\(k\)</span> orthonormal eigenvectors
<span class="math notranslate nohighlight">\(\mathbf{q}_{1},\ldots,\mathbf{q}_{k}\)</span>, and thus
<span class="math notranslate nohighlight">\(\mathbf{A =}\sum_{i = 1}^{k}{\lambda_{i}\mathbf{q}_{i}\mathbf{q}_{i}^{T}}\)</span>;
moreover,
<span class="math notranslate nohighlight">\(\mathbf{A}^{- 1}\mathbf{=}\sum_{i = 1}^{k}{\lambda_{i}^{- 1}\mathbf{q}_{i}\mathbf{q}_{i}^{T}}\)</span>
because <span class="math notranslate nohighlight">\(\mathbf{A}^{- 1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> share the
same eigenspace for each eigenvalue.</p>
<p><strong>Property</strong> <strong>1‑4</strong> As a result of <em>Fact 1‑5</em>,
<span class="math notranslate nohighlight">\(\mathcal{d}_{M}\left( \mathbf{x};\mathbf{\mu,\Sigma} \right) = \sum_{i = 1}^{k}z_{i}^{2} = \mathbf{z}^{T}\mathbf{z}\)</span>
where
<span class="math notranslate nohighlight">\(z_{i} = \frac{1}{\sqrt{\lambda_{i}}}\mathbf{q}_{i}^{T}\left( \mathbf{x} - \mathbf{\mu} \right)\)</span>
and
<span class="math notranslate nohighlight">\(\mathbf{z} = \mathbf{\Lambda}^{- \frac{1}{2}}\mathbf{Q}\left( \mathbf{x} - \mathbf{\mu} \right) = \left( z_{1},\ldots,z_{m} \right)^{T}\)</span>,
and
<span class="math notranslate nohighlight">\(\mathbf{x} = \mathbf{\Lambda}^{\frac{1}{2}}\mathbf{Q}^{T}\mathbf{z}\mathbf{+}\mathbf{\mu}\)</span>.</p>
<p><strong>Shape of contours</strong>. Recall an orthonormal matrix represents a
rotation (oriented rotation, to be exact), then
<span class="math notranslate nohighlight">\(\mathbf{\Lambda}^{\frac{1}{2}}\mathbf{Q}^{T}\left( \cdot \right)\mathbf{+}\mathbf{\mu}\)</span>
geometrically transforms the standard frame on a unit circle to a
frame on an ellipsoid centered at <span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span>, and
<span class="math notranslate nohighlight">\(\mathbf{z}\)</span> is the coordinate of <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> w.r.t. to
the ellipsoid frame. Conversely, given a contour level
<span class="math notranslate nohighlight">\(p\left( \mathbf{x} \right) = p_{0}\)</span>, we have
<span class="math notranslate nohighlight">\(\mathbf{z}^{T}\mathbf{z =}c \Rightarrow \left\| \mathbf{z} \right\|_{2} = \sqrt{c}\)</span>
for some constant <span class="math notranslate nohighlight">\(c\)</span>, and then any <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> s.t.
<span class="math notranslate nohighlight">\(\left\| \mathbf{z} \right\|_{2} = \sqrt{c}\)</span> will be on an
ellipsoid centered at <span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span>. Therefore, the contours
of multivariate Gaussian density are ellipsoids.</p>
</div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></li><li><p class="first"><strong>Lemma</strong> <strong>1‑2</strong> If a density function
<span class="math notranslate nohighlight">\(p\left( \mathbf{x} \right) \propto \exp\left\{ - \frac{1}{2}\mathbf{x}^{T}\mathbf{Ax +}\mathbf{x}^{T}\mathbf{\text{Ay}} \right\}\)</span>
where <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is symmetric positive semidefinite, then
<span class="math notranslate nohighlight">\(p\)</span> must be Gaussian with precision
<span class="math notranslate nohighlight">\(\mathbf{Ⲗ}\mathbf{= A}\)</span> and mean
<span class="math notranslate nohighlight">\(\mathbf{\mu} = \mathbf{y}\)</span>. This is simply we can rearrange it
as</p>
</li>
</ul>
<div class="math notranslate nohighlight">
\[p\left( \mathbf{x} \right) \propto \exp\left\{ - \frac{1}{2}\left( \mathbf{x - y} \right)^{T}\mathbf{A}\left( \mathbf{x}\mathbf{-}\mathbf{y} \right)\mathbf{-}\mathbf{y}^{T}\mathbf{\text{Ay}} \right\} \propto \exp\left\{ - \frac{1}{2}\left( \mathbf{x - y} \right)^{T}\mathbf{A}\left( \mathbf{x}\mathbf{-}\mathbf{y} \right) \right\}\]
<p>There is no need to worry about normalization, since we have assumed
<span class="math notranslate nohighlight">\(p\)</span> is a density, where its normalization is guaranteed.</p>
<p><strong>Fact</strong> <strong>1‑6</strong> If a block matrix <span class="math notranslate nohighlight">\(\begin{pmatrix}
\mathbf{A} &amp; \mathbf{B} \\
\mathbf{C} &amp; \mathbf{D} \\
\end{pmatrix}\)</span> is inversible, then if <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is
non-singular, we have the following with all inverses valid</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{pmatrix}
\mathbf{A} &amp; \mathbf{B} \\
\mathbf{C} &amp; \mathbf{D} \\
\end{pmatrix}^{- 1} = \begin{pmatrix}
\mathbf{A}^{- 1}\left( \mathbf{I}\mathbf{+}\mathbf{\text{BMC}}\mathbf{A}^{- 1} \right) &amp; - \mathbf{A}^{- 1}\mathbf{\text{BM}} \\
 - \mathbf{\text{MC}}\mathbf{A}^{- 1} &amp; \mathbf{M} \\
\end{pmatrix},\mathbf{M} = \left( \mathbf{D} - \mathbf{C}\mathbf{A}^{- 1}\mathbf{B} \right)^{- 1}\end{split}\]
<p>and if <span class="math notranslate nohighlight">\(\mathbf{D}\)</span> is non-singular, we have the following with
all inverses valid,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{pmatrix}
\mathbf{A} &amp; \mathbf{B} \\
\mathbf{C} &amp; \mathbf{D} \\
\end{pmatrix}^{- 1} = \begin{pmatrix}
\mathbf{M} &amp; - \mathbf{\text{MB}}\mathbf{D}^{- 1} \\
 - \mathbf{D}^{- 1}\mathbf{\text{CM}} &amp; \mathbf{D}^{- 1}\left( \mathbf{I} + \mathbf{\text{CMB}}\mathbf{D}^{- 1} \right) \\
\end{pmatrix},\mathbf{M} = \left( \mathbf{A} - \mathbf{B}\mathbf{D}^{- 1}\mathbf{C} \right)^{- 1}\end{split}\]
<p><strong>Fact</strong> <strong>1‑7</strong> Given a density <span class="math notranslate nohighlight">\(p\left( x,y \right)\)</span>, then the
<strong>conditional density</strong> <span class="math notranslate nohighlight">\(p\left( x;y = y_{0} \right)\)</span>, also
denoted as <span class="math notranslate nohighlight">\(p\left( x;y_{0} \right)\)</span>, equals the normalized
<strong>partial density</strong> <span class="math notranslate nohighlight">\(p\left( x,y_{0} \right)\)</span>, i.e.
<span class="math notranslate nohighlight">\(p\left( x;y_{0} \right)\)</span> differs from
<span class="math notranslate nohighlight">\(p\left( x,y_{0} \right)\)</span> only at their scale.</p>
<p><strong>Theorem</strong> <strong>1‑6</strong><strong>Conditional density</strong>. Given
<span class="math notranslate nohighlight">\(\mathbf{x}\sim\operatorname{Gaussian}\left( \mathbf{\mu},\mathbf{\Sigma} \right)\)</span>,
WLOG, partition <span class="math notranslate nohighlight">\(\mathbf{x} = \begin{pmatrix}
\mathbf{x}_{a} \\
\mathbf{x}_{b} \\
\end{pmatrix}\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{x}_{a} \in \mathbb{R}^{d}\)</span> is the
unknown, and <span class="math notranslate nohighlight">\(\mathbf{x}_{b} \in \mathbb{R}^{m - d}\)</span> is the
condition, and we want to find the conditional density
<span class="math notranslate nohighlight">\(p\left( \mathbf{x}_{a}\mathbf{|}\mathbf{x}_{b} \right)\)</span>.
Partition the mean and covariance accordingly as <span class="math notranslate nohighlight">\(\mathbf{\mu} =\)</span>
<span class="math notranslate nohighlight">\(\begin{pmatrix}
\mathbf{\mu}_{a} \\
\mathbf{\mu}_{b} \\
\end{pmatrix}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{\Sigma} = \begin{pmatrix}
\mathbf{\Sigma}_{\text{aa}} &amp; \mathbf{\Sigma}_{\text{ab}} \\
\mathbf{\Sigma}_{\text{ba}} &amp; \mathbf{\Sigma}_{\text{bb}} \\
\end{pmatrix}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Ⲗ} = \begin{pmatrix}
\mathbf{Ⲗ}_{\text{aa}} &amp; \mathbf{Ⲗ}_{\text{ab}} \\
\mathbf{Ⲗ}_{\text{ba}} &amp; \mathbf{Ⲗ}_{\text{bb}} \\
\end{pmatrix}\)</span>. Assume <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\text{aa}}\)</span> is
non-singular, then we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[- \frac{1}{2}\left\]
<p>( mathbf{x} - mathb
f{mu} right)^{T}ma
thbf{Ⲗ}left( mathbf
{x} - mathbf{mu} r
ight) = begin{pmatri
x}</p>
<blockquote>
<div>mathbf{x}_{a}mat</blockquote>
<p>hbf{-}mathbf{mu}_{a
} \</p>
<blockquote>
<div>mathbf{x}_{b}mat</blockquote>
<p>hbf{-}mathbf{mu}_{b
} \</p>
<blockquote>
<div>end{pmatrix}^{T}</blockquote>
<dl class="docutils">
<dt>begin{pmatrix}</dt>
<dd>mathbf{Ⲗ}_{text{</dd>
</dl>
<p>aa}} &amp; mathbf{Ⲗ}_{t
ext{ab}} \</p>
<blockquote>
<div>mathbf{Ⲗ}_{text{</blockquote>
<p>ba}} &amp; mathbf{Ⲗ}_{t
ext{bb}} \</p>
<blockquote>
<div>end{pmatrix}begi</blockquote>
<dl class="docutils">
<dt>n{pmatrix}</dt>
<dd>mathbf{x}_{a}mat</dd>
</dl>
<p>hbf{-}mathbf{mu}_{a
} \</p>
<blockquote>
<div>mathbf{x}_{b}mat</blockquote>
<p>hbf{-}mathbf{mu}_{b
} \</p>
<blockquote>
<div>end{pmatrix} = -</blockquote>
<p>frac{1}{2}left( ma
thbf{x}_{a}mathbf{-}
mathbf{mu}_{a} rig
ht)^{T}mathbf{Ⲗ}_{t
ext{aa}}left( mathb
f{x}_{a}mathbf{-}ma
thbf{mu}_{a} right)</p>
<blockquote>
<div><ul class="simple">
<li>left( mathbf{x}_</li></ul></blockquote>
<p>{a}mathbf{-}mathbf{
mu}_{a} right)^{T}mathbf{Ⲗ}_{text{ab}}
left( mathbf{x}_{b}
mathbf{-}mathbf{mu
}_{b} right)mathbf{
-}frac{1}{2}left( mathbf{x}_{b}mathbf{
-}mathbf{mu}_{b} r
ight)^{T}mathbf{Ⲗ}_{
text{bb}}left( mat
hbf{x}_{b}mathbf{-}mathbf{mu}_{b} righ
t)mathbf{=} - frac{
1}{2}mathbf{x}_{a}^{
T}mathbf{Ⲗ}_{text{a
a}}mathbf{x}_{a} + mathbf{x}_{a}^{T}mat
hbf{Ⲗ}_{text{aa}}ma
thbf{mu}_{a}mathbf{
-}mathbf{x}_{a}^{T}mathbf{Ⲗ}_{text{ab}}
left( mathbf{x}_{b}
mathbf{-}mathbf{mu
}_{b} right)mathbf{
+}text{constant} = -</p>
<blockquote>
<div>frac{1}{2}mathbf{x</blockquote>
<p class="last">}_{a}^{T}mathbf{Ⲗ}_{
text{aa}}mathbf{x}_
{a} + mathbf{x}_{a}^
{T}mathbf{Ⲗ}_{text{
aa}}left( mathbf{m
u}_{a}mathbf{-}math
bf{Ⲗ}_{text{aa}}^{-
1}mathbf{Ⲗ}_{text{a
b}}left( mathbf{x}_
{b}mathbf{-}mathbf{
mu}_{b} right) rig
ht)mathbf{+}text{co
nstant}</p>
</td>
<td>&#160;</td>
<td>(1‑4)</td>
</tr>
</tbody>
</table>
<p>By <em>Lemma 1‑2</em>, we proved that if <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\text{aa}}\)</span> is
non-singular, then
<span class="math notranslate nohighlight">\(p\left( \mathbf{x}_{a}\mathbf{|}\mathbf{x}_{b} \right)\)</span> is
Gaussian. Denote
<span class="math notranslate nohighlight">\(\mathbf{x}_{a}\mathbf{|}\mathbf{x}_{b}\mathbf{\sim}\operatorname{Gaussian}\left( \mathbf{\mu}_{a|b}\mathbf{,}\mathbf{\Sigma}_{a|b} \right)\)</span>,
we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{\mu\]
<p class="last">}_{a|b}mathbf{=}mat
hbf{mu}_{a}mathbf{-
}mathbf{Ⲗ}_{text{aa
}}^{- 1}mathbf{Ⲗ}_{text{ab}}left( math
bf{x}_{b}mathbf{-}m
athbf{mu}_{b} right
)mathbf{,}mathbf{S
igma}_{a|b}mathbf{=}
mathbf{Ⲗ}_{text{aa}
}^{- 1}</p>
</td>
<td>&#160;</td>
<td>(1‑5)</td>
</tr>
</tbody>
</table>
<p>If in addition <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\text{bb}}\)</span> is non-singular,
using <em>Fact 1‑6</em> and <span class="math notranslate nohighlight">\(\begin{pmatrix}
\mathbf{\Sigma}_{\text{aa}} &amp; \mathbf{\Sigma}_{\text{ab}} \\
\mathbf{\Sigma}_{\text{ba}} &amp; \mathbf{\Sigma}_{\text{bb}} \\
\end{pmatrix}^{- 1} = \begin{pmatrix}
\mathbf{Ⲗ}_{\text{aa}} &amp; \mathbf{Ⲗ}_{\text{ab}} \\
\mathbf{Ⲗ}_{\text{ba}} &amp; \mathbf{Ⲗ}_{\text{bb}} \\
\end{pmatrix}\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{ \begin{matrix}
{\mathbf{Ⲗ}_{\text{aa}}\mathbf{=}\left( \mathbf{\Sigma}_{\text{aa}} - \mathbf{\Sigma}_{\text{ab}}\mathbf{\Sigma}_{\text{bb}}^{- 1}\mathbf{\Sigma}_{\text{ba}} \right)}^{- 1} \\
\mathbf{Ⲗ}_{\text{ab}}\mathbf{=} - \mathbf{Ⲗ}_{\text{aa}}\mathbf{\Sigma}_{\text{ab}}\mathbf{\Sigma}_{\text{bb}}^{- 1} \\
\end{matrix} \right.\ \mathbf{\Rightarrow}\left\{ \begin{matrix}
\mathbf{Ⲗ}_{\text{aa}}^{- 1}\mathbf{Ⲗ}_{\text{ab}}\mathbf{= -}\mathbf{\Sigma}_{\text{ab}}\mathbf{\Sigma}_{\text{bb}}^{- 1} \\
\mathbf{Ⲗ}_{\text{aa}}^{- 1}\mathbf{=}\mathbf{\Sigma}_{\text{aa}} - \mathbf{\Sigma}_{\text{ab}}\mathbf{\Sigma}_{\text{bb}}^{- 1}\mathbf{\Sigma}_{\text{ba}} \\
\end{matrix} \right.\\end{split}\]
<p>Plug into <strong>Error! Reference source not found.</strong> we have</p>
<div class="math notranslate nohighlight">
\[\mathbf{\mu}_{a|b}\mathbf{=}\mathbf{\mu}_{a}\mathbf{+}\mathbf{\Sigma}_{\text{ab}}\mathbf{\Sigma}_{\text{bb}}^{- 1}\left( \mathbf{x}_{b}\mathbf{-}\mathbf{\mu}_{b} \right)\mathbf{,}\mathbf{\Sigma}_{a|b}\mathbf{=}\mathbf{\Sigma}_{\text{aa}} - \mathbf{\Sigma}_{\text{ab}}\mathbf{\Sigma}_{\text{bb}}^{- 1}\mathbf{\Sigma}_{\text{ba}}\]
<p>Similarly, if <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\text{bb}}\)</span> is non-singular, then
<span class="math notranslate nohighlight">\(p\left( \mathbf{x}_{b}|\mathbf{x}_{a} \right)\)</span> is Gaussian, and
from (1‑4) we have</p>
<div class="math notranslate nohighlight">
\[- \frac{1}{2}\mathbf{x}_{b}^{T}\mathbf{Ⲗ}_{\text{bb}}\mathbf{x}_{b} + \mathbf{x}_{b}^{T}\mathbf{Ⲗ}_{\text{bb}}\mathbf{\mu}_{b}\mathbf{-}\left( \mathbf{x}_{a}\mathbf{-}\mathbf{\mu}_{a} \right)^{T}\mathbf{Ⲗ}_{\text{ab}}\mathbf{x}_{b}\mathbf{+}\text{constant} = - \frac{1}{2}\mathbf{x}_{b}^{T}\mathbf{Ⲗ}_{\text{bb}}\mathbf{x}_{b} + \mathbf{x}_{b}^{T}\mathbf{Ⲗ}_{\text{bb}}\mathbf{\mu}_{b}\mathbf{-}\mathbf{x}_{b}^{T}\mathbf{Ⲗ}_{\text{ba}}\left( \mathbf{x}_{a}\mathbf{-}\mathbf{\mu}_{a} \right)\mathbf{+}\text{constant} = - \frac{1}{2}\mathbf{x}_{b}^{T}\mathbf{Ⲗ}_{\text{bb}}\mathbf{x}_{b} + \mathbf{x}_{b}^{T}\mathbf{Ⲗ}_{\text{bb}}\left( \mathbf{\mu}_{b}\mathbf{-}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\left( \mathbf{x}_{a}\mathbf{-}\mathbf{\mu}_{a} \right) \right)\mathbf{+}\text{constant}\]
<p>If in addition <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\text{aa}}\)</span> is non-singular,
using <em>Fact 1‑6</em> we have</p>
<div class="math notranslate nohighlight">
\[\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{= -}\mathbf{\Sigma}_{\text{ba}}\mathbf{\Sigma}_{\text{aa}}^{- 1}\mathbf{,}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{=}\mathbf{\Sigma}_{\text{bb}}\mathbf{-}\mathbf{\Sigma}_{\text{ba}}\mathbf{\Sigma}_{\text{aa}}^{- 1}\mathbf{\Sigma}_{\text{ab}}\]
<p>Finally,</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{\mu\]
<p>}_{b|a}mathbf{=}mat
hbf{mu}_{b}mathbf{-
}mathbf{Ⲗ}_{text{bb
}}^{- 1}mathbf{Ⲗ}_{text{ba}}left( math
bf{x}_{a}mathbf{-}m
athbf{mu}_{a} right
)mathbf{=}mathbf{m
u}_{b}mathbf{+}math
bf{Sigma}_{text{ba}
}mathbf{Sigma}_{te
xt{aa}}^{- 1}left( mathbf{x}_{a}mathbf{
-}mathbf{mu}_{a} r
ight)</p>
<div class="math notranslate nohighlight">
\[\mathbf{\Si\]
<p class="last">gma}_{b|a}mathbf{=}mathbf{Ⲗ}_{text{bb}}
^{- 1}mathbf{=}math
bf{Sigma}_{text{bb}
}mathbf{-}mathbf{S
igma}_{text{ba}}mat
hbf{Sigma}_{text{aa
}}^{- 1}mathbf{Sigm
a}_{text{ab}}</p>
</td>
<td>&#160;</td>
<td>(1‑6)</td>
</tr>
</tbody>
</table>
<p>We <em>note</em> 1) the conditional mean and variance is simpler in terms of
precision, as seen in (1‑5) and (1‑6); 2) given the unknowns and
conditions, the conditional mean <span class="math notranslate nohighlight">\(\mathbf{\mu}_{a|b}\)</span> is
independent of <span class="math notranslate nohighlight">\(\mathbf{x}_{a}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{\mu}_{b|a}\)</span> is
independent of <span class="math notranslate nohighlight">\(\mathbf{x}_{b}\)</span>, and both
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{a|b}\mathbf{,}\mathbf{\Sigma}_{b|a}\)</span> are
independent of <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p>
<ul class="simple">
<li><strong>Theorem</strong> <strong>1‑7</strong><strong>Marginal density</strong>. Given
<span class="math notranslate nohighlight">\(\mathbf{x}\sim\operatorname{Gaussian}\left( \mathbf{\mu},\mathbf{\Sigma} \right)\)</span>,
partition <span class="math notranslate nohighlight">\(\mathbf{x} = \begin{pmatrix}
\mathbf{x}_{a} \\
\mathbf{x}_{b} \\
\end{pmatrix}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{\mu} =\)</span> <span class="math notranslate nohighlight">\(\begin{pmatrix}
\mathbf{\mu}_{a} \\
\mathbf{\mu}_{b} \\
\end{pmatrix}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{\Sigma} = \begin{pmatrix}
\mathbf{\Sigma}_{\text{aa}} &amp; \mathbf{\Sigma}_{\text{ab}} \\
\mathbf{\Sigma}_{\text{ba}} &amp; \mathbf{\Sigma}_{\text{bb}} \\
\end{pmatrix}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{Ⲗ} = \begin{pmatrix}
\mathbf{Ⲗ}_{\text{aa}} &amp; \mathbf{Ⲗ}_{\text{ab}} \\
\mathbf{Ⲗ}_{\text{ba}} &amp; \mathbf{Ⲗ}_{\text{bb}} \\
\end{pmatrix}\)</span> as in <em>Theorem 1‑6</em>, and we want to find the marginal
density
<span class="math notranslate nohighlight">\(p\left( \mathbf{x}_{a} \right) = \int_{}^{}{p\left( \mathbf{x}_{a},\mathbf{x}_{b} \right)d\mathbf{x}_{b}}\)</span>.
Let’s break down the terms in the exponential into two parts based on
the result of (1‑4) and (1‑6), one dependent on
<span class="math notranslate nohighlight">\(\mathbf{x}_{b}\)</span> and can be integrated as a constant, and the
other is dependent on <span class="math notranslate nohighlight">\(\mathbf{x}_{a}\)</span>,</li>
</ul>
<div class="math notranslate nohighlight">
\[- \frac{1}{2}\left( \mathbf{x} - \mathbf{\mu} \right)^{T}\mathbf{Ⲗ}\left( \mathbf{x} - \mathbf{\mu} \right) = - \frac{1}{2}\left( \mathbf{x}_{b} - \mathbf{\mu}_{b|a} \right)^{T}\mathbf{Ⲗ}_{\text{bb}}\left( \mathbf{x}_{b} - \mathbf{\mu}_{b|a} \right) + \frac{1}{2}\mathbf{\mu}_{b|a}^{T}\mathbf{Ⲗ}_{\text{bb}}\mathbf{\mu}_{b|a} - \frac{1}{2}\mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{aa}}\mathbf{x}_{a} + \mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{aa}}\mathbf{\mu}_{a} + \mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{ab}}\mathbf{\mu}_{b}\mathbf{+}\text{constant}\]
<p>Assume <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\text{bb}}\)</span> is non-singular. Since the
first term will be integrated out as a constant, we only need to concern
remaining terms. Further, we clean up
<span class="math notranslate nohighlight">\(\frac{1}{2}\mathbf{\mu}_{b|a}^{T}\mathbf{Ⲗ}_{\text{bb}}\mathbf{\mu}_{b|a}\)</span>
and have</p>
<div class="math notranslate nohighlight">
\[\frac{1}{2}\mathbf{\mu}_{b|a}^{T}\mathbf{Ⲗ}_{\text{bb}}\mathbf{\mu}_{b|a} = \frac{1}{2}\left( \mathbf{\mu}_{b}\mathbf{-}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\left( \mathbf{x}_{a}\mathbf{-}\mathbf{\mu}_{a} \right) \right)^{T}\mathbf{Ⲗ}_{\text{bb}}\left( \mathbf{\mu}_{b}\mathbf{-}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\left( \mathbf{x}_{a}\mathbf{-}\mathbf{\mu}_{a} \right) \right) = \frac{1}{2}\left( \mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{x}_{a}\mathbf{-}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{\mu}_{a} \right)^{T}\mathbf{Ⲗ}_{\text{bb}}\left( \mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{x}_{a}\mathbf{-}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{\mu}_{a} \right) - \mathbf{\mu}_{b}^{T}\boxed{\mathbf{Ⲗ}_{\text{bb}}\mathbf{Ⲗ}_{\text{bb}}^{- 1}}\mathbf{Ⲗ}_{\text{ba}}\left( \mathbf{x}_{a}\mathbf{-}\mathbf{\mu}_{a} \right)\mathbf{+}\text{constant} = \frac{1}{2}\left( \mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{x}_{a} \right)^{T}\mathbf{Ⲗ}_{\text{bb}}\left( \mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{x}_{a} \right)\mathbf{-}\left( \mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{x}_{a} \right)^{T}\mathbf{Ⲗ}_{\text{bb}}\left( \mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{\mu}_{a} \right) - \mathbf{\mu}_{b}^{T}\mathbf{Ⲗ}_{\text{ba}}\mathbf{x}_{a}\mathbf{+}\text{constant} = \frac{1}{2}\mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{ab}}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{x}_{a}\mathbf{-}\mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{ab}}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{\mu}_{a} - \mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{ab}}\mathbf{\mu}_{b}\mathbf{+}\text{constant}\]
<p>Then the terms dependent on <span class="math notranslate nohighlight">\(\mathbf{x}_{a}\)</span> are</p>
<div class="math notranslate nohighlight">
\[\frac{1}{2}\mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{ab}}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{x}_{a}\mathbf{-}\mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{ab}}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}}\mathbf{\mu}_{a}\boxed{- \mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{ab}}\mathbf{\mu}_{b}} - \frac{1}{2}\mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{aa}}\mathbf{x}_{a}\boxed{+ \mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{aa}}\mathbf{\mu}_{a}} + \mathbf{x}_{a}^{T}\mathbf{Ⲗ}_{\text{ab}}\mathbf{\mu}_{b}\mathbf{=} - \frac{1}{2}\mathbf{x}_{a}^{T}\left( \mathbf{Ⲗ}_{\text{aa}}\mathbf{-}\mathbf{Ⲗ}_{\text{ab}}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}} \right)\mathbf{x}_{a}\mathbf{+}\mathbf{x}_{a}^{T}\left( \mathbf{Ⲗ}_{\text{aa}}\mathbf{-}\mathbf{Ⲗ}_{\text{ab}}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}} \right)\mathbf{\mu}_{a}\]
<p>By <em>Lemma 1‑2</em>, <em>Fact 1‑6</em> and <span class="math notranslate nohighlight">\(\begin{pmatrix}
\mathbf{Ⲗ}_{\text{aa}} &amp; \mathbf{Ⲗ}_{\text{ab}} \\
\mathbf{Ⲗ}_{\text{ba}} &amp; \mathbf{Ⲗ}_{\text{bb}} \\
\end{pmatrix}^{- 1} = \begin{pmatrix}
\mathbf{\Sigma}_{\text{aa}} &amp; \mathbf{\Sigma}_{\text{ab}} \\
\mathbf{\Sigma}_{\text{ba}} &amp; \mathbf{\Sigma}_{\text{bb}} \\
\end{pmatrix}\)</span>, we conclude if <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\text{bb}}\)</span> is
non-singular, <span class="math notranslate nohighlight">\(p\left( \mathbf{x}_{a} \right)\)</span> is Gaussian with
mean <span class="math notranslate nohighlight">\(\mathbf{\mu}_{a}\)</span> and covariance
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{a} = \left( \mathbf{Ⲗ}_{\text{aa}}\mathbf{-}\mathbf{Ⲗ}_{\text{ab}}\mathbf{Ⲗ}_{\text{bb}}^{- 1}\mathbf{Ⲗ}_{\text{ba}} \right)^{- 1}\mathbf{=}\mathbf{\Sigma}_{\text{aa}}\)</span>;
likewise, if <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\text{aa}}\)</span> is non-singular,
<span class="math notranslate nohighlight">\(p\left( \mathbf{x}_{b} \right)\)</span> is Gaussian with mean
<span class="math notranslate nohighlight">\(\mathbf{\mu}_{b}\)</span> and covariance
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{b} = \left( \mathbf{Ⲗ}_{\text{bb}}\mathbf{-}\mathbf{Ⲗ}_{\text{ba}}\mathbf{Ⲗ}_{\text{aa}}^{- 1}\mathbf{Ⲗ}_{\text{ab}} \right)^{- 1}\mathbf{=}\mathbf{\Sigma}_{\text{bb}}\)</span>.</p>
<ul class="simple">
<li><strong>Theorem</strong> <strong>1‑8</strong><strong>Bayesian Theorem for Gaussian</strong>. Given prior
distribution
<span class="math notranslate nohighlight">\(\mathbf{x}\sim\operatorname{Gaussian}\left( \mathbf{\mu},\mathbf{Ⲗ}_{x}^{- 1} \right)\)</span>
(the prior for Gaussian is chosen as Gaussian because of
<strong>conjugacy</strong>) and condition
<span class="math notranslate nohighlight">\(\mathbf{y}|\mathbf{x}\sim\operatorname{Gaussian}\left( \mathbf{\text{Ax}} + \mathbf{b},\mathbf{Ⲗ}_{y|x}^{- 1} \right)\)</span>,
the key goal is to derive the posterior distribution
<span class="math notranslate nohighlight">\(p\left( \mathbf{x} \middle| \mathbf{y} \right)\)</span> and the
marginal distribution <span class="math notranslate nohighlight">\(p\left( \mathbf{y} \right)\)</span>. The
approach is to first derive joint distribution
<span class="math notranslate nohighlight">\(p\left( \mathbf{x},\mathbf{y} \right)\)</span>, then
<span class="math notranslate nohighlight">\(\mathbf{x}|\mathbf{y}\)</span> is conditional distribution of
<span class="math notranslate nohighlight">\(p\left( \mathbf{x},\mathbf{y} \right)\)</span> (<em>Theorem 1‑6</em>), and
<span class="math notranslate nohighlight">\(p\left( \mathbf{y} \right)\)</span> is the marginal distribution of
<span class="math notranslate nohighlight">\(p\left( \mathbf{x},\mathbf{y} \right)\)</span> (<em>Theorem 1‑7</em>). First,
we have</li>
</ul>
<div class="math notranslate nohighlight">
\[\ln{p\left( \mathbf{x},\mathbf{y} \right)} = \ln{p\left( \mathbf{x} \right)p\left( y|\mathbf{x} \right)} \propto - \frac{1}{2}\left( \mathbf{x} - \mathbf{\mu} \right)^{T}\mathbf{Ⲗ}_{x}\left( \mathbf{x} - \mathbf{\mu} \right) - \frac{1}{2}\left( \mathbf{y} - \mathbf{\text{Ax}} - \mathbf{b} \right)^{T}\mathbf{Ⲗ}_{y|x}\left( \mathbf{y} - \mathbf{\text{Ax}} - \mathbf{b} \right)\]
<p>where the RHS is the terms in the exponential of
<span class="math notranslate nohighlight">\(p\left( \mathbf{x},\mathbf{y} \right)\)</span>. Continue the
simplification: remove terms not dependent on either <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>
or <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\ln{p\left( \mathbf{x},\mathbf{y} \right)} \propto - \frac{1}{2}\left( \mathbf{x}^{T}\mathbf{Ⲗ}_{x}\mathbf{x +}\mathbf{x}^{T}\mathbf{A}\mathbf{Ⲗ}_{y|x}\mathbf{\text{Ax}} \right)\mathbf{+}\frac{1}{2}\mathbf{x}^{T}\mathbf{A}^{T}\mathbf{Ⲗ}_{y|x}\mathbf{y} + \frac{1}{2}\mathbf{y}^{T}\mathbf{Ⲗ}_{y|x}\mathbf{\text{Ax}} - \frac{1}{2}\mathbf{y}^{T}\mathbf{Ⲗ}_{y|x}\mathbf{y}\mathbf{+}\mathbf{x}^{T}\mathbf{Ⲗ}_{x}\mathbf{\mu}\mathbf{-}\mathbf{x}^{T}\mathbf{A}^{T}\mathbf{Ⲗ}_{y|x}\mathbf{b +}\mathbf{y}^{T}\mathbf{Ⲗ}_{y|x}\mathbf{b}\mathbf{= -}\frac{1}{2}\begin{pmatrix}
\mathbf{x} \\
\mathbf{y} \\
\end{pmatrix}^{T}\begin{pmatrix}
\mathbf{Ⲗ}_{x}\mathbf{+}\mathbf{A}^{T}\mathbf{Ⲗ}_{y|x}\mathbf{A} &amp; - \mathbf{A}^{T}\mathbf{Ⲗ}_{y|x} \\
 - \mathbf{Ⲗ}_{y|x}\mathbf{A} &amp; \mathbf{Ⲗ}_{y|x} \\
\end{pmatrix}\begin{pmatrix}
\mathbf{x} \\
\mathbf{y} \\
\end{pmatrix} + \begin{pmatrix}
\mathbf{x} \\
\mathbf{y} \\
\end{pmatrix}^{\mathbf{T}}\begin{pmatrix}
\mathbf{Ⲗ}_{\mathbf{x}}\mathbf{\mu}\mathbf{-}\mathbf{A}^{\mathbf{T}}\mathbf{Ⲗ}_{\mathbf{y|x}}\mathbf{b} \\
\mathbf{Ⲗ}_{\mathbf{y|x}}\mathbf{b} \\
\end{pmatrix}\end{split}\]
<p>Then by <em>Lemma 1‑2</em>, <span class="math notranslate nohighlight">\(p\left( \mathbf{x},\mathbf{y} \right)\)</span> is a
Gaussian with precision and mean</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{Ⲗ}_{x,y}\m\]
<p>athbf{=}begin{pmatri
x}</p>
<blockquote>
<div>mathbf{Ⲗ}_{x}mat</blockquote>
<p>hbf{+}mathbf{A}^{T}mathbf{Ⲗ}_{y|x}mathb
f{A} &amp; - mathbf{A}^{
T}mathbf{Ⲗ}_{y|x} \</p>
<blockquote>
<div><ul class="simple">
<li>mathbf{Ⲗ}_{y|x</li></ul></blockquote>
<p>}mathbf{A} &amp; mathbf
{Ⲗ}_{y|x} \</p>
<blockquote>
<div>end{pmatrix},mat</blockquote>
<p>hbf{mu}_{x,y}mathbf
{=}mathbf{Ⲗ}_{x,y}^{
- 1}begin{pmatrix}</p>
<blockquote>
<div>mathbf{Ⲗ}_{mathb</blockquote>
<p>f{x}}mathbf{mu}mat
hbf{-}mathbf{A}^{ma
thbf{T}}mathbf{Ⲗ}_{mathbf{y|x}}mathbf{b
} \</p>
<blockquote>
<div>mathbf{Ⲗ}_{mathb</blockquote>
<dl class="last docutils">
<dt>f{y|x}}mathbf{b} \</dt>
<dd>end{pmatrix}</dd>
</dl>
</td>
<td>&#160;</td>
<td>(1‑7)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>provided that <span class="math notranslate nohighlight">\(\mathbf{Ⲗ}_{x,y}\)</span> is non-singular. Since
<span class="math notranslate nohighlight">\(\mathbf{Ⲗ}_{y|x}\)</span> is non-singular, using <em>Fact 1‑6</em>, we have</blockquote>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{Ⲗ}_{x,y}^{- 1}\mathbf{=}\begin{pmatrix}
\left( \mathbf{Ⲗ}_{x}\mathbf{+ A}\mathbf{Ⲗ}_{y|x}\mathbf{A -}\mathbf{A}^{T}\boxed{\mathbf{Ⲗ}_{y|x}\mathbf{Ⲗ}_{y|x}^{- 1}}\mathbf{Ⲗ}_{y|x}\mathbf{A} \right)^{- 1}\mathbf{=}\mathbf{Ⲗ}_{x}^{- 1} &amp; \mathbf{Ⲗ}_{x}^{- 1}\mathbf{A}^{T}\boxed{\mathbf{Ⲗ}_{y|x}\mathbf{Ⲗ}_{y|x}^{- 1}} = \mathbf{Ⲗ}_{x}^{- 1}\mathbf{A}^{T} \\
\boxed{\mathbf{Ⲗ}_{y|x}^{- 1}\mathbf{Ⲗ}_{y|x}}\mathbf{A}\mathbf{Ⲗ}_{x}^{- 1}\mathbf{=}\mathbf{A}\mathbf{Ⲗ}_{x}^{- 1} &amp; \mathbf{Ⲗ}_{y|x}^{- 1}\mathbf{+}\boxed{\mathbf{Ⲗ}_{y|x}^{- 1}\mathbf{Ⲗ}_{y|x}}\mathbf{A}\mathbf{Ⲗ}_{x}^{- 1}\mathbf{A}^{T} = \mathbf{Ⲗ}_{y|x}^{- 1}\mathbf{+}\mathbf{A}\mathbf{Ⲗ}_{x}^{- 1}\mathbf{A}^{T} \\
\end{pmatrix}\mathbf{\Rightarrow}\mathbf{\Sigma}_{x,y}\mathbf{=}\mathbf{Ⲗ}_{x,y}^{- 1}\mathbf{=}\begin{pmatrix}
\mathbf{Ⲗ}_{x}^{- 1} &amp; \mathbf{Ⲗ}_{x}^{- 1}\mathbf{A}^{T} \\
\mathbf{A}\mathbf{Ⲗ}_{x}^{- 1} &amp; \mathbf{Ⲗ}_{y|x}^{- 1}\mathbf{+}\mathbf{A}\mathbf{Ⲗ}_{x}^{- 1}\mathbf{A}^{T} \\
\end{pmatrix}\end{split}\]
<p>and therefore,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{\mu}_{x,y} = \mathbf{Ⲗ}_{x,y}^{- 1}\mathbf{\ }\begin{pmatrix}
\mathbf{Ⲗ}_{x}\mathbf{\mu}\mathbf{-}\mathbf{A}^{T}\mathbf{Ⲗ}_{y|x}\mathbf{b} \\
\mathbf{Ⲗ}_{y|x}\mathbf{b} \\
\end{pmatrix} = \begin{pmatrix}
\mathbf{\mu} \\
\mathbf{\text{Aμ}} + \mathbf{b} \\
\end{pmatrix}\end{split}\]
<p>Note the posterior <span class="math notranslate nohighlight">\(p\left( \mathbf{x}|\mathbf{y} \right)\)</span> is the
conditional distribution we found in <em>Theorem 1‑6</em>, and thus by (1‑5) we
have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\left\{ \begin{mat\]
<dl class="docutils">
<dt>rix}</dt>
<dd>mathbf{mu}_{x|y}</dd>
</dl>
<p>mathbf{=}mathbf{mu
}mathbf{+}left( ma
thbf{Ⲗ}_{x}mathbf{+}
mathbf{A}^{T}mathbf
{Ⲗ}_{y|x}mathbf{A} right)^{- 1}mathbf{A
}^{T}mathbf{Ⲗ}_{y|x}
left( mathbf{y}mat
hbf{-}mathbf{text{A
μ}} - mathbf{b} rig
ht) \</p>
<blockquote>
<div>mathbf{Sigma}_{x</blockquote>
<p><a href="#id21"><span class="problematic" id="id22">|</span></a>y}mathbf{=}left( mathbf{Ⲗ}_{x}mathbf{
+}mathbf{A}^{T}math
bf{Ⲗ}_{y|x}mathbf{A}</p>
<blockquote>
<div><dl class="docutils">
<dt>right)^{- 1} \</dt>
<dd>end{matrix} righ</dd>
</dl>
</blockquote>
<p class="last">t.</p>
</td>
<td>&#160;</td>
<td>(1‑8)</td>
</tr>
</tbody>
</table>
<p>We can also rearrange the terms as</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{\mu\]
<p>}_{x|y}mathbf{=}lef
t( mathbf{Ⲗ}_{x}mat
hbf{+}mathbf{A}^{T}mathbf{Ⲗ}_{y|x}mathb
f{A} right)^{- 1}le
ft( left( mathbf{Ⲗ}
_{x}mathbf{+}mathbf
{A}^{T}mathbf{Ⲗ}_{y|
x}mathbf{A} right)mathbf{mu}mathbf{+}
mathbf{A}^{T}mathbf
{Ⲗ}_{y|x}left( math
bf{y}mathbf{-}mathb
f{text{Aμ}} - mathb
f{b} right) right)mathbf{=}left( math
bf{Ⲗ}_{x}mathbf{+}m
athbf{A}^{T}mathbf{Ⲗ
}_{y|x}mathbf{A} ri
ght)^{- 1}left( mat
hbf{Ⲗ}_{x}mathbf{mu</p>
<blockquote>
<div>+}boxed{mathbf{A}^</blockquote>
<p class="last">{T}mathbf{Ⲗ}_{y|x}m
athbf{text{Aμ}}}mat
hbf{+}mathbf{A}^{T}mathbf{Ⲗ}_{y|x}mathb
f{y}mathbf{-}boxed{
mathbf{A}^{T}mathbf
{Ⲗ}_{y|x}mathbf{tex
t{Aμ}}}mathbf{-}mat
hbf{A}^{T}mathbf{Ⲗ}_
{y|x}mathbf{b} righ
t)mathbf{Rightarrow
}mathbf{mu}_{x|y}m
athbf{=}left( mathb
f{Ⲗ}_{x}mathbf{+}ma
thbf{A}^{T}mathbf{Ⲗ}
_{y|x}mathbf{A} rig
ht)^{- 1}left( math
bf{Ⲗ}_{x}mathbf{mu
+}mathbf{A}^{T}math
bf{Ⲗ}_{y|x}left( ma
thbf{y}mathbf{-}mat
hbf{b} right) right
)</p>
</td>
<td>&#160;</td>
<td>(1‑9)</td>
</tr>
</tbody>
</table>
<p>By <em>Theorem 1‑7</em>, we have
<span class="math notranslate nohighlight">\(p\left( \mathbf{y} \right)\sim\operatorname{Gaussian}\left( \mathbf{\mu}_{y},\mathbf{\Sigma}_{y} \right)\)</span>
where</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\left\{ \begin{mat\]
<dl class="docutils">
<dt>rix}</dt>
<dd><blockquote class="first">
<div>mathbf{mu}_{y} =</blockquote>
<p>mathbf{text{Aμ}} +
mathbf{b} \</p>
<blockquote class="last">
<div>mathbf{Sigma}_{y</blockquote>
</dd>
</dl>
<p>} = mathbf{Ⲗ}_{y|x}^
{- 1}mathbf{+}mathb
f{A}mathbf{Ⲗ}_{x}^{-</p>
<blockquote>
<div>1}mathbf{A}^{T} = </blockquote>
<p>mathbf{Sigma}_{y|x}mathbf{+}mathbf{A}m
athbf{Sigma}_{x}mat
hbf{A}^{T} \</p>
<blockquote>
<div>end{matrix} righ</blockquote>
<p class="last">t.</p>
</td>
<td>&#160;</td>
<td>(1‑10)</td>
</tr>
</tbody>
</table>
<p><strong>Corollary</strong> <strong>1‑2</strong>. In the case of
<span class="math notranslate nohighlight">\(\mathbf{A} = \mathbf{I},\mathbf{b} = \mathbf{0}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{x},\mathbf{y}\)</span> have the same dimension, i.e.
<span class="math notranslate nohighlight">\(\mathbf{x}\sim\operatorname{Gaussian}\left( \mathbf{\mu},\mathbf{Ⲗ}_{x}^{- 1} \right)\)</span>
and
<span class="math notranslate nohighlight">\(\mathbf{y}|\mathbf{x}\sim\operatorname{Gaussian}\left( \mathbf{x},\mathbf{Ⲗ}_{y|x}^{- 1} \right)\)</span>
then</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}{\left\{ \begin{matrix}
\mathbf{\mu}_{x|y}\mathbf{=}\mathbf{\mu}\mathbf{+}\left( \mathbf{Ⲗ}_{x}\mathbf{+}\mathbf{Ⲗ}_{y|x} \right)^{- 1}\mathbf{Ⲗ}_{y|x}\left( \mathbf{y}\mathbf{-}\mathbf{\mu} \right)\mathbf{=}\left( \mathbf{Ⲗ}_{x}\mathbf{+}\mathbf{Ⲗ}_{y|x} \right)^{- 1}\left( \mathbf{Ⲗ}_{x}\mathbf{\mu +}\mathbf{Ⲗ}_{y|x}\mathbf{y} \right) \\
\mathbf{\Sigma}_{x|y}\mathbf{=}\left( \mathbf{Ⲗ}_{x}\mathbf{+}\mathbf{Ⲗ}_{y|x} \right)^{- 1} \\
\end{matrix} \right.\
}\left\{ \begin{matrix}
\mathbf{\mu}_{y} = \mathbf{\mu} \\
\mathbf{\Sigma}_{y} = \mathbf{Ⲗ}_{y|x}^{- 1}\mathbf{+}\mathbf{Ⲗ}_{x}^{- 1} = \mathbf{\Sigma}_{y|x}\mathbf{+}\mathbf{\Sigma}_{x} \\
\end{matrix} \right.\\end{split}\\**Corollary** **1‑3**. The joint distribution of two independent
Gaussian RVs :math:`\mathbf{x},\mathbf{y}` s.t.
:math:`\mathbf{x}\sim\operatorname{Gaussian}\left( \mathbf{\mu}_{x},\mathbf{\Sigma}_{x} \right)`
and
:math:`\mathbf{y}\sim\operatorname{Gaussian}\left( \mathbf{\mu}_{y},\mathbf{\Sigma}_{t} \right)`
is Gaussian. This is equivalent to :math:`\mathbf{A} = \mathbf{O}`
and :math:`\mathbf{b} = \mathbf{\mu}_{2}`, and we have\end{aligned}\end{align} \]
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{\mu}_{x,y} = \begin{pmatrix}
\mathbf{\mu}_{x} \\
\mathbf{\mu}_{y} \\
\end{pmatrix},\mathbf{\Sigma}_{x,y}\mathbf{=}\begin{pmatrix}
\mathbf{\Sigma}_{1} &amp; \mathbf{O} \\
\mathbf{O} &amp; \mathbf{\Sigma}_{y} \\
\end{pmatrix}\end{split}\]
<p><strong>Example</strong> <strong>1‑1</strong>. Given prior distribution
<span class="math notranslate nohighlight">\(\mathbf{x}\sim\operatorname{Gaussian}\left( \mathbf{\mu},\mathbf{Ⲗ}_{x}^{- 1} \right)\)</span>,
and we observe multiple i.i.d. realizations
<span class="math notranslate nohighlight">\(\mathbf{y} = \left( y_{1},\ldots,y_{N} \right)\)</span> from
<span class="math notranslate nohighlight">\(\operatorname{Gaussian}\left( \mathbf{a}^{T}\mathbf{x +}b,\sigma^{2} \right)\)</span>
. By previous corollary the joint distribution is
<span class="math notranslate nohighlight">\(\mathbf{y\sim}\operatorname{Gaussian}\left( \mathbf{1}\mathbf{a}^{T}\mathbf{x + b},\sigma^{2}\mathbf{I} \right)\)</span>.
Then the prior
<span class="math notranslate nohighlight">\(p\left( \mathbf{x}|\mathbf{y} \right)\sim\operatorname{Gaussian}\left( \mathbf{\mu}_{x|y}\mathbf{,}\mathbf{\Sigma}_{x|y} \right)\)</span>,
where</p>
<div class="math notranslate nohighlight">
\[\mathbf{\Sigma}_{x|y} = \left( \mathbf{Ⲗ}_{x} + \frac{1}{\sigma^{2}}\mathbf{a}\mathbf{1}^{T}\mathbf{1}\mathbf{a}^{T} \right)^{- 1} = \left( \mathbf{Ⲗ}_{x} + \frac{N}{\sigma^{2}}\mathbf{a}\mathbf{a}^{T} \right)^{- 1}\]
<div class="math notranslate nohighlight">
\[\mathbf{\mu}_{x|y}\mathbf{=}\mathbf{\mu}\mathbf{+}\frac{1}{\sigma^{2}}\mathbf{\Sigma}_{x|y}\mathbf{a}\mathbf{1}^{T}\left( \mathbf{y}\mathbf{-}\mathbf{1}\mathbf{a}^{T}\mathbf{\mu} - \mathbf{b} \right)\mathbf{=}\mathbf{\mu}\mathbf{+}\frac{1}{\sigma^{2}}\mathbf{\Sigma}_{x|y}\left( \mathbf{a}\mathbf{1}^{T}\mathbf{y}\mathbf{-}\mathbf{a}\mathbf{1}^{T}\mathbf{1}\mathbf{a}^{T}\mathbf{\mu} - \mathbf{a}\mathbf{1}^{T}\mathbf{b} \right)\mathbf{=}\mathbf{\mu}\mathbf{+}\frac{1}{\sigma^{2}}\mathbf{\Sigma}_{x|y}\left( \left( \sum_{i = 1}^{N}{y_{i} - b} \right)\mathbf{a}\mathbf{-}N\mathbf{a}\mathbf{a}^{T}\mathbf{\mu} \right)\]
<p>From (<em>1</em>‑<em>9</em>) we also have,</p>
<div class="math notranslate nohighlight">
\[\mathbf{\mu}_{x|y}\mathbf{=}\mathbf{\Sigma}_{x|y}\left( \mathbf{Ⲗ}_{x}\mathbf{\mu +}\frac{1}{\sigma^{2}}\mathbf{a}\mathbf{1}^{T}\left( \mathbf{y}\mathbf{-}\mathbf{b} \right) \right)\mathbf{=}\mathbf{\Sigma}_{x|y}\left( \mathbf{Ⲗ}_{x}\mathbf{\mu +}\frac{\sum_{i = 1}^{N}{y_{i} - b}}{\sigma^{2}}\mathbf{a} \right)\]
<p>As a summary,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{ \begin{matrix}
\mathbf{\mu}_{x|y}\mathbf{=}\mathbf{\mu}\mathbf{+}\frac{1}{\sigma^{2}}\mathbf{\Sigma}_{x|y}\left( \left( \sum_{i = 1}^{N}{y_{i} - b} \right)\mathbf{a}\mathbf{-}N\mathbf{a}\mathbf{a}^{T}\mathbf{\mu} \right)\mathbf{=}\mathbf{\Sigma}_{x|y}\left( \mathbf{Ⲗ}_{x}\mathbf{\mu +}\frac{\sum_{i = 1}^{N}{y_{i} - b}}{\sigma^{2}}\mathbf{a} \right) \\
\mathbf{\Sigma}_{x|y} = \left( \mathbf{Ⲗ}_{x} + \frac{N}{\sigma^{2}}\mathbf{a}\mathbf{a}^{T} \right)^{- 1} \\
\end{matrix} \right.\\end{split}\]

<div class="section" id="student-t-and-f-distribution">
<h4><strong>Student-T and F distribution</strong><a class="headerlink" href="#student-t-and-f-distribution" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="mle-map">
<h4><strong>MLE &amp; MAP</strong><a class="headerlink" href="#mle-map" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="entropy-cross-entropy">
<h4><strong>Entropy &amp; Cross-Entropy</strong><a class="headerlink" href="#entropy-cross-entropy" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="exponential-family">
<h4><strong>Exponential Family</strong><a class="headerlink" href="#exponential-family" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="linear-models">
<h3>Linear Models<a class="headerlink" href="#linear-models" title="Permalink to this headline">¶</a></h3>
<div class="section" id="linear-regression">
<h4><strong>Linear Regression</strong><a class="headerlink" href="#linear-regression" title="Permalink to this headline">¶</a></h4>
<p>We assume the data we are dealing with can be transformed or coded into
a <strong>data set</strong> <span class="math notranslate nohighlight">\(\left( \mathbf{X},\mathbf{y} \right)\)</span>, where the
<strong>data matrix</strong>
<span class="math notranslate nohighlight">\(\mathbf{X} = \left( \mathbf{x}_{1},\ldots,\mathbf{x}_{N} \right) \in \mathbb{R}^{m \times N}\)</span>
contains <span class="math notranslate nohighlight">\(m\)</span>-dimensional <strong>data entries</strong>, each data entry viewed
as a column vector, and the <strong>observation vector</strong> or <strong>target vector</strong>
or <strong>label vector</strong>
<span class="math notranslate nohighlight">\(\mathbf{y =}\left( y_{1},\ldots,y_{N} \right) \in \mathbb{R}^{N}\)</span>
contains <span class="math notranslate nohighlight">\(n\)</span>-dimensional corresponding <strong>properties</strong> or
<strong>labels</strong>. The <strong>data size</strong> is <span class="math notranslate nohighlight">\(N\)</span>.</p>
<p>We first introduce the <strong>deterministic regression model</strong>. The goal is
to find a <strong>regression function</strong>
<span class="math notranslate nohighlight">\(f\left( \mathbf{x} \right):\mathbb{R}^{m}\mathbb{\rightarrow R}\)</span>.
The argument <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> for <span class="math notranslate nohighlight">\(f\)</span> is named <strong>independent
variable</strong> or the <strong>explanatory variable</strong>, and the output
<span class="math notranslate nohighlight">\(\widetilde{y} = f\left( \mathbf{x} \right)\)</span> is named the
<strong>response variable</strong> or <strong>dependent variable</strong>. Input data entries
<span class="math notranslate nohighlight">\(\mathbf{X}\)</span>, the regression function generates a <strong>response
vector</strong> :math:<a href="#id23"><span class="problematic" id="id24">`</span></a>widehat{mathbf{y}} = begin{pmatrix}
{widehat{y}}_{1} \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>{widehat{y}}_{N} \
end{pmatrix} = begin{pmatrix}
fleft( mathbf{x}_{1} right) \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>fleft( mathbf{x}_{N} right) \
end{pmatrix}`. For a <strong>future variable</strong> <span class="math notranslate nohighlight">\(\mathcal{x}\)</span>, <span class="math notranslate nohighlight">\(f\)</span>
provides <strong>prediction</strong>
<span class="math notranslate nohighlight">\(\mathcal{y} = f\left( \mathcal{x} \right)\)</span>.</p>
<p>The difference between the responses and the observations,
<span class="math notranslate nohighlight">\(\mathbf{\epsilon} = \mathbf{y} - \widehat{\mathbf{y}}\)</span> is call
the <strong>error</strong> <strong>vector</strong>, some distance (very often a mathematical
<strong>metric</strong>) between the response and the observation, denoted by
<span class="math notranslate nohighlight">\(d\left( \mathbf{y},\widehat{\mathbf{y}} \right)\)</span>, is called the
<strong>error</strong>, where a typical error is the <strong>squared error</strong>
<span class="math notranslate nohighlight">\(d\left( \mathbf{y},\widehat{\mathbf{y}} \right) = \left\| \mathbf{y} - \widehat{\mathbf{y}} \right\|_{2}^{2}\)</span>,
i.e. the 2-norm of the error vector. For <strong>linear regression</strong>, a linear
regression function <span class="math notranslate nohighlight">\(f\)</span> is defined as an affine function</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\widehat{y}
= f\left( \mathbf{x}
\right) = \mathbf{w}\]</div>
<p class="last">^{T}mathbf{x +}b = mathbf{x}^{T}mathbf{
w} + b</p>
</td>
<td>&#160;</td>
<td>(2‑1)</td>
</tr>
</tbody>
</table>
<p>where <span class="math notranslate nohighlight">\(\mathbf{w}\mathbf{=}\begin{pmatrix}
w_{1} \\
\mathbf{\vdots} \\
w_{m} \\
\end{pmatrix}\)</span> is a <strong>coefficient vector</strong> or <strong>weight vector</strong>, and
<span class="math notranslate nohighlight">\(b\)</span> the <strong>bias</strong> uniquely determines the linear regression
function <span class="math notranslate nohighlight">\(f\)</span>. For the entire data set, we have</p>
<div class="math notranslate nohighlight">
\[\widehat{\mathbf{y}}\mathbf{=}f\left( \mathbf{X} \right)\mathbf{=}\mathbf{X}^{T}\mathbf{w +}b\]</div>
<p>where we put it “<span class="math notranslate nohighlight">\(\mathbf{X}^{T}\mathbf{w}\)</span>” rather than
<span class="math notranslate nohighlight">\(\mathbf{w}^{T}\mathbf{X}\)</span> to keep <span class="math notranslate nohighlight">\(\widehat{\mathbf{y}}\)</span> a
column vector.</p>
<p>Given a set of functions
<span class="math notranslate nohighlight">\(\phi_{j}\left( \mathbf{x} \right):\mathbb{R}^{m}\mathbb{\rightarrow R,}j = 1,\ldots,\mathbb{R}\)</span>,
we say they are <strong>linearly independent functions</strong> if
<span class="math notranslate nohighlight">\(\sum_{j = 1}^{M}{k_{j}\phi_{j}}\left( \mathbf{x} \right) = 0,\forall\mathbf{x} \in \mathbb{R}^{m}\)</span>
iff <span class="math notranslate nohighlight">\(k_{j} = 0,\forall j = 1,\ldots,M\)</span>, or <em>in plain words</em> any
function cannot be written as a linear combination of other functions.
In this case, the set of all linear combinations of
<span class="math notranslate nohighlight">\(\phi_{j},j = 1,\ldots,M\)</span> form a <strong>functional space</strong>, and
<span class="math notranslate nohighlight">\(\phi_{j}\)</span>s are referred to as <strong>basis functions</strong>, analogous to
the classic concept of <strong>vector space</strong> defined for real numbers. Let
<span class="math notranslate nohighlight">\(\phi\mathbf{=}\left( \phi_{1},\ldots,\phi_{M} \right)\mathbf{:}\mathbb{R}^{m} \rightarrow \mathbb{R}^{M}\)</span>,
a simple <em>example</em> of basis function is
<span class="math notranslate nohighlight">\(\phi:\mathbb{R}^{m} \rightarrow \mathbb{R}^{m + 1}\)</span> s.t.
:math:<a href="#id25"><span class="problematic" id="id26">`</span></a>phi_{j}left( mathbf{x} right) = left{ begin{matrix}
1 &amp; j = 1 \
x_{j - 1} &amp; j neq 1 \
end{matrix} right. Rightarrow phileft( mathbf{x} right) = begin{pmatrix}
1 \
x_{1} \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>x_{m} \
end{pmatrix} = begin{pmatrix}
1 \
mathbf{x} \
end{pmatrix}`; another simple example is
<span class="math notranslate nohighlight">\(\phi:\mathbb{R}^{m} \rightarrow \mathbb{R}^{m}\)</span> s.t.
:math:<a href="#id27"><span class="problematic" id="id28">`</span></a>phi_{j}left( mathbf{x} right) = x_{j}^{j} Rightarrow phileft( mathbf{x} right) = begin{pmatrix}
x_{1} \
x_{2}^{2} \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>x_{m}^{m} \
end{pmatrix}`. We can generalize (2‑1) to <strong>linear regression model</strong>,
which can be written as</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\widehat{y}
= \mathbf{w}^{T}\phi\]</div>
<p class="last">left( mathbf{x} ri
ght)mathbf{=}phi^{T
}left( mathbf{x} r
ight)mathbf{w}</p>
</td>
<td>&#160;</td>
<td>(2‑2)</td>
</tr>
</tbody>
</table>
<p>where
<span class="math notranslate nohighlight">\(\phi\mathbf{=}\left( \phi_{1},\ldots,\phi_{M} \right)\mathbf{:}\mathbb{R}^{m} \rightarrow \mathbb{R}^{M}\)</span>
are basis functions that transform <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> according to
modeling needs, and <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> becomes a coefficient vector of
size <span class="math notranslate nohighlight">\(M\)</span>. When the basis function is like
<span class="math notranslate nohighlight">\(\phi\left( \mathbf{x} \right) = \begin{pmatrix}
1 \\
\mathbf{x} \\
\end{pmatrix}\)</span>, then the linear model equals the linear regression. Of
course, (2‑2) could be non-linear in terms of <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, but is
linear in terms of <span class="math notranslate nohighlight">\(\phi\left( \mathbf{x} \right)\)</span>. For the entire
data set, we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\widehat{\m\]</div>
<p class="last">athbf{y}}mathbf{=}p
hi^{T}left( mathbf{
X} right)mathbf{w =
}mathbf{Phi}^{T}ma
thbf{w}</p>
</td>
<td>&#160;</td>
<td>(2‑3)</td>
</tr>
</tbody>
</table>
<p>where we use <span class="math notranslate nohighlight">\(\mathbf{\Phi}\)</span> to denote
<span class="math notranslate nohighlight">\(\phi^{T}\left( \mathbf{X} \right)\)</span> for simplicity. The purpose of
using basis functions is to mathematically ensure (2‑2) and (2‑3) cannot
be written as something “of smaller size”; if <span class="math notranslate nohighlight">\(\phi\)</span> is not basis
functions and contain linear dependent functions, the some columns of
<span class="math notranslate nohighlight">\(\phi\left( \mathbf{x} \right)\)</span> or <span class="math notranslate nohighlight">\(\mathbf{\Phi}^{T}\)</span> can
be trivially collapsed, and the number of weights in <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>
can be reduced. The basis functions are also widely referred to as
<strong>representations</strong> in the context of machine learning.</p>
<p>The above definitions can of course be generalized to higher-dimensional
labels
<span class="math notranslate nohighlight">\(\mathbf{Y =}\left( \mathbf{y}_{1},\ldots,\mathbf{y}_{N} \right) \in \mathbb{R}^{K \times N}\)</span>,
and then we have a weight matrix
<span class="math notranslate nohighlight">\(\mathbf{W}^{T}\mathbf{=}\begin{pmatrix}
\mathbf{w}_{1} \\
\mathbf{\vdots} \\
\mathbf{w}_{K} \\
\end{pmatrix}\mathbf{\in}\mathbb{R}^{K \times M}\)</span> and (2‑2) becomes</p>
<div class="math notranslate nohighlight">
\[\widehat{\mathbf{y}} = \mathbf{W}^{T}\phi\left( \mathbf{x} \right)\]</div>
<p>where we exchange the positions of the weights and <span class="math notranslate nohighlight">\(\phi\)</span> to keep
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{y}}\)</span> a column vector. For the entire data
matrix, we have the <strong>response matrix</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\widehat{\m\]</div>
<p class="last">athbf{Y}} = mathbf{W
}^{T}phileft( math
bf{X} right)mathbf{
=}mathbf{W}^{T}math
bf{Phi}</p>
</td>
<td>&#160;</td>
<td>(2‑4)</td>
</tr>
</tbody>
</table>
<p>and the difference between the responses and the observations
<span class="math notranslate nohighlight">\(\mathbf{Ε} = \mathbf{Y} - \widehat{\mathbf{Y}}\)</span> is an <strong>error</strong>
<strong>matrix</strong>, and some distance by
<span class="math notranslate nohighlight">\(d\left( \mathbf{Y},\widetilde{\mathbf{Y}} \right)\)</span>, is the
<strong>error</strong>, where a typical error is the <strong>squared error</strong>
<span class="math notranslate nohighlight">\(d\left( \mathbf{Y},\widetilde{\mathbf{Y}} \right) = \left\| \mathbf{Y} - \widetilde{\mathbf{Y}} \right\|_{F}^{2}\)</span>,
i.e. the Frobenius norm of the error matrix. <em>In practice</em>, very often
every <span class="math notranslate nohighlight">\(\mathbf{w}_{i}\)</span> is independently inferred; in this case, we
can solve for
<span class="math notranslate nohighlight">\({\widetilde{\mathbf{y}}}_{i}\mathbf{=}\phi^{T}\left( \mathbf{x}_{i} \right)\mathbf{w}_{i}\)</span>
for each <span class="math notranslate nohighlight">\(i = 1,\ldots,l\)</span>. This section is therefore focuses on
(2‑2) and (2‑3).</p>
<div class="section" id="lse-for-regression">
<h5>LSE for Regression<a class="headerlink" href="#lse-for-regression" title="Permalink to this headline">¶</a></h5>
<ul>
<li><p class="first">The <strong>least squared error</strong> (LSE) approach minimizes the squared
error <span class="math notranslate nohighlight">\(\left\| \mathbf{\epsilon} \right\|_{2}^{2}\)</span>. This is the
most basic and intuitive way to infer <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>. It takes
advantage of facts from linear algebra.</p>
<p><strong>Fact</strong> <strong>2‑1</strong> The <strong>Moore Penrose inverse</strong> of a real-valued
matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is defined as
<span class="math notranslate nohighlight">\(\mathbf{A}^{\dagger} = \mathbf{V}\mathbf{\Sigma}^{- 1}\mathbf{U}^{T}\)</span>
where <span class="math notranslate nohighlight">\(\mathbf{A = U\Sigma}\mathbf{V}^{T}\)</span> is the <strong>singular
value decomposition</strong> (SVD) of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>. We have
<span class="math notranslate nohighlight">\(\mathbf{A}^{\dagger} = \left( \mathbf{A}^{T}\mathbf{A} \right)^{\dagger}\mathbf{A}\)</span>.</p>
<p><strong>Fact</strong> <strong>2‑2</strong> Given a linear system
<span class="math notranslate nohighlight">\(\mathbf{\text{Ax}} = \mathbf{y}\)</span>, the best solution
<span class="math notranslate nohighlight">\(\mathbf{x}^{\mathbf{*}}\)</span> in terms of minimum squared error
<span class="math notranslate nohighlight">\(\left\| \mathbf{y} - \mathbf{A}\widetilde{\mathbf{x}} \right\|_{2}^{2}\)</span>
is <span class="math notranslate nohighlight">\(\mathbf{x}^{\mathbf{*}} = \mathbf{A}^{\dagger}\mathbf{y}\)</span>.</p>
<p><strong>Fact</strong> <strong>2‑3</strong> <span class="math notranslate nohighlight">\(\mathbf{\text{AA}}^{\dagger}\mathbf{y}\)</span> is
projecting <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> onto the column space of
<span class="math notranslate nohighlight">\(\mathbf{A}\)</span>, denoted by <span class="math notranslate nohighlight">\(C\left( \mathbf{A} \right)\)</span>,
where we note the projection is in the standard “common-sense” way
w.r.t. the standard basis and Euclidean distance. Given a linear
system <span class="math notranslate nohighlight">\(\mathbf{\text{Ax}} = \mathbf{y}\)</span> where
<span class="math notranslate nohighlight">\(\mathbf{y} \in C\left( \mathbf{A} \right)\)</span>, the solution is
exactly <span class="math notranslate nohighlight">\(\mathbf{x} = \mathbf{A}^{\dagger}\mathbf{y}\)</span>. This is
because <span class="math notranslate nohighlight">\(\mathbf{A}\mathbf{A}^{\dagger}\mathbf{y}\)</span> projects
<span class="math notranslate nohighlight">\(\mathbf{y}\)</span> to the space where it already resides, and thus
<span class="math notranslate nohighlight">\(\mathbf{A}\mathbf{A}^{\dagger}\mathbf{y = y}\)</span>, and then
<span class="math notranslate nohighlight">\(\mathbf{\text{Ax}} = \mathbf{A}\mathbf{A}^{\dagger}\mathbf{y = y}\)</span>
holds exactly.</p>
<p><strong>Fact</strong> <strong>2‑4</strong>
<span class="math notranslate nohighlight">\(C\left( \mathbf{A} \right) = C\left( \mathbf{A}\mathbf{A}^{T} \right)\)</span>
for any real-valued matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>. This can be easily
proved by SVD of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>, or can also be proved by showing
the null space of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is identical to the null space
of <span class="math notranslate nohighlight">\(\mathbf{A}\mathbf{A}^{T}\)</span>.</p>
<p><strong>Theorem</strong> <strong>2‑1</strong><strong>LSE for Regression</strong>. The best regression for
<span class="math notranslate nohighlight">\(\mathbf{y} = \mathbf{\Phi}^{T}\mathbf{w}\)</span> in terms of LSE is
defined by
<span class="math notranslate nohighlight">\(\mathbf{w}^{\mathbf{*}} = \left( \mathbf{\Phi}^{T} \right)^{\dagger}\mathbf{y}\)</span>,
which immediately follows from <em>Fact 2‑2</em>. The other method to derive
the same result is by taking derivative.</p>
</li>
</ul>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\left\| \ma\]</div>
<p>thbf{epsilon} right
|_{2}^{2} = sum_{i
= 1}^{N}left( y_{i}
- {widetilde{y}}_{i}</p>
<blockquote>
<div>right)^{2} = sum_{</div></blockquote>
<p class="last">i = 1}^{N}left( y_{i
} - phi^{T}left( m
athbf{x}_{i} right)mathbf{w} right)^{2}</p>
</td>
<td>&#160;</td>
<td>(2‑5)</td>
</tr>
</tbody>
</table>
<p>Then by <strong>chain rule</strong> and <em>Fact 1‑1</em>,</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\nabla_{\mathbf{w}}\lef\]</div>
<p>t| mathbf{epsilon} right|_{2
}^{2} = sum_{i = 1}^{N}{2left(
y_{i} - phi^{T}left( mathbf{x}
_{i} right)mathbf{w} right)le
ft( - phileft( mathbf{x}_{i} right) right)} = 2left( sum_{i</p>
<blockquote>
<div>= 1}^{N}{phi^{T}left( mathbf{</div></blockquote>
<p>x}_{i} right)mathbf{w}phi_{j}left( mathbf{x}_{i} right)} - sum_{i = 1}^{N}{y_{i}phileft( mathbf{x}_{i} right)} right)ma
thbf{Rightarrow}nabla_{mathbf{
w}}left| mathbf{epsilon} rig
ht|_{2}^{2} = 2left( phileft(</p>
<blockquote>
<div>mathbf{X} right)phi^{T}left(
mathbf{X} right)mathbf{w -}p</div></blockquote>
<p class="last">hileft( mathbf{X} right)mathb
f{y} right) = 0 Rightarrow nab
la_{mathbf{w}}left| mathbf{e
psilon} right|_{2}^{2} = 2left
( mathbf{Phi}mathbf{Phi}^{T}mathbf{w - Phi y} right) = 0 R
ightarrow mathbf{text{Φy}} = m
athbf{Phi}mathbf{Phi}^{T}math
bf{w}</p>
</td>
<td>(2‑6)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>We can also directly use</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\left\| \mathbf{\epsilon} \right\|_{2}^{2} = \mathbf{\epsilon}^{T}\mathbf{\epsilon =}\left( \mathbf{y}\mathbf{-}\mathbf{\Phi}^{T}\mathbf{w} \right)^{T}\left( \mathbf{y}\mathbf{-}\mathbf{\Phi}^{T}\mathbf{w} \right)\mathbf{\propto}\mathbf{w}^{T}\mathbf{\Phi}\mathbf{\Phi}^{T}\mathbf{w -}\mathbf{y}^{T}\mathbf{\Phi}^{T}\mathbf{w -}\mathbf{w}^{T}\mathbf{\text{Φy}}\\Then apply *Fact 1‑1* and *Fact 1‑4*, and have the following which is
the same as (2‑6)\end{aligned}\end{align} \]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\nabla_{\mathbf{w}}\left\| \mathbf{\epsilon} \right\|_{2}^{2} = 2\mathbf{\Phi}\mathbf{\Phi}^{T}\mathbf{w}\mathbf{- 2}\mathbf{\Phi y = 0}\mathbf{\Rightarrow}\mathbf{\text{Φy}} = \mathbf{\Phi}\mathbf{\Phi}^{T}\mathbf{w}\\Note :math:`\mathbf{\text{Φy}} \in C\left( \mathbf{\Phi} \right)`,
and
:math:`C\left( \mathbf{\Phi} \right) = C\left( \mathbf{\Phi}\mathbf{\Phi}^{T} \right) \Rightarrow \mathbf{\Phi y \in}C\left( \mathbf{\Phi}\mathbf{\Phi}^{T} \right)`
by *Fact 2‑4*, which gives the following by first applying *Fact 2‑3*
and then *Fact 2‑1*,\end{aligned}\end{align} \]</div>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{w}^\]</div>
<p class="last">{mathbf{*}}mathbf{=
}left( mathbf{Phi}
mathbf{Phi}^{T} ri
ght)^{dagger}mathbf
{text{Φy}} = left(
mathbf{Phi}^{T} ri
ght)^{dagger}mathbf
{y =}left( mathbf{Phi}^{dagger} right
)^{T}mathbf{y}</p>
</td>
<td>&#160;</td>
<td>(2‑7)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>And the regression function is thus</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}f\left( \mathbf{x} \right) = \phi^{T}\left( \mathbf{x} \right)\mathbf{w}^{*}\\\begin{split}**The special case** when
:math:`\phi\left( \mathbf{x} \right) = \begin{pmatrix}
1 \\
\mathbf{x} \\
\end{pmatrix}`, :math:`\mathbf{\Phi} ≔ \begin{pmatrix}
\mathbf{1}^{T} \\
\mathbf{X} \\
\end{pmatrix}` and :math:`\mathbf{w} ≔ \begin{pmatrix}
w_{0} \\
\mathbf{w} \\
\end{pmatrix}`, we have\end{split}\end{aligned}\end{align} \]</div>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\left\| \mathbf{\e\]</div>
<p>psilon} right|_{2}^
{2} = sum_{i = 1}^{N
}left( y_{i} - {wid
etilde{y}}_{i} right
)^{2} = sum_{i = 1}^
{N}left( y_{i} - le
ft( 1mathbf{,}mathb
f{x}_{i}^{T} right)begin{pmatrix}</p>
<blockquote>
<div>w_{0} \
mathbf{w} \
end{pmatrix} rig</div></blockquote>
<p>ht)^{2} = sum_{i = 1
}^{N}left( y_{i} - w
_{0}mathbf{-}mathbf
{x}_{i}^{T}mathbf{w}</p>
<blockquote>
<div>right)^{2} Rightar</div></blockquote>
<p>row nabla_{w_{0}}le
ft| mathbf{epsilon
} right|_{2}^{2} =
- 2sum_{i = 1}^{N}l
eft( y_{i} - w_{0}ma
thbf{-}mathbf{x}_{i}
^{T}mathbf{w} right
) = 0 Rightarrow su
m_{i = 1}^{N}y_{i} =
sum_{i = 1}^{N}w_{0}</p>
<blockquote>
<div><ul class="simple">
<li>sum_{i = 1}^{N}{</li></ul></blockquote>
<p class="last">mathbf{x}_{i}^{T}mat
hbf{w}} Rightarrow mathbf{1}^{T}mathbf{
y}mathbf{=}Nw_{0} +
mathbf{1}^{T}mathbf
{X}^{T}mathbf{w}</p>
</td>
<td>&#160;</td>
<td>(2‑8)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>Or we can also achieve this by</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\begin{pmatrix}
\mathbf{1}^{T} \\
\mathbf{X} \\
\end{pmatrix}\mathbf{y} = \begin{pmatrix}
\mathbf{1}^{T} \\
\mathbf{X} \\
\end{pmatrix}\left( \mathbf{1,}\mathbf{X}^{T} \right)\begin{pmatrix}
w_{0} \\
\mathbf{w} \\
\end{pmatrix} \Rightarrow \begin{pmatrix}
\mathbf{1}^{T}\mathbf{y} \\
\mathbf{\text{Xy}} \\
\end{pmatrix} = \begin{pmatrix}
\mathbf{1}^{T}\mathbf{1} &amp; \mathbf{1}^{T}\mathbf{X}^{T} \\
\mathbf{X}\mathbf{1} &amp; \mathbf{X}\mathbf{X}^{T} \\
\end{pmatrix}\begin{pmatrix}
w_{0} \\
\mathbf{w} \\
\end{pmatrix} = \begin{pmatrix}
Nw_{0} + \mathbf{1}^{T}\mathbf{X}^{T}\mathbf{w} \\
w_{0}\mathbf{X}\mathbf{1 +}\mathbf{X}\mathbf{X}^{T}\mathbf{w} \\
\end{pmatrix} \Rightarrow \left\{ \begin{matrix}
\mathbf{1}^{T}\mathbf{y}\mathbf{=}Nw_{0} + \mathbf{1}^{T}\mathbf{X}^{T}\mathbf{w} \\
\mathbf{Xy =}w_{0}\mathbf{X}\mathbf{1 +}\mathbf{X}\mathbf{X}^{T}\mathbf{w} \\
\end{matrix} \right.\\end{split}\\Let
:math:`\overline{y} = \frac{\mathbf{1}^{T}\mathbf{y}}{N},\overline{\mathbf{x}} = \frac{\mathbf{X}\mathbf{1}}{N}`,
then we have\end{aligned}\end{align} \]</div>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\overline{y\]</div>
<p class="last">}mathbf{=}w_{0} + {overline{mathbf{x}}}
^{T}mathbf{w Righta
rrow}w_{0}^{*} = ove
rline{y} - {overline
{mathbf{x}}}^{T}mat
hbf{w}</p>
</td>
<td>&#160;</td>
<td>(2‑9)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>For <span class="math notranslate nohighlight">\(\mathbf{w}^{\mathbf{*}}\)</span>, instead of plugging
<span class="math notranslate nohighlight">\(w_{0}^{*}\)</span> of (2‑9) into the second equation
“<span class="math notranslate nohighlight">\(\mathbf{Xy =}w_{0}\mathbf{X}\mathbf{1 +}\mathbf{X}\mathbf{X}^{T}\mathbf{w}\)</span>”,
a trick is used to simplify the calculation. Let
<span class="math notranslate nohighlight">\(\overline{\mathbf{y}} = \overline{y}\mathbf{1}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{1}{\overline{\mathbf{x}}}^{T}\mathbf{=}{\overline{\mathbf{X}}}^{T}\)</span>
where every column of <span class="math notranslate nohighlight">\(\overline{\mathbf{X}}\)</span> is the mean
<span class="math notranslate nohighlight">\(\overline{\mathbf{x}}\)</span>, then</div></blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{y}\mathbf{\]</div>
<p>-}mathbf{Phi}^{T}m
athbf{w = y}mathbf{-
}left( mathbf{1,}m
athbf{X}^{T} right)begin{pmatrix}</p>
<blockquote>
<div>w_{0} \
mathbf{w} \
end{pmatrix}math</div></blockquote>
<p>bf{=}mathbf{y} - w_{
0}mathbf{1} - mathb
f{X}^{T}mathbf{w}ma
thbf{=}mathbf{y} - left( overline{y} -
{overline{mathbf{x}
}}^{T}mathbf{w} rig
ht)mathbf{1} - math
bf{X}^{T}mathbf{w}m
athbf{= y} - overlin
e{mathbf{y}} + math
bf{1}{overline{math
bf{x}}}^{T}mathbf{w}</p>
<blockquote>
<div><ul class="simple">
<li>mathbf{X}^{T}mat</li></ul></blockquote>
<p class="last">hbf{w}mathbf{=}left
( mathbf{y} - overl
ine{mathbf{y}} righ
t)mathbf{-}left( m
athbf{X}mathbf{-}ov
erline{mathbf{X}} r
ight)^{T}mathbf{w}</p>
</td>
<td>&#160;</td>
<td>(2‑10)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>Let
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{X}} = \mathbf{X}\mathbf{-}\overline{\mathbf{X}}\)</span>
and
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{y}} = \mathbf{y} - \overline{\mathbf{y}}\)</span>,
then
<span class="math notranslate nohighlight">\(\left( \widetilde{\mathbf{X}},\widetilde{\mathbf{y}} \right)\)</span>
is called <strong>centralized data</strong>, and by above (2‑10) and then (2‑6) we
have</div></blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td colspan="2"><div class="first math notranslate nohighlight">
\[\mathbf{y}\ |\]</div>
<p class="last">mathbf{-}mathbf{Phi |
}^{T}mathbf{w =}wid |
etilde{mathbf{y}}ma |
thbf{-}{widetilde{m |
athbf{X}}}^{T}mathbf |
{w}mathbf{Rightarro |
w}left| mathbf{ep |
silon} right|_{2}^{ |
2} = left( widetild |
e{mathbf{y}}mathbf{ |
-}{widetilde{mathbf |
{X}}}^{T}mathbf{w} |
right)^{T}left( wid |
etilde{mathbf{y}}ma |
thbf{-}{widetilde{m |
athbf{X}}}^{T}mathbf |
{w} right)mathbf{R |
ightarrow}nabla_{ma |
thbf{w}}left| math |
bf{epsilon} right| |
_{2}^{2} = 2left( w |
idetilde{mathbf{X}}{ |
widetilde{mathbf{X} |
}}^{T}mathbf{w -}wi |
detilde{mathbf{X}}w |
idetilde{mathbf{y}}  |
right) = 0mathbf{R |
ightarrow}mathbf{w}^ |
{mathbf{*}}mathbf{= |
}left( widetilde{m |
athbf{X}}{widetilde{ |
mathbf{X}}}^{T} rig |
ht)^{dagger}widetil |
de{mathbf{X}}mathbf |
{y =}left. （operato |
rname{cov}mathbf{X}  |
right.）^{dagger}wi |
detilde{mathbf{X}}m |
athbf{y}mathbf{=}le |
ft( {widetilde{math |
bf{X}}}^{T} right)^{ |
dagger}widetilde{m |
athbf{y}}mathbf{=}l |
eft( {widetilde{mat |
hbf{X}}}^{dagger} r |
ight)^{T}widetilde{|
mathbf{y}}mathbf{Ri |
ghtarrow}w_{0}^{*} =  |
overline{y} - {over |
line{mathbf{x}}}^{T} |
mathbf{w}^{mathbf{* |
}}                    |</p>
</td>
<td>(2‑11)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>where we <em>note</em>
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{X}}{\widetilde{\mathbf{X}}}^{T}\mathbf{=}\operatorname{cov}\mathbf{X}\)</span>
is the covariance matrix of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>. We then have the
regression function as</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}g\left( \mathbf{x} \right) = \mathbf{x}^{T}\mathbf{w}^{*} + w_{0}^{*} = {\widetilde{\mathbf{x}}}^{T}\mathbf{w}^{*} + \overline{y}\\We should note two key *limitations* of LSE. 1) it is not robust and
high sensitive to outliers, which can be seem from its objective: the
error is squared, and if there are outliers that introduce large
squares, then :math:`\mathbf{w}^{*}` will be skewed to reduce the
impact of the outlier; 2) overfitting when data is insufficient
represent all possible case, then the inferred :math:`\mathbf{w}^{*}`
could have small error for known data, but poor for prediction. Both
problems are mediated by regularization or assign priors that we show
later.\end{aligned}\end{align} \]</div>
</div>
<div class="section" id="gaussian-ml">
<h5>Gaussian ML<a class="headerlink" href="#gaussian-ml" title="Permalink to this headline">¶</a></h5>
<ul>
<li><p class="first"><strong>Theorem</strong> <strong>2‑2</strong><strong>Gaussian ML</strong>. Under Gaussian maximum
likelihood, the variance is the mean LSE, and optimal weights is the
same as that inferred from LSE.</p>
<p>This approach is a simple generalization of least square, it keeps
the result <span class="math notranslate nohighlight">\(\mathbf{w}^{\mathbf{*}}\)</span> as in (2‑7) (so it keeps
the same limitations of LSE), and in addition finds “error variance”
under Gaussian assumption. It <em>assumes</em> each observation
<span class="math notranslate nohighlight">\(y_{i},i = 1,\ldots,N\)</span> is the
response&nbsp;<span class="math notranslate nohighlight">\({\widetilde{y}}_{i}\)</span> plus i.i.d. independent
Gaussian random error <span class="math notranslate nohighlight">\(\epsilon_{i}\)</span> with zero mean and some
variance <span class="math notranslate nohighlight">\(\sigma^{2}\)</span>, i.e.
<span class="math notranslate nohighlight">\(y_{i}\sim\text{Gaussian}\left( {\widetilde{y}}_{i},\sigma^{2} \right)\)</span>
or
<span class="math notranslate nohighlight">\(\epsilon_{i} = y_{i} - {\widetilde{y}}_{i}\sim\text{Gaussian}\left( 0,\sigma^{2} \right)\)</span>.
Note two assumptions are made here, 1) one point of this assumption
is the error is unimodal; 2) errors for each observation are i.i.d.
The probability of observing <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> is therefore</p>
</li>
</ul>
<div class="math notranslate nohighlight">
\[p\left( \mathbf{y} \right) = \prod_{i = 1}^{N}{\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left\{ - \frac{\left( y_{i} - {\widetilde{y}}_{i} \right)^{2}}{2\sigma^{2}} \right\}}\]</div>
<p>And the goal is to maximize <span class="math notranslate nohighlight">\(p\)</span>. Taking logarithm, we have</p>
<div class="math notranslate nohighlight">
\[\ln p = \sum_{i = 1}^{N}{\ln\frac{1}{\sqrt{2\pi\sigma^{2}}} - \frac{\left( y_{i} - {\widetilde{y}}_{i} \right)^{2}}{2\sigma^{2}}} = - \frac{N}{2}\ln{2\pi\sigma^{2}} - \frac{1}{2\sigma^{2}}\sum_{i = 1}^{N}\left( y_{i} - {\widetilde{y}}_{i} \right)^{2} \propto \frac{N}{2}\ln\frac{1}{\sigma^{2}} - \frac{1}{2\sigma^{2}}\left\| \mathbf{\epsilon} \right\|_{2}^{2}\]</div>
<p>For convenience, denote <span class="math notranslate nohighlight">\(\beta = \sigma^{- 2}\)</span> where <span class="math notranslate nohighlight">\(\beta\)</span>
is the precision, and
<span class="math notranslate nohighlight">\(\ln p \propto N\ln\beta - \beta\left\| \mathbf{\epsilon} \right\|_{2}^{2}\)</span>.
Note only <span class="math notranslate nohighlight">\(\mathbf{\epsilon}\)</span> is dependent on <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>,
thus finding optimal <span class="math notranslate nohighlight">\(\mathbf{w}^{*}\)</span> is exactly the same as
solving least squared error; from the proof of <em>Theorem 2‑1</em>, we have
<span class="math notranslate nohighlight">\(\mathbf{w}^{\mathbf{*}}\mathbf{=}\left( \mathbf{\Phi}^{T} \right)^{\dagger}\mathbf{y}\)</span>.
Denote <span class="math notranslate nohighlight">\(\mathbf{\epsilon}^{*}\)</span> as the optimal error vector, then</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\frac{\part\]</div>
<p>ialln p}{partialbe
ta} = frac{N}{beta}</p>
<blockquote>
<div><ul class="simple">
<li>left| mathbf{e</li></ul></blockquote>
<p>psilon}^{mathbf{*}}
right|_{2}^{2} = 0
Rightarrow beta^{*}</p>
<blockquote>
<div>= frac{N}{left| </div></blockquote>
<p class="last">mathbf{epsilon}^{ma
thbf{*}} right|_{2}
^{2}} = frac{N}{lef
t| mathbf{y -}math
bf{Phi}^{T}left( m
athbf{Phi}^{T} righ
t)^{dagger}mathbf{y
} right|_{2}^{2}} Rightarrow {{(sigma}
^{2})}^{*} = frac{l
eft| mathbf{epsilo
n}^{mathbf{*}} righ
t|_{2}^{2}}{N} = fr
ac{left| mathbf{y
-}mathbf{Phi}^{T}l
eft( mathbf{Phi}^{T
} right)^{dagger}m
athbf{y} right|_{2}
^{2}}{N}</p>
</td>
<td>&#160;</td>
<td>(2‑12)</td>
</tr>
</tbody>
</table>
<p>That is, the optimal variance is the <strong>mean squared error</strong> (MSE).</p>
</div>
<div class="section" id="regularization">
<h5>Regularization<a class="headerlink" href="#regularization" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><strong>Regularization</strong>. To prevent the well-known <strong>overfitting</strong> problem
that occurs when the data size is not sufficient to well support the
regression model, one classic approach is to add <strong>regularization
function</strong> <span class="math notranslate nohighlight">\(r\left( \mathbf{w} \right)\)</span> to the regression
objective like (2‑5). A typical regularization is
<span class="math notranslate nohighlight">\(r\left( \mathbf{w} \right) = \gamma\left\| \mathbf{w} \right\|_{p}^{p}\)</span>,
where <span class="math notranslate nohighlight">\(\gamma\)</span> is a scalar controlling the strength of
regularization, and <span class="math notranslate nohighlight">\(\left\| \cdot \right\|\)</span> is the
<span class="math notranslate nohighlight">\(p\)</span>-<strong>norm</strong> of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>, e.g. in the case of
<span class="math notranslate nohighlight">\(r\left( \mathbf{w} \right) = \gamma\left\| \mathbf{w} \right\|_{2}^{2} = \gamma\mathbf{w}^{T}\mathbf{w}\)</span>,
(2‑5) becomes the following objective,</li>
</ul>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\operatorna\]</div>
<p class="last">me{}L = operatorname
{}left( frac{1}{2}left| mathbf{epsil
on} right|_{2}^{2}
+ gammamathbf{w}^{T
}mathbf{w} right)</p>
</td>
<td>&#160;</td>
<td>(2‑13)</td>
</tr>
</tbody>
</table>
<p>Applying (<em>2</em>‑<em>6</em>) to the squared error, and gradient rule <em>Fact
1‑4</em> to the regularization, and note
<span class="math notranslate nohighlight">\(\mathbf{\Phi}\mathbf{\Phi}^{T}\mathbf{+}\gamma\mathbf{I}\)</span> must be
invertible because it is positive definite (a sum of a positive
semidefinite matrix <span class="math notranslate nohighlight">\(\mathbf{\Phi}\mathbf{\Phi}^{T}\)</span> and a
positive definite matrix <span class="math notranslate nohighlight">\(\mathbf{I}\)</span>), then we have</p>
<div class="math notranslate nohighlight">
\[\nabla_{\mathbf{w}}L \propto \mathbf{\Phi}\mathbf{\Phi}^{T}\mathbf{w - \Phi y} + \gamma\mathbf{w} = \mathbf{0}\mathbf{\Rightarrow \Phi y} = \left( \mathbf{\Phi}\mathbf{\Phi}^{T}\mathbf{+}\gamma\mathbf{I} \right)\mathbf{w}\mathbf{\Rightarrow}\mathbf{w}^{*}\mathbf{=}\left( \mathbf{\Phi}\mathbf{\Phi}^{T}\mathbf{+}\gamma\mathbf{I} \right)^{- 1}\mathbf{\text{Φy}}\]</div>
<p><em>Note</em> <span class="math notranslate nohighlight">\(\gamma\)</span> has to be pre-defined, and there is no way to
optimize it in terms of (<em>2</em>‑<em>13</em>) or other <span class="math notranslate nohighlight">\(p\)</span>-norm, simply
because
<span class="math notranslate nohighlight">\(\frac{\partial L}{\partial\gamma} = \mathbf{w}^{T}\mathbf{w} \neq 0\)</span>
unless <span class="math notranslate nohighlight">\(\mathbf{w = 0}\)</span>.</p>
</div>
<div class="section" id="gaussian-map">
<h5>Gaussian MAP<a class="headerlink" href="#gaussian-map" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><strong>Theorem</strong> <strong>2‑3</strong><strong>Gaussian MAP</strong>. Based on above, we can further
assume a prior distribution over <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> and use maximum a
posteriori technique. Based on the Gaussian ML in <em>Theorem 2‑2</em>,
besides
<span class="math notranslate nohighlight">\(y_{i}|\mathbf{w}\sim\text{Gaussian}\left( \phi^{T}\left( \mathbf{x}_{i} \right)\mathbf{w},\sigma^{2} \right)\)</span>
and <span class="math notranslate nohighlight">\(\beta = \sigma^{- 2}\)</span> is the precision, we assume a
Gaussian prior over the weight
<span class="math notranslate nohighlight">\(\mathbf{w}\sim\operatorname{Gaussian}\left( \mathbf{w}|\mathbf{\mu}_{\mathbf{w}},\mathbf{\Sigma}_{\mathbf{w}} \right)\)</span>
with pre-defined parameters
<span class="math notranslate nohighlight">\(\mathbf{\mu}_{\mathbf{w}},\mathbf{\Sigma}_{\mathbf{w}}\)</span>, then</li>
</ul>
<div class="math notranslate nohighlight">
\[L_{\mathbf{w}|\mathbf{y}} \propto \ln{p\left( \mathbf{y}|\mathbf{w} \right)} + \ln{p\left( \mathbf{w} \right)} = \sum_{i = 1}^{N}{\ln{p\left( y_{i}|\mathbf{w} \right)}} + \ln{p\left( \mathbf{w} \right)} \propto \frac{N}{2}\ln\frac{1}{\sigma^{2}} - \frac{1}{2\sigma^{2}}\left( \sum_{i = 1}^{N}\left( y_{i} - \phi^{T}\left( \mathbf{x}_{i} \right)\mathbf{w} \right)^{2} \right) - \frac{1}{2}\left( \mathbf{w -}\mathbf{\mu}_{\mathbf{w}} \right)^{T}\mathbf{\Sigma}_{\mathbf{w}}^{- 1}\left( \mathbf{w -}\mathbf{\mu}_{\mathbf{w}} \right)\mathbf{=}\frac{N}{2}\ln\frac{1}{\sigma^{2}} - \frac{1}{2\sigma^{2}}\left\| \mathbf{\epsilon} \right\|_{2}^{2} - \frac{1}{2}\left( \mathbf{w -}\mathbf{\mu}_{\mathbf{w}} \right)^{T}\mathbf{\Sigma}_{\mathbf{w}}^{- 1}\left( \mathbf{w -}\mathbf{\mu}_{\mathbf{w}} \right)\]</div>
<p>where the choice of best <span class="math notranslate nohighlight">\(\sigma^{2}\)</span> is still the MSE based on
(2‑12). The choice of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> uses objective</p>
<div class="math notranslate nohighlight">
\[\operatorname{}L = \operatorname{}\left( \frac{1}{2\sigma^{2}}\left\| \mathbf{\epsilon} \right\|_{2}^{2} + \frac{1}{2}\left( \mathbf{w}^{T}\mathbf{\Sigma}_{\mathbf{w}}^{- 1}\mathbf{w -}2\mathbf{\mu}_{\mathbf{w}}^{T}\mathbf{\Sigma}_{\mathbf{w}}^{- 1}\mathbf{w} \right) \right)\]</div>
<p>where we note <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\mathbf{w}}^{- 1}\)</span> is symmetric,
and apply (2‑6), gradient rule <em>Fact 1‑1</em>, <em>Fact 1‑4</em>, we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\nabla_{\mathbf{w}}L \p\]</div>
<p>ropto frac{1}{sigma^{2}}left(
mathbf{Phi}mathbf{Phi}^{T}ma
thbf{w - Phi y} right) + frac{
1}{2}left( mathbf{Sigma}_{mat
hbf{w}}^{- 1} + mathbf{Sigma}_{
mathbf{w}}^{- T} right)mathbf{
w} - mathbf{Sigma}_{mathbf{w}}
^{T}mathbf{mu}_{mathbf{w}} = frac{1}{sigma^{2}}left( mathbf
{Phi}mathbf{Phi}^{T}mathbf{w
- Phi y} right) + mathbf{Sigm
a}_{mathbf{w}}^{- 1}mathbf{w} -</p>
<blockquote>
<div>mathbf{Sigma}_{mathbf{w}}^{-</div></blockquote>
<p>1}mathbf{mu}_{mathbf{w}}mathb
f{= 0}mathbf{Rightarrow}frac{1
}{sigma^{2}}mathbf{Phi y +}ma
thbf{Sigma}_{mathbf{w}}^{- 1}m
athbf{mu}_{mathbf{w}}mathbf{=}
frac{1}{sigma^{2}}mathbf{Phi}
mathbf{Phi}^{T}mathbf{w +}mat
hbf{Sigma}_{mathbf{w}}^{- 1}ma
thbf{w}mathbf{Rightarrow}mathb
f{w}^{mathbf{*}}mathbf{=}left(</p>
<blockquote>
<div>mathbf{Phi}mathbf{Phi}^{T}m</div></blockquote>
<p class="last">athbf{+}sigma^{2}mathbf{Sigma}
_{mathbf{w}}^{- 1} right)^{- 1}
left( mathbf{Phi y +}sigma^{2
}mathbf{Sigma}_{mathbf{w}}^{-
1}mathbf{mu}_{mathbf{w}} righ
t)mathbf{=}left( betamathbf{Phi}mathbf{Phi}^{T}mathbf{+}m
athbf{Sigma}_{mathbf{w}}^{- 1}
right)^{- 1}left( betamathbf{
Phi y +}mathbf{Sigma}_{mathbf
{w}}^{- 1}mathbf{mu}_{mathbf{w
}} right)</p>
</td>
<td>(2‑14)</td>
</tr>
</tbody>
</table>
<p>MAP (and the Bayesian inference to be discussed) is smoothing the
parameter inference and hence making up for overfitting and outliers, as
we can see from above that it supplements the distribution of
<span class="math notranslate nohighlight">\(\mathbf{w}\)</span>, which provides predefined information for
<span class="math notranslate nohighlight">\(\mathbf{w}\)</span> especially for the case when the data is
insufficient.</p>
<blockquote>
<div><strong>Example</strong> <strong>2‑1</strong>. Assume
<span class="math notranslate nohighlight">\(\mathbf{w}\sim\operatorname{Gaussian}\left( \mathbf{w}|\mathbf{0},\varsigma^{2}\mathbf{I} \right)\)</span>
and
<span class="math notranslate nohighlight">\(y_{i}|\mathbf{w}\sim Gaussian\left( \phi^{T}\left( \mathbf{x}_{i} \right)\mathbf{w},\sigma^{2} \right)\)</span>,
and let <span class="math notranslate nohighlight">\(\alpha = \varsigma^{- 2},\beta = \sigma^{- 2}\)</span> be the
precisions, then the MAP objective for <span class="math notranslate nohighlight">\(\mathbf{y}|\mathbf{w}\)</span>
is <span class="math notranslate nohighlight">\(\operatorname{}L_{\mathbf{w}|\mathbf{y}}\)</span> where</div></blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[L_{\mathbf{\]</div>
<p>w}|mathbf{y}} propt
o ln{pleft( mathbf
{y}|mathbf{w} right
)} + ln{pleft( mat
hbf{w} right)} prop
to - frac{1}{2sigma
^{2}}left| mathbf{
epsilon} right|_{2
}^{2} - frac{1}{2va
rsigma^{2}}mathbf{w}
^{T}mathbf{w}mathbf
{Rightarrow}nabla_{
mathbf{w}}L propto
frac{1}{sigma^{2}}left( mathbf{Phi}m
athbf{Phi}^{T}mathb
f{w - Phi y} right)</p>
<blockquote>
<div><ul class="simple">
<li>frac{1}{varsigma</li></ul></blockquote>
<p>^{2}}mathbf{w}mathb
f{=}0mathbf{Rightar
row}mathbf{w}^{math
bf{*}}mathbf{=}left
( mathbf{Phi}mathb
f{Phi}^{T}mathbf{+}
frac{sigma^{2}}{va
rsigma^{2}}mathbf{I}</p>
<blockquote>
<div>right)^{- 1}mathbf</div></blockquote>
<p class="last">{Phi y =}left( mat
hbf{Phi}mathbf{Phi
}^{T}mathbf{+}frac{
alpha}{beta}mathbf
{I} right)^{- 1}mat
hbf{text{Φy}}</p>
</td>
<td>&#160;</td>
<td>(2‑15)</td>
</tr>
</tbody>
</table>
<p>which is equivalent to minimizing the regularized least square in (2‑13)
with <span class="math notranslate nohighlight">\(\gamma = \frac{\sigma^{2}}{\varsigma^{2}}\)</span>. This illustrates
the idea that MAP is a generalized regularization.</p>
<p>In contrast to deterministic regression which finds a determined
regression function <span class="math notranslate nohighlight">\(f\)</span>, a <strong>probabilistic regression model</strong>
constructs a conditional probability distribution
<span class="math notranslate nohighlight">\(p_{\mathbf{X},\mathbf{y}}\left( \mathcal{y}\mathcal{|x} \right)\)</span>
for the property <span class="math notranslate nohighlight">\(\mathcal{y}\)</span> of a future variable
<span class="math notranslate nohighlight">\(\mathcal{x}\)</span>, where <span class="math notranslate nohighlight">\(p_{\mathbf{X},\mathbf{y}}\)</span> is inferred
based on data <span class="math notranslate nohighlight">\(\left( \mathbf{X},\mathbf{y} \right)\)</span>. Here,
<span class="math notranslate nohighlight">\(p_{\mathbf{X},\mathbf{y}}\left( \mathcal{y}\mathcal{|x} \right)\)</span>
is also named the <strong>predictive distribution</strong>, and we use another
notation
<span class="math notranslate nohighlight">\(p\left( \mathcal{y|x,}\mathbf{y} \right) ≔ p_{\mathbf{X},\mathbf{y}}\left( \mathcal{y|x} \right)\)</span>
(omits <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>) in future discussion for better arithmetic
consistency. At this moment, our probabilistic regression is built upon
the Bayesian inference, which assumes prior distributions for
parameters, e.g. prior distributions over <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> for
Gaussian MAP like in <em>Theorem 2‑3</em>.</p>
</div>
<div class="section" id="gaussian-bayesian-regression">
<h5>Gaussian Bayesian regression<a class="headerlink" href="#gaussian-bayesian-regression" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><strong>Theorem</strong> <strong>2‑4</strong><strong>Gaussian Bayesian Regression</strong>. This is the
most basic Bayesian inference for Gaussian regression. Assume</li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{w}\sim\operatorname{Gaussian}\left( \mathbf{w}|\mathbf{\mu}_{\mathbf{w}},\mathbf{\Sigma}_{\mathbf{w}} \right)\]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}y_{i}|\mathbf{w}\sim\text{Gaussian}\left( \phi^{T}\left( \mathbf{x}_{i} \right)\mathbf{w},\sigma^{2} \right),\beta = \sigma^{- 2}\\where however :math:`\sigma^{2}` has to predefined. Then by *Theorem
1‑8*, especially (1‑8) and (1‑9), we have
:math:`\mathbf{w}|\mathbf{y}\sim\operatorname{Gaussian}\left( \mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{,}\mathbf{\Sigma}_{\mathbf{w}|\mathbf{y}} \right)`
where\end{aligned}\end{align} \]</div>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\left\{ \begin{mat\]</div>
<dl class="docutils">
<dt>rix}</dt>
<dd>mathbf{mu}_{mat</dd>
</dl>
<p>hbf{w}|mathbf{y}}ma
thbf{=}mathbf{mu}_{
mathbf{w}}mathbf{+}
betamathbf{Sigma}_
{mathbf{w}|mathbf{y
}}mathbf{Phi}left(</p>
<blockquote>
<div>mathbf{y}mathbf{-}</div></blockquote>
<p>mathbf{Phi}^{T}mat
hbf{mu}_{mathbf{w}}</p>
<blockquote>
<div>right)mathbf{=}ma</div></blockquote>
<p>thbf{Sigma}_{mathbf
{w}|mathbf{y}}left(</p>
<blockquote>
<div>mathbf{Sigma}_{ma</div></blockquote>
<p>thbf{w}}^{- 1}mathbf
{mu}_{mathbf{w}}ma
thbf{+}betamathbf{Phi}mathbf{y} right
) \</p>
<blockquote>
<div>mathbf{Sigma}_{</div></blockquote>
<p>mathbf{w}|mathbf{y}}
mathbf{=}left( mat
hbf{Sigma}_{mathbf{
w}}^{- 1}mathbf{+}b
etamathbf{Phi}math
bf{Phi}^{T} right)^
{- 1} \</p>
<blockquote>
<div>end{matrix} righ</div></blockquote>
<p class="last">t.</p>
</td>
<td>&#160;</td>
<td>(2‑16)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>Note plug <span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{\mathbf{w}|\mathbf{y}}\)</span> into
<span class="math notranslate nohighlight">\(\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\)</span> and we have</div></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\left( \mathbf{\Sigma}_{\mathbf{w}}^{- 1}\mathbf{+}\beta\mathbf{\Phi}\mathbf{\Phi}^{T} \right)^{- 1}\left( \mathbf{\Sigma}_{\mathbf{w}}^{- 1}\mathbf{\mu}_{\mathbf{w}}\mathbf{+}\beta\mathbf{\Phi}\mathbf{y} \right)\\which is identical to :math:`\mathbf{w}^{*}` in (2‑14). The solution
of Gaussian MAP now becomes the mean of the posterior, and from this
point of view Gaussian Bayesian can be viewed as extension of
Gaussian MAP.\\Then one approach to derive the predictive distribution is to first
find the joint distribution
:math:`p\left( \mathcal{y,}\mathbf{w|}\mathcal{x,}\mathbf{y} \right)`,
and then find the marginal\end{aligned}\end{align} \]</div>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[p\left( \ma\]</div>
<p>thcal{y|}mathcal{x,}
mathbf{y} right) =
int_{}^{}{pleft( m
athcal{y,}mathbf{w|}
mathcal{x,}mathbf{y
} right)dmathbf{w}}</p>
<blockquote>
<div>= int_{}^{}{pleft(
mathcal{y|}mathbf{</div></blockquote>
<p class="last">w,}mathcal{x,}mathb
f{y} right)pleft( mathbf{w|}mathcal{x,
}mathbf{y} right)dmathbf{w}}</p>
</td>
<td>&#160;</td>
<td>(2‑17)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>For the Gaussian Bayesian regression, (2‑17) can be solved using
<em>Theorem 1‑8</em> without actual integration. We have
<span class="math notranslate nohighlight">\(\mathbf{w|y\sim}\operatorname{Gaussian}\left( \mathbf{\mu}_{w|y}\mathbf{,}\Sigma_{\mathbf{w}|\mathbf{y}} \right)\)</span>
and
<span class="math notranslate nohighlight">\(\mathcal{y|}\mathbf{w,}\mathcal{x,}\mathbf{y\sim}\text{Gaussian}\left( \phi^{T}\left( \mathcal{x} \right)\mathbf{w},\sigma^{2} \right)\)</span>.
By <em>Theorem 1‑8</em>, we have the joint distribution is
<span class="math notranslate nohighlight">\(\mathcal{y}\mathcal{|x,}\mathbf{y}\mathbf{\sim}\operatorname{Gaussian}\left( \mu_{\mathcal{y}},\sigma_{\mathcal{y}}^{2} \right)\)</span>
where</div></blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mu_{\mathc\]</div>
<p>al{y}} = phi^{T}lef
t( mathcal{x} right
)mathbf{mu}_{mathb
f{w}|mathbf{y}},sig
ma_{mathcal{y}}^{2}
= sigma^{2}mathbf{+
}phi^{T}left( math
cal{x} right)mathbf
{Sigma}_{mathbf{w}|
mathbf{y}}phileft(</p>
<blockquote class="last">
<div>mathcal{x} right)</div></blockquote>
</td>
<td>&#160;</td>
<td>(2‑18)</td>
</tr>
</tbody>
</table>
<blockquote>
<div><p>One known <em>issue</em> of the predictive distribution define by (2‑18) is
it tends to have large variance for those <span class="math notranslate nohighlight">\(\mathcal{x}\)</span> not
near any data entries, because of no data in the neighborhood of
<span class="math notranslate nohighlight">\(\mathcal{\text{x\ }}\)</span> to provide sufficient information for
the prediction, and the issue is especially serious when the data is
sparse.</p>
<p><strong>Example</strong> <strong>2‑2</strong> Assume
<span class="math notranslate nohighlight">\(\mathbf{w}\sim\operatorname{Gaussian}\left( \mathbf{w}|\mathbf{0},\varsigma^{2}\mathbf{I} \right),\alpha = \varsigma^{- 2}\)</span>
and
<span class="math notranslate nohighlight">\(y_{i}|\mathbf{w}\sim\text{Gaussian}\left( \phi^{T}\left( \mathbf{x}_{i} \right)\mathbf{w},\sigma^{2} \right),\beta = \sigma^{- 2}\)</span>
as in Example 2‑1, we have</p>
</div></blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\left\{ \begin{mat\]</div>
<dl class="docutils">
<dt>rix}</dt>
<dd>mathbf{mu}_{mat</dd>
</dl>
<p>hbf{w}|mathbf{y}}ma
thbf{=}betamathbf{Sigma}_{mathbf{w}|m
athbf{y}}mathbf{Phi
}mathbf{y} \</p>
<blockquote>
<div>mathbf{Sigma}_{</div></blockquote>
<p>mathbf{w}|mathbf{y}}
mathbf{=}left( alp
hamathbf{I}mathbf{+
}betamathbf{Phi}m
athbf{Phi}^{T}left(</p>
<blockquote>
<div>mathbf{X} right) </div></blockquote>
<dl class="docutils">
<dt>right)^{- 1} \</dt>
<dd>end{matrix} righ</dd>
</dl>
<p class="last">t.</p>
</td>
<td>&#160;</td>
<td>(2‑19)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>Note</div></blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{\mu\]</div>
<p class="last">}_{mathbf{w}|mathbf
{y}}mathbf{=}betam
athbf{Sigma}_{mathb
f{w}|mathbf{y}}math
bf{Phi}mathbf{y =}betaleft( alphamat
hbf{I}mathbf{+}beta
mathbf{Phi}mathbf{
Phi}^{T} right)^{-
1}mathbf{Phi}mathb
f{y}mathbf{=}left(
mathbf{Phi}mathbf{
Phi}^{T}mathbf{+}f
rac{alpha}{beta}ma
thbf{I} right)^{- 1}
mathbf{text{Φy}}</p>
</td>
<td>&#160;</td>
<td>(2‑20)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>which is identical to <span class="math notranslate nohighlight">\(\mathbf{w}^{*}\)</span> in (2‑15).</div></blockquote>
</div>
<div class="section" id="model-selection">
<h5>Model selection<a class="headerlink" href="#model-selection" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><strong>Model Selection</strong>. Given a probabilistic model
<span class="math notranslate nohighlight">\(p\left( \mathbf{y}|\mathbf{\omega} \right)\)</span> where
<span class="math notranslate nohighlight">\(\mathbf{\omega}\)</span> are parameter, then the choice of
<span class="math notranslate nohighlight">\(\mathbf{\omega}\)</span> can be done by maximizing
<span class="math notranslate nohighlight">\(p\left( \mathbf{\omega}|\mathbf{y} \right)\)</span>, called the
<strong>model selection</strong>. For simplicity, we study the case of Example 2‑1
(Gaussian MAP) and Example 2‑2 (Gaussian Bayesian), i.e. assuming the
independence of components of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>,</li>
</ul>
<div class="math notranslate nohighlight">
\[\left( \alpha,\beta \right)\sim p\left( \alpha,\beta|\mathbf{y} \right)\]</div>
<div class="math notranslate nohighlight">
\[\mathbf{w}\sim\operatorname{Gaussian}\left( \mathbf{w}|\mathbf{0},\alpha^{- 1}\mathbf{I} \right),\alpha = \varsigma^{- 2}\]</div>
<div class="math notranslate nohighlight">
\[y_{i}|\mathbf{w}\sim\text{Gaussian}\left( \phi^{T}\left( \mathbf{x}_{i} \right)\mathbf{w},\beta^{- 1} \right),\beta = \sigma^{- 2}\]</div>
<p>where we use precisions <span class="math notranslate nohighlight">\(\alpha,\beta\)</span> for convenience. Note</p>
<div class="math notranslate nohighlight">
\[p\left( \alpha,\beta|\mathbf{y} \right)\mathbf{\propto}p\left( \mathbf{y}|\alpha,\beta \right)p\left( \alpha,\beta \right)\]</div>
<p>Further assume <span class="math notranslate nohighlight">\(p\left( \alpha,\beta \right)\)</span> is nearly flat and
can be treated as constant. This assumption can be justified by thinking
about there is no particular favorable choice of <span class="math notranslate nohighlight">\(\alpha,\beta\)</span>
without the data. Therefore, the model selection is equivalent to
maximizing to maximizing the evidence</p>
<div class="math notranslate nohighlight">
\[p\left( \alpha,\beta|\mathbf{y} \right)\mathbf{\propto}p\left( \mathbf{y}|\alpha,\beta \right)\]</div>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><p class="first">If we use the familiar <em>Theorem 1‑8</em> again,
<span class="math notranslate nohighlight">\(p\left( \mathbf{y}|\alpha,\beta \right)\sim\operatorname{Gauss
ian}\left( \mathbf{0},\mathbf{\Sigma}_{\mathbf{y}} \right)\)</span>,
and by (1‑10) we have</p>
<div class="math notranslate nohighlight">
\[\mathbf{\Sigma}_{\mathbf{y}} = \sigma^{2}\mathbf{I}\mathbf{\]</div>
<p>+}varsigma^{2}phi^{T}left( mathbf{X} right)mathbf{phi}left( mathbf{X} right)</p>
<p class="last">Then
<span class="math notranslate nohighlight">\(\ln p \propto \log\left| \mathbf{\Sigma}_{\mathbf{y}}^{- 1} \r
ight| - \mathbf{y}^{T}\mathbf{\Sigma}_{\mathbf{y}}^{- 1}\mathbf{y}\)</span>,
which involves matrix, making it difficult to calculate gradients
<span class="math notranslate nohighlight">\(\frac{\partial\ln p}{\partial\sigma}\)</span> and
<span class="math notranslate nohighlight">\(\frac{\partial\ln p}{\partial\varsigma}\)</span>. Thus, we turn to
another approach that integrates joint distribution
<span class="math notranslate nohighlight">\(p\left( \mathbf{y,w}|\alpha,\beta \right)\)</span>.</p>
</td>
</tr>
</tbody>
</table>
<p>It turns out direct use of (1‑10) of <em>Theorem 1‑8</em> does not yield an
easy solution, see the remark above. We instead look at</p>
<div class="math notranslate nohighlight">
\[p\left( \mathbf{y}|\alpha,\beta \right) = \int_{}^{}{p\left( \mathbf{y,w}|\alpha,\beta \right)d\mathbf{w}} = \int_{}^{}{p\left( \mathbf{y}|\mathbf{w},\beta \right)p\left( \mathbf{w}|\alpha \right)d\mathbf{w}}\]</div>
<p>Since the components of <span class="math notranslate nohighlight">\(\mathbf{y,w}\)</span> are independent, let
<span class="math notranslate nohighlight">\(M\)</span> be the size of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> as well as the number of
basis functions, then</p>
<div class="math notranslate nohighlight">
\[p\left( \mathbf{y}|\alpha,\beta \right) = \int_{}^{}{\prod_{i = 1}^{N}{p\left( y_{i}\mathbf{|w},\beta \right)}\prod_{j = 1}^{M}{p\left( w_{j}|\alpha \right)}d\mathbf{w}} = \left( \frac{\beta}{2\pi} \right)^{\frac{N}{2}}\left( \frac{\alpha}{2\pi} \right)^{\frac{M}{2}}\int_{}^{}{\exp\left\{ - \frac{1}{2}L\left( \mathbf{w} \right) \right\} d\mathbf{w}}\]</div>
<p>where by (2‑15) we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[L\left( \ma\]</div>
<p>thbf{w} right) = be
taleft( mathbf{y} -</p>
<blockquote>
<div>phi^{T}left( math</div></blockquote>
<p class="last">bf{X} right)mathbf{
w} right)^{T}left(
mathbf{y} - phi^{T}
left( mathbf{X} ri
ght)mathbf{w} right
) + alphamathbf{w}^
{T}mathbf{w}</p>
</td>
<td>&#160;</td>
<td>(2‑21)</td>
</tr>
</tbody>
</table>
<p><strong>Step 1 - Simplify the integration</strong>. The integration result does not
easily follow from the format of (2‑21). The integration is only
dependent on <span class="math notranslate nohighlight">\(\mathbf{Ⲗ}_{\mathbf{y},\mathbf{w}}\)</span> based on the
Gaussian density, and by (1‑7) we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{Ⲗ}_{\mathbf{w,y}}\mathbf{=}\begin{pmatrix}
\alpha\mathbf{I}\mathbf{+}\beta\phi\left( \mathbf{X} \right)\phi^{T}\left( \mathbf{X} \right) &amp; - \beta\phi\left( \mathbf{X} \right) \\
 - \beta\phi^{T}\left( \mathbf{X} \right) &amp; \beta\mathbf{I} \\
\end{pmatrix},\mathbf{\mu}_{\mathbf{w,y}}\mathbf{=}\mathbf{0}\end{split}\]</div>
<p>Unfortunately, this would be too complicated since the integration
result contains
<span class="math notranslate nohighlight">\(\left| \mathbf{Ⲗ}_{\mathbf{y},\mathbf{w}} \right|\)</span>; but notice
<span class="math notranslate nohighlight">\(\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\alpha\mathbf{I}\mathbf{+}\beta\phi\left( \mathbf{X} \right)\phi^{T}\left( \mathbf{X} \right)\)</span>
by (2‑19) of Example 2‑1 and (<em>1</em>‑<em>5</em>) of <em>Theorem 1‑6</em>, we can
write</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[L\left( \ma\]</div>
<p>thbf{w} right) = be
tamathbf{y}^{T}math
bf{y}mathbf{-}2beta
mathbf{y}^{T}phi^{T
}left( mathbf{X} r
ight)mathbf{w +}bet
amathbf{w}^{T}phil
eft( mathbf{X} righ
t)phi^{T}left( mat
hbf{X} right)mathbf
{w} + alphamathbf{w
}^{T}mathbf{w}mathb
f{=}betamathbf{y}^{
T}mathbf{y}mathbf{-
}2betamathbf{w}^{T}
phileft( mathbf{X}</p>
<blockquote>
<div>right)mathbf{y +}</div></blockquote>
<p class="last">mathbf{w}^{T}left( text{βϕ}left( mathb
f{X} right)phi^{T}left( mathbf{X} rig
ht) + alphamathbf{I
} right)mathbf{w}m
athbf{=}betamathbf{
y}^{T}mathbf{y}math
bf{-}2betamathbf{w}
^{T}phileft( mathb
f{X} right)mathbf{y
}mathbf{+}mathbf{w}
^{T}mathbf{Ⲗ}_{math
bf{w}|mathbf{y}}mat
hbf{w}</p>
</td>
<td>&#160;</td>
<td>(2‑22)</td>
</tr>
</tbody>
</table>
<p>Recall
<span class="math notranslate nohighlight">\(\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\beta\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}^{- 1}\phi\left( \mathbf{X} \right)\mathbf{y}\)</span>
from (<em>2</em>‑<em>19</em>), then we further manipulate above as,</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[L\left( \ma\]</div>
<p class="last">thbf{w} right) = le
ft( mathbf{w -}math
bf{mu}_{mathbf{w}|mathbf{y}} right)^{T
}mathbf{Ⲗ}_{mathbf{
w}|mathbf{y}}left(
mathbf{w -}mathbf{mu}_{mathbf{w}|math
bf{y}} right)mathbf
{+}2mathbf{mu}_{ma
thbf{w}|mathbf{y}}^{
T}mathbf{Ⲗ}_{mathbf
{w}|mathbf{y}}mathb
f{w} - mathbf{mu}_{
mathbf{w}|mathbf{y}
}^{T}mathbf{Ⲗ}_{mat
hbf{w}|mathbf{y}}ma
thbf{mu}_{mathbf{w}
<a href="#id29"><span class="problematic" id="id30">|</span></a>mathbf{y}}mathbf{+
}mathbf{y}^{T}mathb
f{y}mathbf{-}2betamathbf{w}^{T}philef
t( mathbf{X} right)
mathbf{y}</p>
</td>
<td>&#160;</td>
<td>(2‑23)</td>
</tr>
</tbody>
</table>
<p>At first glance it looks like the simplification cannot continue, but
note the similarity between <span class="math notranslate nohighlight">\(\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\)</span>
and <span class="math notranslate nohighlight">\(\beta\mathbf{w}^{T}\phi\left( \mathbf{X} \right)\mathbf{y}\)</span>,
and we actually have</p>
<div class="math notranslate nohighlight">
\[\beta\mathbf{w}^{T}\phi\left( \mathbf{X} \right)\mathbf{y =}\beta\mathbf{w}^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}^{- 1}\phi\left( \mathbf{X} \right)\mathbf{y}\mathbf{=}\mathbf{w}^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\]</div>
<p>Then respectively for (<em>2</em>‑<em>22</em>) and (<em>2</em>‑<em>23</em>) we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[L\left( \ma\]</div>
<p class="last">thbf{w} right) = be
tamathbf{y}^{T}math
bf{y}mathbf{-}2math
bf{w}^{T}mathbf{Ⲗ}_{
mathbf{w}|mathbf{y}
}mathbf{mu}_{mathb
f{w}|mathbf{y}}math
bf{+}mathbf{w}^{T}m
athbf{Ⲗ}_{mathbf{w}|
mathbf{y}}mathbf{w}</p>
</td>
<td>&#160;</td>
<td>(2‑24)</td>
</tr>
</tbody>
</table>
<p>and</p>
<div class="math notranslate nohighlight">
\[L\left( \mathbf{w} \right) = \left( \mathbf{w -}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\left( \mathbf{w -}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)\mathbf{+}\boxed{2\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{w}} - \mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{+}\beta\mathbf{y}^{T}\mathbf{y}\mathbf{-}\boxed{2\mathbf{w}^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}} = \left( \mathbf{w -}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\left( \mathbf{w -}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)\mathbf{+}\beta\mathbf{y}^{T}\mathbf{y} - \mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\]</div>
<p>where the remaining terms
“<span class="math notranslate nohighlight">\(\beta\mathbf{y}^{T}\mathbf{y} - \mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\)</span>”
are independent of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>, and consequently,</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\int_{}^{}{\]</div>
<p>expleft{ - frac{1
}{2}Lleft( mathbf{w
} right) right} dmathbf{w}} = explef
t{ - frac{1}{2}lef
t( betamathbf{y}^{T
}mathbf{y} - mathbf
{mu}_{mathbf{w}|ma
thbf{y}}^{T}mathbf{Ⲗ
}_{mathbf{w}|mathbf
{y}}mathbf{mu}_{ma
thbf{w}|mathbf{y}} right) right}int_{
}^{}{expleft{ - f
rac{1}{2}left( math
bf{w -}mathbf{mu}_{
mathbf{w}|mathbf{y}
} right)^{T}mathbf{
Ⲗ}_{mathbf{w}|mathb
f{y}}left( mathbf{w</p>
<blockquote>
<div>-}mathbf{mu}_{mat</div></blockquote>
<p>hbf{w}|mathbf{y}} r
ight) right} dmath
bf{w}} = left( 2pi
right)^{frac{M}{2}}
left| mathbf{Ⲗ}_{m
athbf{w}|mathbf{y}}
right|^{- frac{1}{2
}}expleft{ - frac
{1}{2}left( betama
thbf{y}^{T}mathbf{y}</p>
<blockquote>
<div><ul class="simple">
<li>mathbf{mu}_{mat</li></ul></blockquote>
<p class="last">hbf{w}|mathbf{y}}^{T
}mathbf{Ⲗ}_{mathbf{
w}|mathbf{y}}mathbf
{mu}_{mathbf{w}|ma
thbf{y}} right) rig
ht}</p>
</td>
<td>&#160;</td>
<td>(2‑25)</td>
</tr>
</tbody>
</table>
<p>We can further find from (2‑24) that</p>
<div class="math notranslate nohighlight">
\[L\left( \mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right) = \beta\mathbf{y}^{T}\mathbf{y}\mathbf{-}2\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{+}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\beta\mathbf{y}^{T}\mathbf{y}\mathbf{-}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\]</div>
<p>Plug this into (2‑25) and we have</p>
<div class="math notranslate nohighlight">
\[\int_{}^{}{\exp\left\{ - \frac{1}{2}L\left( \mathbf{w} \right) \right\} d\mathbf{w}} = \left( 2\pi \right)^{\frac{M}{2}}\left| \mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}} \right|^{- \frac{1}{2}}\exp\left\{ - \frac{1}{2}L\left( \mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right) \right\} \Rightarrow p\left( \mathbf{y}|\alpha,\beta \right) = \left( \frac{\beta}{2\pi} \right)^{\frac{N}{2}}\left( \alpha \right)^{\frac{M}{2}}\left| \mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}} \right|^{- \frac{1}{2}}\exp\left\{ - \frac{1}{2}L\left( \mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right) \right\} \Rightarrow \ln p \propto \frac{M}{2}\ln\alpha + \frac{N}{2}\ln\beta - \frac{1}{2}\ln\left| \mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}} \right| - \frac{1}{2}L\left( \mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)\]</div>
<p><strong>Step 2 - Find optimal parameters</strong>. Treating <span class="math notranslate nohighlight">\(\beta\)</span> as
constant, we have</p>
<div class="math notranslate nohighlight">
\[\frac{\partial\ln p}{\partial\alpha} = \frac{M}{2\alpha} - \frac{1}{2}\frac{\partial\ln\left| \mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}} \right|}{\partial\alpha} - \frac{1}{2}\frac{\partial L\left( \mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)}{\partial\alpha} = 0\]</div>
<p>From (<em>2</em>‑<em>21</em>), we have</p>
<div class="math notranslate nohighlight">
\[\frac{\partial L\left( \mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)}{\partial\alpha} = \mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\]</div>
<p>Recall the fact that the determinant of a matrix is the product of its
eigenvalues. Since
<span class="math notranslate nohighlight">\(\mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\alpha\mathbf{I}\mathbf{+}\beta\phi\left( \mathbf{X} \right)\phi^{T}\left( \mathbf{X} \right)\)</span>,
then
<span class="math notranslate nohighlight">\(\left| \mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}} \right| = \prod_{i = 1}^{M}{\beta\lambda_{i} + \alpha}\)</span>
where <span class="math notranslate nohighlight">\(\lambda_{i}\)</span> are the <span class="math notranslate nohighlight">\(m\)</span> eigenvalues of
<span class="math notranslate nohighlight">\(\phi\left( \mathbf{X} \right)\phi^{T}\left( \mathbf{X} \right)\)</span>,
then</p>
<div class="math notranslate nohighlight">
\[\ln\left| \mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}} \right| = \sum_{i = 1}^{M}{\ln\left( \beta\lambda_{i} + \alpha \right)} \Rightarrow \frac{\partial\ln\left| \mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}} \right|}{\partial\alpha} = \sum_{i = 1}^{M}\frac{1}{\beta\lambda_{i} + \alpha} \Rightarrow \frac{M}{\alpha} - \sum_{i = 1}^{M}\frac{1}{\beta\lambda_{i} + \alpha} - \mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}} = 0 \Rightarrow M - \sum_{i = 1}^{M}\frac{\alpha}{\beta\lambda_{i} + \alpha} = \sum_{i = 1}^{M}\frac{\beta\lambda_{i}}{\beta\lambda_{i} + \alpha} = \alpha\ \mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{\Rightarrow}\alpha = \frac{\sum_{i = 1}^{M}\frac{\beta\lambda_{i}}{\beta\lambda_{i} + \alpha}}{\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}}\]</div>
<p>Let
<span class="math notranslate nohighlight">\(\mathcal{M =}\sum_{i = 1}^{M}\frac{\beta\lambda_{i}}{\beta\lambda_{i} + \alpha}\)</span>,
we have</p>
<div class="math notranslate nohighlight">
\[\alpha = \frac{\mathcal{M}}{\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}}\]</div>
<p>Treating <span class="math notranslate nohighlight">\(\alpha\)</span> as a constant, then we have</p>
<div class="math notranslate nohighlight">
\[\frac{\partial\ln\left| \mathbf{Ⲗ}_{\mathbf{w}|\mathbf{y}} \right|}{\partial\beta} = \sum_{i = 1}^{M}\frac{\lambda_{i}}{\beta\lambda_{i} + \alpha},\frac{\partial L\left( \mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)}{\partial\beta} = \left( \mathbf{y} - \mathbf{\Phi}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)^{T}\left( \mathbf{y} - \mathbf{\Phi}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)\]</div>
<p>Then</p>
<div class="math notranslate nohighlight">
\[\frac{\partial\ln p}{\partial\beta} = \frac{N}{2\beta} - \frac{1}{2}\sum_{i = 1}^{M}\frac{\lambda_{i}}{\beta\lambda_{i} + \alpha} - \frac{1}{2}\left( \mathbf{y} - \mathbf{\Phi}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right)^{T}\left( \mathbf{y} - \mathbf{\Phi}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right) = 0 \Rightarrow \frac{N}{\beta} - \frac{1}{\beta}\mathcal{M -}\left\| \mathbf{\epsilon} \right\|_{2}^{2} = 0 \Rightarrow \beta = \frac{N\mathcal{- M}}{\left\| \mathbf{\epsilon} \right\|_{2}^{2}}\]</div>
<p>Now we have iterative formulas to estimate a fixed point for both
<span class="math notranslate nohighlight">\(\alpha,\beta\)</span>.</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\left\{ \begin{mat\]</div>
<dl class="docutils">
<dt>rix}</dt>
<dd>alpha = frac{ma</dd>
</dl>
<p>thcal{M}}{mathbf{mu
}_{mathbf{w}|mathbf
{y}}^{T}mathbf{mu}_
{mathbf{w}|mathbf{y
}}} \</p>
<blockquote>
<div>beta = frac{Nma</div></blockquote>
<p>thcal{- M}}{left| mathbf{epsilon} rig
ht|_{2}^{2}} \</p>
<blockquote>
<div>end{matrix} righ</div></blockquote>
<p class="last">t.</p>
</td>
<td>&#160;</td>
<td>(2‑26)</td>
</tr>
</tbody>
</table>
<p><strong>Implementation</strong>. Note at the end of each iteration we need to update</p>
<div class="math notranslate nohighlight">
\[\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\beta\mathbf{\Sigma}_{\mathbf{w}|\mathbf{y}}^{- 1}\mathbf{\Phi}\mathbf{y}\mathbf{=}\beta\left( \alpha\mathbf{I}\mathbf{+}\beta\mathbf{\Phi}\mathbf{\Phi}^{T} \right)^{- 1}\mathbf{\Phi}\mathbf{y}\]</div>
<p>Computing matrix inverse is not recommended. A recommended algorithm is
to first eigen-decompose</p>
<div class="math notranslate nohighlight">
\[\mathbf{\Phi}\mathbf{\Phi}^{T} = \mathbf{\text{UΛ}}\mathbf{U}^{T} \Rightarrow \mathbf{\Sigma}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\mathbf{U}\left( \alpha\mathbf{I} + \beta\mathbf{\Lambda} \right)\mathbf{U}^{T}\mathbf{\Rightarrow}\mathbf{\Sigma}_{\mathbf{w}|\mathbf{y}}^{- 1}\mathbf{=}\mathbf{U}\left( \alpha\mathbf{I} + \beta\mathbf{\Lambda} \right)^{- 1}\mathbf{U}^{T}\]</div>
<div class="math notranslate nohighlight">
\[\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\beta\mathbf{U}\left( \alpha\mathbf{I} + \beta\mathbf{\Lambda} \right)^{- 1}\mathbf{U}^{T}\mathbf{\Phi}\mathbf{y}\mathbf{\Rightarrow}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\beta^{2}\mathbf{y}^{T}\mathbf{\Phi}^{T}\mathbf{U}\left( \alpha\mathbf{I} + \beta\mathbf{\Lambda} \right)^{- 1}\mathbf{U}^{T}\mathbf{U}\left( \alpha\mathbf{I} + \beta\mathbf{\Lambda} \right)^{- 1}\mathbf{U}^{T}\mathbf{\Phi}\mathbf{y =}\beta^{2}\mathbf{y}^{T}\mathbf{\Phi}^{T}\mathbf{U}\left( \alpha\mathbf{I} + \beta\mathbf{\Lambda} \right)^{- 2}\mathbf{U}^{T}\mathbf{\Phi}\mathbf{y}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\left\| \mathbf{y} - \mathbf{\Phi}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}} \right\|_{2}^{2} = \mathbf{y}^{T}\mathbf{y}\mathbf{-}2\mathbf{y}^{T}\mathbf{\Phi}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{+}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{\Phi}\mathbf{\Phi}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\mathbf{y}^{T}\mathbf{y}\mathbf{-}2\beta\mathbf{y}^{T}\mathbf{\Phi}^{T}\mathbf{U}\left( \alpha\mathbf{I} + \beta\mathbf{\Lambda} \right)^{- 1}\mathbf{U}^{T}\mathbf{\Phi}\mathbf{y}\mathbf{+}\beta^{2}\mathbf{y}^{T}\mathbf{\Phi}^{T}\mathbf{U}\left( \alpha\mathbf{I} + \beta\mathbf{\Lambda} \right)^{- 1}\mathbf{U}^{T}\mathbf{\Phi}\mathbf{\Phi}^{T}\mathbf{U}\left( \alpha\mathbf{I} + \beta\mathbf{\Lambda} \right)^{- 1}\mathbf{U}^{T}\mathbf{\Phi}\mathbf{y}\]</div>
<p>Thus, we can store
<span class="math notranslate nohighlight">\(\mathbf{y}^{T}\mathbf{y,}\mathbf{U}^{T}\mathbf{\Phi}\mathbf{y}\)</span>
and <span class="math notranslate nohighlight">\(\mathbf{U}^{T}\mathbf{\Phi}\mathbf{\Phi}^{T}\mathbf{U}\)</span>,
which are fixed quantities, for repeated use at the end of each
iteration.</p>
<p><strong>Interpretation of</strong> <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>. Note above model selection
works for both Gaussian MAP and Gaussian Bayesian. Let
<span class="math notranslate nohighlight">\(\mathbf{\Phi = U}\mathbf{\Lambda}^{\frac{1}{2}}\mathbf{V}^{T}\)</span> be
the SVD of <span class="math notranslate nohighlight">\(\mathbf{\Phi}\)</span> where <span class="math notranslate nohighlight">\(\mathbf{U},\mathbf{V}\)</span> are
orthonormal matrices, and recall orthonormal matrices geometrically
represent rotation, then for <span class="math notranslate nohighlight">\(\mathbf{w}^{*}\)</span> in (<em>2</em>‑<em>15</em>)
and <span class="math notranslate nohighlight">\(\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\)</span> in (<em>2</em>‑<em>20</em>), we
have</p>
<div class="math notranslate nohighlight">
\[\mathbf{w}^{*} = \mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\beta\mathbf{\Sigma}_{\mathbf{w}|\mathbf{y}}^{- 1}\mathbf{\Phi}\mathbf{y}\mathbf{=}\beta\left( \alpha\mathbf{I}\mathbf{+}\beta\mathbf{\Phi}\mathbf{\Phi}^{T} \right)^{- 1}\mathbf{\Phi}\mathbf{y}\]</div>
<p>Then
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{y}}\mathbf{=}\mathbf{\Phi}^{T}\mathbf{w}^{*}\)</span>
in Gaussian MAP and
<span class="math notranslate nohighlight">\(\mathbb{E}\left\lbrack \widetilde{\mathbf{y}} \right\rbrack\mathbf{=}\mathbf{\Phi}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\)</span>
in Gaussian Bayesian are</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{\Phi}^{T}\mathbf{w}^{*}\mathbf{=}\mathbf{\Phi}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}\mathbf{=}\mathbf{V}\mathbf{\Lambda}^{\frac{1}{2}}\boxed{\mathbf{U}^{T}\mathbf{U}}{\beta\left( \alpha\mathbf{I} + \beta\mathbf{\Lambda} \right)}^{- 1}\boxed{\mathbf{U}^{T}\mathbf{U}}\mathbf{\Lambda}^{\frac{1}{2}}\mathbf{V}^{T}\mathbf{y}\mathbf{=}\mathbf{V}\begin{pmatrix}
\frac{\beta\lambda_{1}}{\alpha + \beta\lambda_{1}} &amp; &amp; \\
 &amp; \ddots &amp; \\
 &amp; &amp; \frac{\beta\lambda_{M}}{\alpha + \beta\lambda_{M}} \\
\end{pmatrix}\mathbf{V}^{T}\mathbf{y}\end{split}\]</div>
<p>where
<span class="math notranslate nohighlight">\(\mathbf{V =}\mathbf{\Lambda}^{- \frac{1}{2}}\mathbf{U}^{T}\mathbf{\Phi}\)</span>
is rotated and scaled data, and
:math:<a href="#id31"><span class="problematic" id="id32">`</span></a>widetilde{mathbf{mu}_{mathbf{w}|mathbf{y}}} = mathbf{Lambda}^{frac{1}{2}}mathbf{U}^{T}mathbf{w} = begin{pmatrix}
frac{betalambda_{1}}{alpha + betalambda_{1}} &amp; &amp; \</p>
<blockquote>
<div>&amp; ddots &amp; \
&amp; &amp; frac{betalambda_{M}}{alpha + betalambda_{M}} \</div></blockquote>
<p>end{pmatrix}mathbf{V}^{T}mathbf{y}` is with the same rotation
<span class="math notranslate nohighlight">\(\mathbf{U}^{T}\)</span> but different scaling for interpretation
convenience. Note the model assumes
<span class="math notranslate nohighlight">\(\mathbf{\mu}_{\mathbf{w}}\mathbf{= 0 \Rightarrow}\mathbf{U}^{T}\mathbf{w}\mathbf{= 0}\)</span>;
and
<span class="math notranslate nohighlight">\(\frac{\beta\lambda_{1}}{\alpha + \beta\lambda_{1}} \in \left\lbrack 0,1 \right\rbrack\)</span>.</p>
<p>Our interpretation is w.r.t. rotation under rotation
<span class="math notranslate nohighlight">\(\mathbf{U}^{T}\)</span>. When <span class="math notranslate nohighlight">\(\lambda_{i} \approx 0\)</span>, then
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}}\left( i \right)\mathbf{\approx}0\)</span>,
and thus the data does not provide sufficient information for the
<span class="math notranslate nohighlight">\(i\)</span>th weight. When
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}}\)</span> is large s.t.
<span class="math notranslate nohighlight">\(\frac{\beta\lambda_{i}}{\alpha + \beta\lambda_{i}} \approx 1\)</span>,
then the <span class="math notranslate nohighlight">\(i\)</span>th weight is almost determined only by the data
(<span class="math notranslate nohighlight">\(\lambda_{i},\mathbf{V},\mathbf{y}\)</span> all come from the data) and
has little to do with the predefined <span class="math notranslate nohighlight">\(\alpha\)</span>. As a result, we
<em>interpret</em>
<span class="math notranslate nohighlight">\(\mathcal{M =}\sum_{i = 1}^{M}\frac{\beta\lambda_{i}}{\alpha + \beta\lambda_{i}}\)</span>
as the number of effective weights.</p>
<p>If we add <span class="math notranslate nohighlight">\(N^{(1)}\)</span> new data
<span class="math notranslate nohighlight">\(\mathbf{X}_{m \times N^{\left( 1 \right)}}^{\left( 1 \right)}\)</span> to
<span class="math notranslate nohighlight">\(\mathbf{X}\)</span> and denote
<span class="math notranslate nohighlight">\(\mathbf{\Phi}_{M \times N^{\left( 1 \right)}}^{\left( 1 \right)}\mathbf{= \phi}\left( \mathbf{X}^{\left( 1 \right)} \right)\)</span>,
then we will take eigenvalues
<span class="math notranslate nohighlight">\(\lambda_{1}^{\left( 1 \right)},\ldots,\lambda_{n}^{\left( 1 \right)}\)</span>
of
<span class="math notranslate nohighlight">\(\mathbf{\Phi}\mathbf{\Phi}^{T} + \mathbf{\Phi}_{1}^{\left( 1 \right)}\left( \mathbf{\Phi}_{1}^{\left( 1 \right)} \right)^{T}\)</span>.
In practice, it is usually the case that
<span class="math notranslate nohighlight">\(\lambda_{1}^{\left( 1 \right)} &gt; \lambda_{1},\ldots,\lambda_{n}^{\left( 1 \right)} &gt; \lambda_{n}\)</span>
when <span class="math notranslate nohighlight">\(N^{\left( 1 \right)}\)</span> is sufficiently large; or in other
words, empirically all eigenvalues will be large with sufficient many
data (<span class="math notranslate nohighlight">\(N \gg M\)</span>), and in this case <span class="math notranslate nohighlight">\(\mathcal{M \approx}M\)</span>,
and the choice of parameters become</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{ \begin{matrix}
\alpha \approx \frac{M}{\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}^{T}\mathbf{\mu}_{\mathbf{w}|\mathbf{y}}} \\
\beta \approx \frac{N - M}{\left\| \mathbf{\epsilon} \right\|_{2}^{2}} \approx \frac{N}{\left\| \mathbf{\epsilon} \right\|_{2}^{2}} \\
\end{matrix} \right.\\end{split}\]</div>
<p>And we only need to iteratively compute a fixed point for
<span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p>EX 1. Solve for weighted LSE problem
<span class="math notranslate nohighlight">\(\arg{\operatorname{}\left\| \mathbf{\Lambda}^{\frac{1}{2}}\left( \mathbf{y}\mathbf{-}\mathbf{\Phi}^{T}\mathbf{w} \right) \right\|_{2}^{2}}\)</span>
where <span class="math notranslate nohighlight">\(\mathbf{\Lambda}\)</span> is a diagonal matrix consisting of
weights. This is later applied in logistic regression (2‑55).</p>
<p>Key. Let
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{y}} = \mathbf{\Lambda}^{\frac{1}{2}}\mathbf{y}\)</span>
and
<span class="math notranslate nohighlight">\({\widetilde{\mathbf{\Phi}}}^{T}\mathbf{=}\mathbf{\Lambda}^{\frac{1}{2}}\mathbf{\Phi}^{T}\)</span>,
then by (2‑7)
<span class="math notranslate nohighlight">\(\mathbf{w}^{\mathbf{*}}\mathbf{=}\left( \widetilde{\mathbf{\Phi}}{\widetilde{\mathbf{\Phi}}}^{T} \right)^{\dagger}\widetilde{\mathbf{\Phi}}\widetilde{\mathbf{y}}\mathbf{=}\left( \mathbf{\Phi}\mathbf{\Lambda}\mathbf{\Phi}^{T} \right)^{\dagger}\mathbf{\Phi}\mathbf{\Lambda}\mathbf{y}\)</span>.</p>
</div>
</div>
<div class="section" id="linear-discriminant-analysis">
<h4><strong>Linear Discriminant Analysis</strong><a class="headerlink" href="#linear-discriminant-analysis" title="Permalink to this headline">¶</a></h4>
<p><strong>Discriminant analysis</strong> or <strong>classification</strong>, can be viewed as a
special type of regression, sometimes named <strong>categorical regression</strong>.
Still, we are given the data set
<span class="math notranslate nohighlight">\(\left( \mathbf{X},\mathbf{y} \right)\)</span> where data matrix
<span class="math notranslate nohighlight">\(\mathbf{X} = \left( \mathbf{x}_{1},\ldots,\mathbf{x}_{N} \right) \in \mathbb{R}^{M \times N}\)</span>,
but
<span class="math notranslate nohighlight">\(\mathbf{y =}\left( y_{1},\ldots,y_{N} \right) \in \mathbb{L}^{N},\mathbb{L \subseteq N}\)</span>,
where <span class="math notranslate nohighlight">\(\mathbb{L}\)</span> is a finite set of discrete <strong>class labels</strong>,
and we name its size <span class="math notranslate nohighlight">\(K = \left| \mathbb{L} \right|\)</span> as the
<strong>class size</strong>. We <em>note</em> the labels are <strong>categorical</strong> and for
distinction of groups of data; although labels are represented by
integers, their numerical values do not really matter. For example, the
whole data set still makes sense if the chosen labels in
<span class="math notranslate nohighlight">\(\mathbb{L}\)</span> are replaced by other distinct integers. The
discriminant analysis finds a <strong>discriminant function</strong>
<span class="math notranslate nohighlight">\(\mathcal{f:}\mathbb{R}^{M}\mathbb{\rightarrow L}\)</span> and
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{y}} = \left( {\widetilde{y}}_{1},\ldots,{\widetilde{y}}_{N} \right) = \mathcal{f}\left( \mathbf{X} \right)\)</span>
gives estimation of the true labels <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>. The most basic
type is the <strong>binary classification</strong> when <span class="math notranslate nohighlight">\(K = 2\)</span>. For a <strong>future
variable</strong> <span class="math notranslate nohighlight">\(\mathcal{x}\)</span>, <span class="math notranslate nohighlight">\(\mathcal{f}\)</span> provides
<strong>prediction</strong>
<span class="math notranslate nohighlight">\(\mathcal{y}\mathcal{= f}\left( \mathcal{x} \right)\)</span>.</p>
<p>We again emphasize the labels mainly serve the purpose of distinction
between groups of data; <em>however</em>, it is not uncommon the labels could
also serve technical or interpretive purposes. For example, 1) in
perceptron algorithm, the label set is designed as
<span class="math notranslate nohighlight">\(\left\{ - 1,1 \right\}\)</span> for its error function; 2) Fisher’s
binary linear discriminant in <em>Theorem 2‑6</em> can be shown to be
equivalent to LSE if using label set
<span class="math notranslate nohighlight">\(\left\{ - \frac{N}{N_{0}},\frac{N}{N_{1}} \right\}\)</span>; 3) in
<strong>sentiment analysis</strong>, <span class="math notranslate nohighlight">\(- 1\)</span> is usually to label the class of
negative sentiment, and <span class="math notranslate nohighlight">\(+ 1\)</span> is used to label the class of
positive sentiment. The design of label set is called <strong>label</strong>
<strong>coding</strong>.</p>
<p>As before, there can be feature function <span class="math notranslate nohighlight">\(\phi\)</span> applied to each
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, and we are actually dealing with
<span class="math notranslate nohighlight">\(\mathbf{\phi} = \phi\left( \mathbf{x} \right)\)</span>. The basic idea is
to utilize the regression in (2‑2), and write the discriminant as</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathcal{f}\]</div>
<p class="last">left( mathbf{x} ri
ght) = fleft( phi^{
T}left( mathbf{X} right)mathbf{w} rig
ht) = fleft( mathbf
{phi}^{T}mathbf{w}
right)</p>
</td>
<td>&#160;</td>
<td>(2‑27)</td>
</tr>
</tbody>
</table>
<p>where <span class="math notranslate nohighlight">\(f\)</span> is to convert the decimal value resulting from
<span class="math notranslate nohighlight">\(\mathbf{\phi}^{T}\mathbf{w}\)</span> to a label, and it is very often
referred to as <strong>activation function</strong>. Discriminant analysis based on
(2‑27) is called <strong>linear discriminant analysis</strong>. For example, suppose
we have binary label set
<span class="math notranslate nohighlight">\(\mathbb{L =}\left\{ l_{1},l_{2} \right\}\)</span>, then we can define</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\widetilde{y}\math\]</div>
<p>cal{= f}left( mathb
f{x} right) = left{ begin{matrix}</p>
<blockquote>
<div><blockquote>
<div>1 &amp; phi^{T}left(</div></blockquote>
<p>mathbf{x} right)m</p>
</div></blockquote>
<dl class="docutils">
<dt>athbf{w} geq 0 \</dt>
<dd><blockquote class="first">
<div>0 &amp; phi^{T}left(</div></blockquote>
<p class="last">mathbf{x} right)m</p>
</dd>
<dt>athbf{w &lt;}0 \</dt>
<dd>end{matrix} righ</dd>
</dl>
<p class="last">t.</p>
</td>
<td>&#160;</td>
<td>(2‑28)</td>
</tr>
</tbody>
</table>
<p>For the special case where the bias <span class="math notranslate nohighlight">\(w_{0}\)</span> is explicit, we can
write</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathcal{f}\]</div>
<p class="last">left( mathbf{x} ri
ght) = fleft( phi^{
T}left( mathbf{X} right)mathbf{w +}w_{
0} right) = fleft(
mathbf{phi}^{T}mat
hbf{w +}w_{0} right)</p>
</td>
<td>&#160;</td>
<td>(2‑29)</td>
</tr>
</tbody>
</table>
<p>which can be viewed as classification in <span class="math notranslate nohighlight">\(\mathbb{R}^{M + 1}\)</span>
dimension consistent with (2‑27), putting all feature points at height
<span class="math notranslate nohighlight">\(1\)</span> in the first dimension.</p>
<p>For error, there could be a variety of different definitions.
Considering the categorical nature of labels, one intuitive error
definition is to count the differences between
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{y}}\mathcal{= f}\left( \mathbf{X} \right)\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{y}\)</span>:
<span class="math notranslate nohighlight">\(\mathcal{e}\left( \widetilde{\mathbf{y}} \right) = \sum_{i = 1}^{N}1_{y_{i} = {\widetilde{y}}_{i}}\)</span>,
which we refer to as <strong>identity error</strong>. Identity error is the most
widely used performance indicator, but it is hard to optimize (it is
highly piecewise, and its derivative is zero almost everywhere).</p>
<div class="section" id="perceptron-algorithm">
<h5>Perceptron Algorithm<a class="headerlink" href="#perceptron-algorithm" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><strong>Perceptron Algorithm</strong> could be the simplest algorithm for binary
classification and can be viewed as a simplest one-layer <strong>neural
network</strong> with one output. Technically, it tries to minimize a more
numerical error rather than the identity error. To achieve this, it
designs the label set as <span class="math notranslate nohighlight">\(\left\{ - 1,1 \right\}\)</span>. For each
data point <span class="math notranslate nohighlight">\(\mathbf{x}_{i}\)</span> and label <span class="math notranslate nohighlight">\(y_{i}\)</span>, the
algorithm checks if
<span class="math notranslate nohighlight">\(\operatorname{sgn}\left( \mathbf{\phi}_{i}^{T}\mathbf{w} \right) = y_{i}\)</span>;
if so, the classification is correct; otherwise, the classification
is wrong, and we calculate the <strong>perceptron error</strong> as the following,</li>
</ul>
<div class="math notranslate nohighlight">
\[\mathcal{e}_{p} = \sum_{\operatorname{sgn}\left( \mathbf{\phi}_{i}^{T}\mathbf{w} \right) \neq y_{i}}^{}{- y_{i}\mathbf{\phi}_{i}^{T}\mathbf{w}}\]</div>
<p><em>Note</em>
<span class="math notranslate nohighlight">\(\operatorname{sgn}\left( \mathbf{\phi}_{i}^{T}\mathbf{w} \right) \neq y_{i}\)</span>
is equivalent to <span class="math notranslate nohighlight">\(y_{i}\mathbf{\phi}_{i}^{T}\mathbf{w &lt;}0\)</span>, and
thus we put a minus sign in front of it to make the error positive. Our
objective is now to simply minimize the error, i.e.
<span class="math notranslate nohighlight">\(\operatorname{}\mathcal{e}_{p}\)</span>. The classic way is to use
gradient descent, with <span class="math notranslate nohighlight">\(\eta\)</span> as a predefined positive step length</p>
<div class="math notranslate nohighlight">
\[\mathbf{w}^{\left( t + 1 \right)}\mathbf{=}\mathbf{w}^{\left( t \right)}\mathbf{-}\eta\nabla_{\mathbf{w}^{\left( t \right)}}\mathcal{e}_{p}\]</div>
<p>where by <em>Fact 1‑1</em></p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\nabla_{\ma\]</div>
<p>thbf{w}^{left( t ri
ght)}}mathcal{e}_{p}</p>
<blockquote>
<div>= sum_{operatornam</div></blockquote>
<p>e{sgn}left( mathbf{
phi}_{i}^{T}mathbf{
w}^{left( t right)}</p>
<blockquote>
<div>right) neq y_{i}}^</div></blockquote>
<p>{}{- y_{i}mathbf{ph
i}_{i}} Rightarrow mathbf{w}^{left( t +</p>
<blockquote>
<div>1 right)}mathbf{=}</div></blockquote>
<p class="last">mathbf{w}^{left( t
right)}mathbf{+}et
asum_{operatorname{
sgn}left( mathbf{p
hi}_{i}^{T}mathbf{w}
^{left( t right)} right) neq y_{i}}^{}
{y_{i}mathbf{phi}_{
i}}</p>
</td>
<td>&#160;</td>
<td>(2‑30)</td>
</tr>
</tbody>
</table>
<p>The above can be modified as online updates whenever an error is
encountered.</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><span class="math notranslate nohighlight">\(\mathbf{w}^{\l
eft( t + 1 \right)}\m
athbf{≔}\mathbf{w}^{\
left( t \right)}\math
bf{+}\eta y_{i_{t}}\m
athbf{\phi}_{i_{t}}\)</span>
if
<span class="math notranslate nohighlight">\(\operatorname{
sgn}\left( \mathbf{\p
hi}_{i_{t}}^{T}\mathb
f{w}^{\left( t \right
)} \right) \neq y_{i_
{t}}\)</span>,<span class="math notranslate nohighlight">\(\ i_{t
} \in \left\{ 1,\ldot
s,N \right\}\)</span></td>
<td>&#160;</td>
<td>(2‑31)</td>
</tr>
</tbody>
</table>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><a class="reference internal" href="media/image1.png"><img alt="image1" src="media/image1.png" style="width: 2.69484in; height: 2.59494in;" /></a></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><em>Figure</em> <em>2‑1 Perceptron algorithm is to find the best hyperplane
through origin separating the points. With unit normal, the
perceptron error can be interpreted as adding up the distances from
misclassified points to the hyperplane.</em></td>
</tr>
</tbody>
</table>
<p>The <em>geometric interpretation</em> is illustrated in <em>Figure 2‑1</em>. A
hyperplane <span class="math notranslate nohighlight">\(H\left( \mathbf{x} \right) = \mathbf{w}^{T}\mathbf{x}\)</span>
goes through the origin and has <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> as its normal. With a
fixed <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>,
<span class="math notranslate nohighlight">\(\cos\left\langle \mathbf{\phi}_{i}\mathbf{,}\mathbf{w} \right\rangle = \frac{\mathbf{\phi}_{i}^{T}\mathbf{w}}{\left\| \mathbf{w} \right\|_{2}\left\| \mathbf{\phi}_{i} \right\|_{2}}\)</span>
will be all positive if <span class="math notranslate nohighlight">\(\mathbf{\phi}_{i}\)</span> is at one side of
<span class="math notranslate nohighlight">\(H\)</span> and all negative if at the other side,
<span class="math notranslate nohighlight">\(d\left( \mathbf{\phi}_{i}\mathbf{,}H \right) = \frac{\mathbf{\phi}_{i}^{T}\mathbf{w}}{\left\| \mathbf{w} \right\|_{2}}\)</span>
is a signed distance from point <span class="math notranslate nohighlight">\(\mathbf{\phi}_{i}\)</span> to the
hyperplane, and
<span class="math notranslate nohighlight">\(\mathbf{\phi}_{i}^{T}\mathbf{w =}\left\| \mathbf{w} \right\|_{2}d\left( \mathbf{\phi}_{i}\mathbf{,}H \right)\mathbf{\propto}d\left( \mathbf{\phi}_{i}\mathbf{,}H \right)\)</span>.
The interpretation can be clearer if we restrict
<span class="math notranslate nohighlight">\(\left\| \mathbf{w} \right\|_{2}\mathbf{=}1\)</span>, then we have
<span class="math notranslate nohighlight">\(\mathbf{\phi}_{i}^{T}\mathbf{w =}d\left( \mathbf{\phi}_{i}\mathbf{,}H \right)\)</span>,
and “<span class="math notranslate nohighlight">\(\mathcal{e}_{p}\)</span>” is adding up the distances of
misclassified points to the hyperplane. It is trivial to verify the
optimal solution with or without the constraint are identical. Thus, in
practice, we might just proceed the optimization without the “unit
normal” constraint for simplicity, and normalize the optimal solution
<span class="math notranslate nohighlight">\(\mathbf{w}^{*}\)</span> at the end. The perceptron objective
<span class="math notranslate nohighlight">\(\operatorname{}\mathcal{e}_{p}\)</span> can be viewed as finding an
orientation of <span class="math notranslate nohighlight">\(H\)</span> that best separates the data points, where the
“best” is in terms of minimum “<span class="math notranslate nohighlight">\(\mathcal{e}_{p}\)</span>”. The
<em>initialization</em> <span class="math notranslate nohighlight">\(\mathbf{w}^{\left( 0 \right)}\)</span> for (2‑30) can be
random choice of any nonzero vector. The <em>advantage</em> of Perceptron is
its simplicity, its online updates and the guaranteed convergence in
ideal situation; while the <em>disadvantage</em> is its limited to binary
classification and it runs indefinitely in non-ideal situation when the
data points are not separable by a hyperplane (in this case a heuristic
rule is needed for termination).</p>
<p><strong>Fact</strong> <strong>2‑5</strong> <strong>Cauchy-Schwarz inequality</strong> states that
<span class="math notranslate nohighlight">\(\left\| \mathbf{x} \right\|_{\langle\rangle}\left\| \mathbf{y} \right\|_{\langle\rangle} \geq \left| \left\langle \mathbf{x},\mathbf{y} \right\rangle \right|\)</span>
for any <span class="math notranslate nohighlight">\(\mathbf{x},\mathbf{y} \in \mathbb{R}^{n}\)</span> where
<span class="math notranslate nohighlight">\(\left\langle \mathbf{x},\mathbf{y} \right\rangle\)</span> is an inner
product, and
<span class="math notranslate nohighlight">\(\left\| \mathbf{x} \right\|_{\langle\rangle} = \sqrt{\left\langle \mathbf{x},\mathbf{x} \right\rangle}\)</span>
is the inner product induced norm.</p>
<p><strong>Theorem</strong> <strong>2‑5</strong> <strong>Perceptron Convergence Theorem</strong>. In binary
classification, if there exists a hyperplane
<span class="math notranslate nohighlight">\(H:\mathbf{w}^{T}\mathbf{x} = 0\)</span> s.t. the feature points
<span class="math notranslate nohighlight">\(\left( \mathbf{\phi}_{1},y_{1} \right),\ldots,\left( \mathbf{\phi}_{N},y_{N} \right)\)</span>
satisfy
<span class="math notranslate nohighlight">\(\left\{ \mathbf{\phi}_{i}:\mathbf{w}^{T}\mathbf{x} \geq 0 \right\}\)</span>
all have the same label and
<span class="math notranslate nohighlight">\(\left\{ \mathbf{\phi}_{i}:\mathbf{w}^{T}\mathbf{x} &lt; 0 \right\}\)</span>
all have the other label, then the feature points are <strong>linearly
separable</strong>. If the feature points are linearly separable by some
hyperplane <span class="math notranslate nohighlight">\(H\)</span>, then there exist two constants <span class="math notranslate nohighlight">\(a,b\)</span> s.t.
<span class="math notranslate nohighlight">\(at^{2}\mathbf{\leq}\left\| \mathbf{w}^{\left( t \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2}\mathbf{\leq}\text{bt}\)</span>
for all <span class="math notranslate nohighlight">\(t\)</span> if <span class="math notranslate nohighlight">\(\mathcal{e}_{p} \neq 0\)</span> for the algorithm
defined by (2‑31). <em>As a result</em>, the algorithm must terminate within
<span class="math notranslate nohighlight">\(t \leq \frac{b}{a}\)</span> iterations <span class="math notranslate nohighlight">\(\mathcal{e}_{p} = 0\)</span> at
termination, otherwise <span class="math notranslate nohighlight">\(at^{2} &gt; bt\)</span> when <span class="math notranslate nohighlight">\(t\)</span> is
sufficiently large. <em>For the lower bound</em>, let <span class="math notranslate nohighlight">\(\mathbf{w}^{*}\)</span> be
a normal of the separation hyperplane <span class="math notranslate nohighlight">\(H\)</span>, then</p>
<div class="math notranslate nohighlight">
\[\mathbf{w}^{\left( t \right)} = \mathbf{w}^{\left( 0 \right)} + \eta y_{i_{1}}\mathbf{\phi}_{i_{1}}\mathbf{+ \ldots +}\eta y_{i_{t}}\mathbf{\phi}_{i_{t}} \Rightarrow \mathbf{w}^{\left( t \right)} - \mathbf{w}^{\left( 0 \right)} = \eta y_{i_{1}}\mathbf{\phi}_{i_{1}}\mathbf{+ \ldots +}\eta y_{i_{t}}\mathbf{\phi}_{i_{t}} \Rightarrow \left( \mathbf{w}^{*} \right)^{T}\left( \mathbf{w}^{\left( t \right)} - \mathbf{w}^{\left( 0 \right)} \right) = \left( \mathbf{w}^{*} \right)^{T}\left( \eta y_{i_{1}}\mathbf{\phi}_{i_{1}}\mathbf{+ \ldots +}\eta y_{i_{t}}\mathbf{\phi}_{i_{t}} \right) \geq \text{ηt}\operatorname{}{y_{i}\left( \mathbf{w}^{*} \right)^{T}\mathbf{\phi}_{i}}\]</div>
<p>By Cauchy-Schwarz inequality,
<span class="math notranslate nohighlight">\(\left| \left( \mathbf{w}^{*} \right)^{T}\left( \mathbf{w}^{\left( t \right)} - \mathbf{w}^{\left( 0 \right)} \right) \right| \leq \left\| \mathbf{w}^{*} \right\|_{2}\left\| \mathbf{w}^{\left( t \right)} - \mathbf{w}^{\left( 0 \right)} \right\|_{2}\)</span>,
therefore</p>
<div class="math notranslate nohighlight">
\[\left\| \mathbf{w}^{*} \right\|_{2}\left\| \mathbf{w}^{\left( t \right)} - \mathbf{w}^{\left( 0 \right)} \right\|_{2} \geq \text{ηt}\operatorname{}{y_{i}\left( \mathbf{w}^{*} \right)^{T}\mathbf{\phi}_{i}} \Rightarrow \left\| \mathbf{w}^{\left( t \right)} - \mathbf{w}^{\left( 0 \right)} \right\|_{2} \geq \frac{\eta\operatorname{}{y_{i}\left( \mathbf{w}^{*} \right)^{T}\mathbf{\phi}_{i}}}{\left\| \mathbf{w}^{*} \right\|_{2}}t\]</div>
<p>where
<span class="math notranslate nohighlight">\(a = \frac{\eta\operatorname{}{y_{i}\left( \mathbf{w}^{*} \right)^{T}\mathbf{\phi}_{i}}}{\left\| \mathbf{w}^{*} \right\|_{2}}\)</span>
is independent of <span class="math notranslate nohighlight">\(t\)</span>. <em>For the upper bound</em>, notice</p>
<div class="math notranslate nohighlight">
\[{\mathbf{w}^{\left( 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)}\mathbf{=}\eta y_{i_{1}}\mathbf{\phi}_{i_{1}}
}{\mathbf{w}^{\left( 2 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)}\mathbf{=}\eta y_{i_{1}}\mathbf{\phi}_{i_{1}}\mathbf{+}\eta y_{i_{2}}\mathbf{\phi}_{i_{2}}\mathbf{=}\left( \mathbf{w}^{\left( 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right) + \eta y_{i_{2}}\mathbf{\phi}_{i_{2}}
}{\mathbf{w}^{\left( 3 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)}\mathbf{=}\eta y_{i_{1}}\mathbf{\phi}_{i_{1}}\mathbf{+}\eta y_{i_{2}}\mathbf{\phi}_{i_{2}}\mathbf{+}\eta y_{i_{3}}\mathbf{\phi}_{i_{3}}\mathbf{=}\boxed{\left( \mathbf{w}^{\left( 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right)} + \left( \mathbf{w}^{\left( 2 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right) - \boxed{\left( \mathbf{w}^{\left( 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right)} + \eta y_{i_{3}}\mathbf{\phi}_{i_{3}}\mathbf{=}\left( \mathbf{w}^{\left( 2 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right) + \eta y_{i_{3}}\mathbf{\phi}_{i_{3}}}\]</div>
<p>and generally</p>
<div class="math notranslate nohighlight">
\[\mathbf{w}^{\left( t \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)}\mathbf{=}\left( \mathbf{w}^{\left( t - 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right) + \eta y_{i_{t}}\mathbf{\phi}_{i_{t}}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\left\| \mathbf{w}^{\left( t \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} = \left\| \mathbf{w}^{\left( t - 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} + \eta^{2}\left\| \mathbf{\phi}_{i_{t}} \right\|_{2}^{2}\mathbf{+}2\eta y_{i_{t}}\left( \mathbf{w}^{\left( t - 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right)^{T}\mathbf{\phi}_{i_{t}}\]</div>
<p>Note
<span class="math notranslate nohighlight">\(y_{i_{t}}\left( \mathbf{w}^{\left( t - 1 \right)} \right)^{T}\mathbf{\phi}_{i_{t}}\mathbf{&lt;}0\)</span>
because we assume <span class="math notranslate nohighlight">\(\mathcal{e}_{p} \neq 0\)</span> at step <span class="math notranslate nohighlight">\(t\)</span>.
Therefore,</p>
<div class="math notranslate nohighlight">
\[\left\| \mathbf{w}^{\left( t \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} \leq \left\| \mathbf{w}^{\left( t - 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} + \eta^{2}\left\| \mathbf{\phi}_{i_{t}} \right\|_{2}^{2}\mathbf{-}2\eta y_{i_{t}}\left( \mathbf{w}^{\left( 0 \right)} \right)^{T}\mathbf{\phi}_{i_{t}}\]</div>
<p>which gives</p>
<div class="math notranslate nohighlight">
\[{\left\| \mathbf{w}^{\left( 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} = \eta^{2}\left\| \mathbf{\phi}_{i_{1}} \right\|_{2}
}{\left\| \mathbf{w}^{\left( 2 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} \leq \left\| \mathbf{w}^{\left( 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} + \eta^{2}\left\| \mathbf{\phi}_{i_{2}} \right\|_{2}^{2}\mathbf{-}2\eta y_{i_{2}}\left( \mathbf{w}^{\left( 0 \right)} \right)^{T}\mathbf{\phi}_{i_{2}}
}{\ldots
}{\left\| \mathbf{w}^{\left( t \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} \leq \left\| \mathbf{w}^{\left( t - 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} + \eta^{2}\left\| \mathbf{\phi}_{i_{t}} \right\|_{2}^{2}\mathbf{-}2\eta y_{i_{t}}\left( \mathbf{w}^{\left( 0 \right)} \right)^{T}\mathbf{\phi}_{i_{t}}}\]</div>
<p>Adding up these inequalities, we can cancel terms on both sizes as the
following,</p>
<div class="math notranslate nohighlight">
\[{\boxed{\left\| \mathbf{w}^{\left( 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2}} = \eta^{2}\left\| \mathbf{\phi}_{i_{1}} \right\|_{2}
}{\boxed{\left\| \mathbf{w}^{\left( 2 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2}} \leq \boxed{\left\| \mathbf{w}^{\left( 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2}} + \eta^{2}\left\| \mathbf{\phi}_{i_{2}} \right\|_{2}^{2}\mathbf{-}2\eta y_{i_{2}}\left( \mathbf{w}^{\left( 0 \right)} \right)^{T}\mathbf{\phi}_{i_{2}}
}{\ldots
}{\left\| \mathbf{w}^{\left( t \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} \leq \boxed{\left\| \mathbf{w}^{\left( t - 1 \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2}} + \eta^{2}\left\| \mathbf{\phi}_{i_{t}} \right\|_{2}^{2}\mathbf{-}2\eta y_{i_{t}}\left( \mathbf{w}^{\left( 0 \right)} \right)^{T}\mathbf{\phi}_{i_{t}}}\]</div>
<p>and therefore</p>
<div class="math notranslate nohighlight">
\[\left\| \mathbf{w}^{\left( t \right)}\mathbf{-}\mathbf{w}^{\left( 0 \right)} \right\|_{2}^{2} \leq \eta^{2}\left( \left\| \mathbf{\phi}_{i_{1}} \right\|_{2}^{2}\mathbf{+ \ldots +}\left\| \mathbf{\phi}_{i_{t}} \right\|_{2}^{2} \right)\mathbf{-}2\mathbf{\eta}\left( \mathbf{w}^{\left( 0 \right)} \right)^{T}\left( y_{i_{2}}\mathbf{\phi}_{i_{2}}\mathbf{+ \ldots +}y_{i_{t}}\mathbf{\phi}_{i_{t}} \right)\mathbf{\leq}\eta^{2}\left( \operatorname{}\left\| \mathbf{\phi}_{i_{t}} \right\|_{2}^{2} \right)t - 2\eta\left( \operatorname{}{y_{i_{t}}\left( \mathbf{w}^{\left( 0 \right)} \right)^{T}\mathbf{\phi}_{i_{t}}} \right)t\]</div>
<p>where we see
<span class="math notranslate nohighlight">\(b = \eta^{2}\left( \operatorname{}\left\| \mathbf{\phi}_{i_{t}} \right\|_{2}^{2} \right) - 2\eta\left( \operatorname{}{y_{i_{t}}\left( \mathbf{w}^{\left( 0 \right)} \right)^{T}\mathbf{\phi}_{i_{t}}} \right)\)</span>,
independent of <span class="math notranslate nohighlight">\(t\)</span>.</p>
</div>
<div class="section" id="membership-lse">
<h5>Membership LSE<a class="headerlink" href="#membership-lse" title="Permalink to this headline">¶</a></h5>
<ul>
<li><p class="first"><strong>Theorem</strong> <strong>2‑6</strong><strong>Membership LSE</strong>. Least squared error method
for regression (see <em>Theorem 2‑1</em>) can be adapted for classification;
however, direct use the categorical values of the class labels as
regression target is usually less favorable due to both performance
issues and interpretation difficulty.</p>
<p>One adaption is to convert class labels into membership vectors.
Define a new target vector <span class="math notranslate nohighlight">\(\mathbf{z}_{j}\)</span>, roughly named the
<strong>membership vector</strong>, for each class label
<span class="math notranslate nohighlight">\(y_{j},j = 1,\ldots,N\)</span></p>
<p><span class="math notranslate nohighlight">\(\mathbf{z}_{j}\mathbf{=}\begin{pmatrix}
t_{1,j} \\
\mathbf{\vdots} \\
t_{K,j} \\
\end{pmatrix} \in \left\{ 0,1 \right\}^{K},j = 1,\ldots,N\)</span> s.t.
<span class="math notranslate nohighlight">\(t_{i,j} = 1_{y_{j} = i}\)</span> for <span class="math notranslate nohighlight">\(i = 1,\ldots,K\)</span></p>
<p>That is, only one component of <span class="math notranslate nohighlight">\(\mathbf{z}_{j}\)</span> is assigned
<span class="math notranslate nohighlight">\(1\)</span> with all other components being <span class="math notranslate nohighlight">\(0\)</span>. If
<span class="math notranslate nohighlight">\(t_{i,j} = 1\)</span> for some <span class="math notranslate nohighlight">\(i\)</span>, then <span class="math notranslate nohighlight">\(y_{j} = i\)</span>,
indicating <span class="math notranslate nohighlight">\(\mathbf{x}_{j} \in C_{i}\)</span>. Then the whole target
matrix is
<span class="math notranslate nohighlight">\(\mathbf{Z} = \left( \mathbf{z}_{1},\ldots,\mathbf{z}_{N} \right)\)</span>.
By (2‑4) we have the regression model
<span class="math notranslate nohighlight">\(\widehat{\mathbf{Z}}\mathbf{=}\mathbf{W}^{T}\mathbf{\Phi}\)</span>,
and the objective of LSE is to minimize
<span class="math notranslate nohighlight">\(\left\| \mathbf{Z} - \widehat{\mathbf{Z}} \right\|_{F}^{2}\)</span>.
We have the solution by (2‑6) and (2‑7) of <em>Theorem 2‑1</em> that</p>
</li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{W}^{\mathbf{*}}\mathbf{=}\left( \mathbf{\Phi}^{T} \right)^{\dagger}\mathbf{Z}^{T}\]</div>
<p>Using the fact that
<span class="math notranslate nohighlight">\(\left( \mathbf{\Phi}^{T} \right)^{\dagger} = \left( \mathbf{\Phi}^{\mathbf{\dagger}} \right)^{T}\)</span>,
we have</p>
<div class="math notranslate nohighlight">
\[\mathbf{W}^{\mathbf{*}}\mathbf{=}\left( \mathbf{\Phi}^{\dagger} \right)^{T}\mathbf{Z}^{T}\mathbf{\Rightarrow}\left( \mathbf{W}^{\mathbf{*}} \right)^{T}\mathbf{= Z}\mathbf{\Phi}^{\dagger}\]</div>
<p>And the regression function is</p>
<div class="math notranslate nohighlight">
\[f\left( \mathbf{x} \right) = \mathbf{Z}\mathbf{\Phi}^{\dagger}\phi\left( \mathbf{x} \right)\]</div>
<p>Note the discriminant function is different, which needs to yield a
class label. We heuristically set it as</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathcal{f}\]</div>
<p class="last">left( mathbf{x} ri
ght) = max{fleft( mathbf{x} right)}</p>
</td>
<td>&#160;</td>
<td>(2‑29)</td>
</tr>
</tbody>
</table>
<p>As a special case, if <span class="math notranslate nohighlight">\(\mathbf{\Phi} ≔ \begin{pmatrix}
\mathbf{1}^{T} \\
\mathbf{X} \\
\end{pmatrix}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{W} ≔ \begin{pmatrix}
\mathbf{w}_{0}^{T} \\
\mathbf{W} \\
\end{pmatrix}\)</span>, then by (2‑11) of <em>Theorem 2‑1</em>, we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{ \begin{matrix}
\mathbf{w}_{0}^{*} = \overline{\mathbf{z}} - \left( \mathbf{W}^{\mathbf{*}} \right)^{T}\overline{\mathbf{x}} \\
\mathbf{W}^{*} = \left( {\widetilde{\mathbf{X}}}^{\dagger} \right)^{T}{\widetilde{\mathbf{Z}}}^{T}\mathbf{,}\left( \mathbf{W}^{\mathbf{*}} \right)^{T}\mathbf{=}\widetilde{\mathbf{Z}}{\widetilde{\mathbf{X}}}^{\dagger} \\
\end{matrix} \right.\\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\overline{\mathbf{x}},\overline{\mathbf{z}}\)</span> are the mean
vector of <span class="math notranslate nohighlight">\(\mathbf{X},\mathbf{Z}\)</span>, and
<span class="math notranslate nohighlight">\(\widetilde{\mathbf{X}},\widetilde{\mathbf{Z}}\)</span> are centralized
data. Then the regression function is</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[g\left( \ma\]</div>
<p class="last">thbf{x} right) = le
ft( mathbf{W}^{math
bf{*}} right)^{T}ma
thbf{x +}mathbf{w}_{
0}^{*}mathbf{=}left
( mathbf{W}^{mathbf
{*}} right)^{T}math
bf{x +}overline{mat
hbf{z}} - left( mat
hbf{W}^{mathbf{*}} right)^{T}overline{mathbf{x}} = widetil
de{mathbf{Z}}{widet
ilde{mathbf{X}}}^{d
agger}widetilde{mat
hbf{x}}mathbf{+}ove
rline{mathbf{z}}</p>
</td>
<td>&#160;</td>
<td>(2‑30)</td>
</tr>
</tbody>
</table>
<p>There are many <em>limitations</em> of LSE for classification. It inherits the
sensitivity to outliers as mentioned in <em>Theorem 2‑1</em>; secondly, the
efficiency of LSE quickly degenerates when <span class="math notranslate nohighlight">\(K\)</span> increases; thirdly,
the discriminant decision is made based on the maximum of the inferred
membership weights of <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>, but we lack good
interpretation of <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>; one example for (2‑30) is shown in
the following property.</p>
<p><strong>Property</strong> <strong>2‑1</strong> If <span class="math notranslate nohighlight">\(\mathbf{a}^{T}\mathbf{z}_{j} = b\)</span> for
every <span class="math notranslate nohighlight">\(j = 1,\ldots,N\)</span>, then we have
<span class="math notranslate nohighlight">\(\mathbf{a}^{T}g\left( \mathbf{x} \right) = b\)</span>. Let
<span class="math notranslate nohighlight">\(\mathbf{b} = b\mathbf{1}\)</span>, then</p>
<div class="math notranslate nohighlight">
\[\mathbf{a}^{T}\overline{\mathbf{z}} = \frac{1}{N}\mathbf{a}^{T}\left( \mathbf{z}_{1} + \ldots + \mathbf{z}_{N} \right) = b \Rightarrow \mathbf{a}^{T}\overline{\mathbf{Z}} = \mathbf{b}\mathbf{\Rightarrow}\mathbf{a}^{T}\widetilde{\mathbf{Z}}\mathbf{=}\mathbf{a}^{T}\left( \mathbf{Z}\mathbf{-}\overline{\mathbf{Z}} \right)\mathbf{=}\mathbf{b}^{T}\mathbf{-}\mathbf{b}^{T}\mathbf{= 0}\mathbf{\Rightarrow}\mathbf{a}^{T}g\left( \mathbf{x} \right) = \mathbf{a}^{T}\left( \widetilde{\mathbf{Z}}{\widetilde{\mathbf{X}}}^{\dagger}\widetilde{\mathbf{x}}\mathbf{+}\overline{\mathbf{z}} \right) = \mathbf{a}^{T}\overline{\mathbf{z}} = b\]</div>
<p>In particular, if we let <span class="math notranslate nohighlight">\(\mathbf{a} = \mathbf{1}\)</span>, then
<span class="math notranslate nohighlight">\(b = 1\)</span>, and <span class="math notranslate nohighlight">\(\mathbf{1}^{T}\mathbf{z}_{j} = 1\)</span> holds for
every <span class="math notranslate nohighlight">\(j = 1,\ldots,N\)</span>. Therefore
<span class="math notranslate nohighlight">\(\mathbf{1}^{T}g\left( \mathbf{x} \right) = 1\)</span> for any
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, i.e. the inferred membership of any data entry
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span> under <span class="math notranslate nohighlight">\(g\)</span> in (2‑30) sums to 1. However, we
<em>note</em> it is not guaranteed <span class="math notranslate nohighlight">\(\mathbf{z}_{j}\)</span> is a probabilistic
vector under, i.e. it may have components not in
<span class="math notranslate nohighlight">\(\left\lbrack 0,1 \right\rbrack\)</span>, which is one limitation of LSE.</p>
<ul class="simple">
<li><strong>Theorem</strong> <strong>2‑6</strong><strong>Fisher’s Binary Linear Discriminant</strong>. For
simplicity and WLOG, we consider
<span class="math notranslate nohighlight">\(\phi\left( \mathbf{x} \right) ≔ \begin{pmatrix}
1 \\
\mathbf{x} \\
\end{pmatrix}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{w} ≔ \begin{pmatrix}
w_{0} \\
\mathbf{w} \\
\end{pmatrix}\)</span>, and we start with binary classification. By (2‑28),
the general form of a binary discriminant is</li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\mathcal{f}\left( \mathbf{x} \right) = \left\{ \begin{matrix}
1 &amp; \mathbf{x}^{T}\mathbf{w} \geq - w_{0} \\
0 &amp; \mathbf{x}^{T}\mathbf{w} &lt; - w_{0} \\
\end{matrix} \right.\ \\end{split}\]</div>
<p>The <em>idea</em> is those <span class="math notranslate nohighlight">\(\mathcal{f}\left( \mathbf{x}^{0} \right)\)</span> for
<span class="math notranslate nohighlight">\(\mathbf{x}^{0} \in C_{0}\)</span> should be as far away from those
<span class="math notranslate nohighlight">\(\mathcal{f}\left( \mathbf{x}^{1} \right)\)</span> for
<span class="math notranslate nohighlight">\(\mathbf{x}^{1} \in C_{1}\)</span>. The distance between two sets of data
entries can be characterized by the mean of the data.</p>
<div class="math notranslate nohighlight">
\[{\overline{\mathbf{x}}}^{i} = \frac{1}{N_{i}}\sum_{\mathbf{x} \in C_{i}}^{}\mathbf{x},i = 0,1\]</div>
<p>We would like to maximize</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\operatorna\]</div>
<p class="last">me{}left( mathbf{w}
^{T}{overline{mathb
f{x}}}^{1} - mathbf{
w}^{T}{overline{mat
hbf{x}}}^{0} right)
= operatorname{}{ma
thbf{w}^{T}left( {o
verline{mathbf{x}}}^
{1} - {overline{mat
hbf{x}}}^{0} right)}</p>
</td>
<td>&#160;</td>
<td>(2‑31)</td>
</tr>
</tbody>
</table>
<p>where the normalization <span class="math notranslate nohighlight">\(\left\| \mathbf{w} \right\|_{2} = 1\)</span> is
to prevent the objective from going to infinity. A less obvious issue is
that when <span class="math notranslate nohighlight">\(\mathbf{w}^{T}C_{0}\)</span> or <span class="math notranslate nohighlight">\(\mathbf{w}^{T}C_{1}\)</span> or
both have large variance, then
<span class="math notranslate nohighlight">\(\mathbf{w}^{T}\left( {\overline{\mathbf{x}}}^{0} - {\overline{\mathbf{x}}}^{1} \right)\)</span>
could be large but <span class="math notranslate nohighlight">\(\mathbf{w}^{T}C_{0}\)</span> or
<span class="math notranslate nohighlight">\(\mathbf{w}^{T}C_{1}\)</span> may have considerable overlap. The variance
is written as the following,</p>
<div class="math notranslate nohighlight">
\[s_{i}^{2} = \sum_{\mathbf{x} \in C_{i}}^{}{\left( \mathbf{w}^{T}\left( \mathbf{x -}{\overline{\mathbf{x}}}^{i} \right) \right)\left( \mathbf{w}^{T}\left( \mathbf{x -}{\overline{\mathbf{x}}}^{i} \right) \right)^{T}},i = 0,1\]</div>
<p>Therefore, we would like to minimize the variance of
<span class="math notranslate nohighlight">\(\mathbf{w}^{T}C_{0}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{w}^{T}C_{1}\)</span> as well.</p>
<table border="1" class="docutils">
<colgroup>
<col width="86%" />
<col width="3%" />
<col width="11%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first last math notranslate nohighlight">
\[\operatorname{}\left( s_{0}^{2} + s_{1}^{2} \right)\]</div>
</td>
<td>&#160;</td>
<td>(2‑32)</td>
</tr>
</tbody>
</table>
<p>Therefore, combining (2‑31) and (2‑32) we give the <strong>Fisher’s
criterion</strong> as the squared distance of mean over the sum of variance,</p>
<div class="math notranslate nohighlight">
\[\max_{\left\| \mathbf{w} \right\|_{2} = 1}L = \operatorname{}\frac{\left( \mathbf{w}^{T}\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right) \right)^{2}}{s_{0}^{2} + s_{1}^{2}} = \operatorname{}\frac{\mathbf{w}^{T}\mathbf{\text{Mw}}}{\mathbf{w}^{T}\left( \mathbf{S}_{0}\mathbf{+}\mathbf{S}_{1} \right)\mathbf{w}}\]</div>
<p>where
<span class="math notranslate nohighlight">\(\mathbf{M =}\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right)\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right)^{T}\)</span>
and
<span class="math notranslate nohighlight">\(\mathbf{S}_{i}\mathbf{=}\sum_{\mathbf{x} \in C_{i}}^{}{\left( \mathbf{x -}{\overline{\mathbf{x}}}^{i} \right)\left( \mathbf{x -}{\overline{\mathbf{x}}}^{i} \right)^{T}}\)</span>
is the covariance matrix of class <span class="math notranslate nohighlight">\(C_{i}\)</span> for <span class="math notranslate nohighlight">\(i = 0,1\)</span>, and
all these matrices are symmetric. Then, let
<span class="math notranslate nohighlight">\(\mathbf{S} = \mathbf{S}_{0}\mathbf{+}\mathbf{S}_{1}\)</span> for
convenience,</p>
<div class="math notranslate nohighlight">
\[\nabla L \propto \left( \mathbf{w}^{T}\mathbf{\text{Sw}} \right)\mathbf{\text{Mw}}\mathbf{-}\left( \mathbf{w}^{T}\mathbf{\text{Mw}} \right)\left( \mathbf{\text{Sw}} \right)\mathbf{=}0\mathbf{\Rightarrow}\left( \mathbf{w}^{T}\mathbf{\text{Sw}} \right)\mathbf{\text{Mw}}\mathbf{=}\left( \mathbf{w}^{T}\mathbf{\text{Mw}} \right)\left( \mathbf{\text{Sw}} \right)\]</div>
<p>We <em>note</em> there is no need for Lagrange multiplier for the constraint;
if we can find the direction of optimal <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>, we just
normalize it to unit vector. Note
<span class="math notranslate nohighlight">\(\mathbf{Mw =}\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right)\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right)^{T}\mathbf{w}\mathbf{\propto}{\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0}\)</span>,
then f or some constant <span class="math notranslate nohighlight">\(c\)</span>,</p>
<div class="math notranslate nohighlight">
\[\left( \mathbf{w}^{T}\mathbf{\text{Mw}} \right)\left( \mathbf{\text{Sw}} \right)\mathbf{=}c\left( \mathbf{w}^{T}\mathbf{\text{Sw}} \right)\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right)\mathbf{\Rightarrow}\mathbf{w =}\frac{c\left( \mathbf{w}^{T}\mathbf{\text{Sw}} \right)}{\mathbf{w}^{T}\mathbf{\text{Mw}}}\mathbf{S}^{- 1}\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right)\]</div>
<p>Since we need to normalize <span class="math notranslate nohighlight">\(w\)</span> anyway, we do not care the
constant, therefore we have the following <strong>Fisher’s discriminant</strong>.</p>
<div class="math notranslate nohighlight">
\[\mathbf{w}^{\mathbf{*}}\mathbf{\propto}\mathbf{S}^{- 1}\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right)\]</div>
<p><strong>Connection to LSE &amp; Optimal</strong> <span class="math notranslate nohighlight">\(w_{0}^{*}\)</span>. There are many
strategies to determine <span class="math notranslate nohighlight">\(w_{0}\)</span>, e.g. one way to do this is to set
<span class="math notranslate nohighlight">\(w_{0}\)</span> naively as
<span class="math notranslate nohighlight">\(w_{0}^{*} = \frac{1}{2}\left( \mathbf{w}^{*} \right)^{T}\left( \mathbf{x}_{1} - \mathbf{x}_{0} \right)\)</span>.
One better quantitative approach to find optimal <span class="math notranslate nohighlight">\(w_{0}\)</span> is
through LSE, by direct regression to class labels (rather than
membership vectors in <em>Theorem 2‑5</em>). We show Fisher’s discriminant is
equivalent to a LSE with special label coding, and therefore
<span class="math notranslate nohighlight">\(w_{0}\)</span> can be found by taking derivative. First, LSE minimizes</p>
<div class="math notranslate nohighlight">
\[\sum_{\left( \mathbf{x,}y \right) \in C_{0}}^{}\left( y - w_{0}\mathbf{-}\mathbf{x}^{T}\mathbf{w} \right)^{2} + \sum_{\left( \mathbf{x,}y \right) \in C_{1}}^{}\left( y - w_{0}\mathbf{-}\mathbf{x}^{T}\mathbf{w} \right)^{2} \Rightarrow \sum_{\left( \mathbf{x,}y \right) \in C_{0}}^{}{\left( y - w_{0}\mathbf{-}\mathbf{x}^{T}\mathbf{w} \right)\mathbf{x}} + \sum_{\left( \mathbf{x,}y \right) \in C_{1}}^{}{\left( y - w_{0}\mathbf{-}\mathbf{x}^{T}\mathbf{w} \right)\mathbf{x}} = 0 \Rightarrow \sum_{\left( \mathbf{x,}y \right) \in C_{0}}^{}{\left( w_{0}\mathbf{+}\mathbf{x}^{T}\mathbf{w} \right)\mathbf{x}} + \sum_{\left( \mathbf{x,}y \right) \in C_{1}}^{}{\left( w_{0}\mathbf{+}\mathbf{x}^{T}\mathbf{w} \right)\mathbf{x}} = \sum_{i = 1}^{N}{y_{i}\mathbf{x}} \Rightarrow \sum_{\left( \mathbf{x,}y \right) \in C_{0}}^{}{\mathbf{x}\mathbf{x}^{T}\mathbf{w}} + \sum_{\left( \mathbf{x,}y \right) \in C_{1}}^{}{\mathbf{x}\mathbf{x}^{T}\mathbf{w}} + \sum_{\left( \mathbf{x,}y \right) \in C_{0}}^{}{w_{0}\mathbf{x}} + \sum_{\left( \mathbf{x,}y \right) \in C_{1}}^{}{w_{0}\mathbf{x}} = \sum_{i = 1}^{N}{y_{i}\mathbf{x}_{i}}\]</div>
<p>Then plug in (2‑9) of <em>Theorem 2‑1</em> and have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\left( \sum\]</div>
<dl class="docutils">
<dt>_{left( mathbf{x,}y</dt>
<dd>right) in C_{0}}^{</dd>
</dl>
<p>}{mathbf{x}mathbf{x
}^{T}} + sum_{left(</p>
<blockquote>
<div>mathbf{x,}y right)
in C_{1}}^{}{mathb</div></blockquote>
<dl class="docutils">
<dt>f{x}mathbf{x}^{T}} -</dt>
<dd>sum_{left( mathbf</dd>
</dl>
<p class="last">{x,}y right) in C_{
0}}^{}{mathbf{x}{ov
erline{mathbf{x}}}^{
T}} - sum_{left( m
athbf{x,}y right) i
n C_{1}}^{}{mathbf{x
}{overline{mathbf{x
}}}^{T}} right)math
bf{w} = sum_{i = 1}^
{N}left( y_{i} - ov
erline{y} right)mat
hbf{x}_{i}</p>
</td>
<td>&#160;</td>
<td>(2‑33)</td>
</tr>
</tbody>
</table>
<p>By Corollary 1‑1, we have</p>
<div class="math notranslate nohighlight">
\[\sum_{\mathbf{x} \in C_{0}}^{}{\mathbf{x}\mathbf{x}^{T}} + \sum_{\mathbf{x} \in C_{1}}^{}{\mathbf{x}\mathbf{x}^{T}} = \mathbf{S} + N_{0}{\overline{\mathbf{x}}}^{0}\left( {\overline{\mathbf{x}}}^{0} \right)^{T} + N_{1}{\overline{\mathbf{x}}}^{1}\left( {\overline{\mathbf{x}}}^{1} \right)^{T}\]</div>
<p>Notice
<span class="math notranslate nohighlight">\(\overline{\mathbf{x}}\mathbf{=}\frac{1}{N}\left( N_{0}{\overline{\mathbf{x}}}^{0} + N_{1}{\overline{\mathbf{x}}}^{1} \right)\)</span>,
we have</p>
<div class="math notranslate nohighlight">
\[\sum_{\mathbf{x} \in C_{0}}^{}{\mathbf{x}{\overline{\mathbf{x}}}^{T}} = \left( \sum_{\mathbf{x} \in C_{0}}^{}{\frac{N_{0}}{N}\mathbf{x}} \right)\left( {\overline{\mathbf{x}}}^{0} \right)^{T} + \frac{N_{1}}{N}\left( \sum_{\mathbf{x} \in C_{0}}^{}\mathbf{x} \right)\left( {\overline{\mathbf{x}}}^{1} \right)^{T} = \frac{N_{0}^{2}}{N}{\overline{\mathbf{x}}}^{0}\left( {\overline{\mathbf{x}}}^{0} \right)^{T} + \frac{N_{0}N_{1}}{N}{\overline{\mathbf{x}}}^{0}\left( {\overline{\mathbf{x}}}^{1} \right)^{T}\]</div>
<div class="math notranslate nohighlight">
\[\sum_{\mathbf{x} \in C_{1}}^{}{\mathbf{x}{\overline{\mathbf{x}}}^{T}} = \left( \sum_{\mathbf{x} \in C_{1}}^{}{\frac{N_{0}}{N}\mathbf{x}} \right)\left( {\overline{\mathbf{x}}}^{0} \right)^{T} + \frac{N_{1}}{N}\left( \sum_{\mathbf{x} \in C_{1}}^{}\mathbf{x} \right)\left( {\overline{\mathbf{x}}}^{1} \right)^{T} = \frac{N_{0}N_{1}}{N}{\overline{\mathbf{x}}}^{1}\left( {\overline{\mathbf{x}}}^{0} \right)^{T} + \frac{N_{1}^{2}}{N}{\overline{\mathbf{x}}}^{1}\left( {\overline{\mathbf{x}}}^{1} \right)^{T}\]</div>
<p>Then the LHS of (2‑33) becomes</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{S}\]</div>
<ul class="simple">
<li>N_{0}{overline{ma</li>
</ul>
<p class="last">thbf{x}}}^{0}left( {
overline{mathbf{x}}
}^{0} right)^{T} + N
_{1}{overline{mathb
f{x}}}^{1}left( {ov
erline{mathbf{x}}}^{
1} right)^{T} - lef
t( frac{N_{0}^{2}}{N
}{overline{mathbf{x
}}}^{0}left( {overl
ine{mathbf{x}}}^{0}
right)^{T} + frac{N
_{0}N_{1}}{N}{overli
ne{mathbf{x}}}^{0}l
eft( {overline{math
bf{x}}}^{1} right)^{
T} + frac{N_{0}N_{1}
}{N}{overline{mathb
f{x}}}^{1}left( {ov
erline{mathbf{x}}}^{
0} right)^{T} + fra
c{N_{1}^{2}}{N}{over
line{mathbf{x}}}^{1}
left( {overline{ma
thbf{x}}}^{1} right)
^{T} right) = mathb
f{S} + frac{N_{0}N_{
1}}{N}left( {overli
ne{mathbf{x}}}^{0}l
eft( {overline{math
bf{x}}}^{0} right)^{
T} + {overline{math
bf{x}}}^{1}left( {o
verline{mathbf{x}}}^
{1} right)^{T} - {o
verline{mathbf{x}}}^
{0}left( {overline{
mathbf{x}}}^{1} rig
ht)^{T} - {overline{
mathbf{x}}}^{1}left
( {overline{mathbf{
x}}}^{1} right)^{T}
right)mathbf{=}mat
hbf{S}mathbf{+}frac
{N_{0}N_{1}}{N}mathb
f{M}</p>
</td>
<td>&#160;</td>
<td>(2‑34)</td>
</tr>
</tbody>
</table>
<p>For the RHS of (2‑33), suppose <span class="math notranslate nohighlight">\(y_{i} = c_{0}\)</span> for all
<span class="math notranslate nohighlight">\(\mathbf{x}_{i} \in C_{0}\)</span> and <span class="math notranslate nohighlight">\(y_{i} = c_{1}\)</span> for all
<span class="math notranslate nohighlight">\(\mathbf{x}_{i} \in C_{1}\)</span>, then</p>
<div class="math notranslate nohighlight">
\[\sum_{i = 1}^{N}\left( y_{i} - \overline{y} \right)\mathbf{x}_{i}\mathbf{=}\left( c_{0} - \overline{y} \right)\sum_{\mathbf{x} \in C_{0}}^{}\mathbf{x} + \left( c_{1} - \overline{y} \right)\sum_{\mathbf{x} \in C_{1}}^{}\mathbf{x} = \left( c_{0} - \overline{y} \right)N_{0}{\overline{\mathbf{x}}}^{0} + \left( c_{1} - \overline{y} \right)N_{1}{\overline{\mathbf{x}}}^{1}\]</div>
<p>As a result, if we let
<span class="math notranslate nohighlight">\(\left( c_{1} - \overline{y} \right)N_{1} = - \left( c_{0} - \overline{y} \right)N_{0}\)</span>,
then the RHS will be
<span class="math notranslate nohighlight">\({\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0}\)</span> times
a constant. This happens when simply</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\left\{ \begin{mat\]</div>
<dl class="docutils">
<dt>rix}</dt>
<dd>c_{0} = - frac{N}</dd>
<dt>{N_{0}} \</dt>
<dd>c_{1} = frac{N}{N</dd>
<dt>_{1}} \</dt>
<dd>end{matrix} righ</dd>
</dl>
<p>t. Rightarrow ove
rline{y} = frac{1}{N
}left( N_{0}c_{0} +
N_{1}c_{1} right) =
frac{1}{N}left( - N</p>
<blockquote>
<div><ul class="simple">
<li>N right) = 0 Rig</li></ul></blockquote>
<p class="last">htarrow left( c_{1}
- overline{y} right
)N_{1} = - left( c_{
0} - overline{y} ri
ght)N_{0} = N Righta
rrow sum_{i = 1}^{N}
left( y_{i} - overl
ine{y} right)mathbf
{x}_{i} = Nleft( {o
verline{mathbf{x}}}^
{1} - {overline{mat
hbf{x}}}^{0} right)</p>
</td>
<td>&#160;</td>
<td>(2‑35)</td>
</tr>
</tbody>
</table>
<p>Combining (2‑33), (2‑34) and (2‑35), we have</p>
<div class="math notranslate nohighlight">
\[\left( \mathbf{S}\mathbf{+}\frac{N_{0}N_{1}}{N}\mathbf{M} \right)\mathbf{w} = N\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right) \Rightarrow \mathbf{Sw =}\left( N - \frac{N_{0}N_{1}}{N}\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right)^{T}\mathbf{w} \right)\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right) \Rightarrow \mathbf{w}^{\mathbf{*}}\mathbf{\propto}\mathbf{S}^{- 1}\left( {\overline{\mathbf{x}}}^{1} - {\overline{\mathbf{x}}}^{0} \right)\]</div>
<p>By this equivalence, we can find best <span class="math notranslate nohighlight">\(w_{0}\)</span> in terms LSE by
(2‑9) of <strong>Theorem 2‑1</strong>,</p>
<div class="math notranslate nohighlight">
\[w_{0}^{*} = \overline{y} - {\overline{\mathbf{x}}}^{T}\mathbf{w}^{\mathbf{*}}\]</div>
<p>Also, by this equivalence to LSE, Fisher’s discriminant has all
limitations of LSE.</p>
<p><strong>Theorem</strong> <strong>2‑7</strong><strong>Fisher’s Linear Discriminant for Mutiple
Classes</strong>. For</p>
</div>
<div class="section" id="sigmoid-softmax-function">
<h5>Sigmoid &amp; Softmax Function<a class="headerlink" href="#sigmoid-softmax-function" title="Permalink to this headline">¶</a></h5>
<p>In above models, each data point is hard-assigned to a class, by
designing activation function and hand-crafting objectives to optimize.
In contrast, the probabilistic models find distributions for
<span class="math notranslate nohighlight">\(p\left( C_{i}|\mathbf{\phi} \right)\)</span> for each feature data
<span class="math notranslate nohighlight">\(\mathbf{\phi}\)</span> rather than a hard assignment. Many classic
probabilistic classification models involve sigmoid function and its
extension softmax function.</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><a class="reference internal" href="media/image2.png"><img alt="image4" src="media/image2.png" style="width: 2.39126in; height: 1.49951in;" /></a></th>
<th class="head">&#160;</th>
<th class="head"><a class="reference internal" href="media/image3.png"><img alt="image5" src="media/image3.png" style="width: 2.46398in; height: 1.5in;" /></a></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><p class="first"><em>(a) Sigmoid
function</em>
:math:<a href="#id33"><span class="problematic" id="id34">`</span></a>sigmaleft( a</p>
<blockquote>
<div>right) = frac{1}{1
+ e^{- a}}`</div></blockquote>
<p class="last"><em>and</em>
<span class="math notranslate nohighlight">\(1 - \sigma\lef
t( a \right)\)</span></p>
</td>
<td>&#160;</td>
<td><p class="first"><em>(b) Logit function</em>
:math:<a href="#id35"><span class="problematic" id="id36">`</span></a>aleft( sigma</p>
<blockquote>
<div>right) = lnfrac{</div></blockquote>
<p class="last">sigma}{1 - sigma}`</p>
</td>
</tr>
</tbody>
</table>
<p><em>Figure</em> <em>2‑2 Sigmoid function and logit function.</em></p>
<p>The famous <strong>sigmoid function</strong> is defined as
<span class="math notranslate nohighlight">\(\sigma\left( a \right) = \frac{1}{1 + e^{- a}}\mathbb{:R \rightarrow}\left( 0,1 \right)\)</span>,
representing an S-shaped curve. Its inverse
<span class="math notranslate nohighlight">\(a = \ln\frac{\sigma}{1 - \sigma}\)</span> is called a <strong>logit function</strong>.
Also note <span class="math notranslate nohighlight">\(\sigma\left( a \right) \in \left( 0,1 \right)\)</span> and</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[1 - \sigma\\]</div>
<dl class="docutils">
<dt>left( a right) = 1 -</dt>
<dd>frac{1}{1 + e^{- a}</dd>
</dl>
<p>} = frac{e^{- a}}{1
+ e^{- a}} = frac{1}
{1 + e^{a}} Rightarr
ow 1 - sigmaleft( a</p>
<blockquote>
<div>right) = sigmalef</div></blockquote>
<p class="last">t( - a right)</p>
</td>
<td>&#160;</td>
<td>(2‑39)</td>
</tr>
</tbody>
</table>
<p>We therefore <em>note</em>
<span class="math notranslate nohighlight">\(\left( \sigma\left( a \right),\sigma\left( - a \right) \right)\)</span>
can be viewed as a Bernoulli distribution. The <strong>softmax function</strong>, or
<strong>normalized exponential function</strong>, can be viewed as an extension of
the distribution
<span class="math notranslate nohighlight">\(\left( \sigma\left( a \right),\sigma\left( - a \right) \right)\)</span>
to higher dimensions. Given a vector
<span class="math notranslate nohighlight">\(\mathbf{\alpha} = \left( \alpha_{1},\ldots,\alpha_{K} \right)\)</span>,
then the softmax outputs a multinomial distribution</p>
<div class="math notranslate nohighlight">
\[\sigma\left( \mathbf{\alpha} \right) = \left( \frac{e^{\alpha_{1}}}{\sum_{k = 1}^{K}e^{\alpha_{k}}},\ldots,\frac{e^{\alpha_{K}}}{\sum_{k = 1}^{K}e^{\alpha_{k}}} \right):\mathbb{R}^{K} \rightarrow \mathbb{R}^{K}\]</div>
<p>The name “softmax” contains “max” because it is a probability
distribution that preserves the information to find the maximum;
meanwhile, it is “soft” in contrast to another function called <strong>hardmax
function</strong>, which outputs a vector of zero components except for the
component corresponding to the largest value in <span class="math notranslate nohighlight">\(\mathbf{\alpha}\)</span>
is set <span class="math notranslate nohighlight">\(1\)</span>. In the <em>special case</em> of <span class="math notranslate nohighlight">\(K = 2\)</span>, the softmax
function is</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\sigma\left\]</div>
<p class="last">( alpha_{1},alpha_{
2} right) = left( frac{e^{alpha_{1}}}{
e^{alpha_{1}} + e^{alpha_{2}}},frac{e^{
alpha_{2}}}{e^{alph
a_{1}} + e^{alpha_{2
}}} right) = left(
frac{1}{1 + e^{- le
ft( alpha_{1} - alp
ha_{2} right)}},fra
c{1}{1 + e^{- left(
alpha_{2} - alpha_{
1} right)}} right)</p>
</td>
<td>&#160;</td>
<td>(2‑40)</td>
</tr>
</tbody>
</table>
<p>Comparing (2‑39) and (2‑40) we can see the relation between the sigmoid
parameter <span class="math notranslate nohighlight">\(a\)</span> and the two softmax parameter is
<span class="math notranslate nohighlight">\(a = \alpha_{1} - \alpha_{2}\)</span>. This extension is more concrete in
(2‑45) when both sigmoid and softmax functions are applied in
constructing probabilistic discriminants below.</p>
</div>
<div class="section" id="sigmoid-assumption">
<h5>Sigmoid Assumption<a class="headerlink" href="#sigmoid-assumption" title="Permalink to this headline">¶</a></h5>
<p>The models we discuss here are based on <strong>sigmoid assumption</strong>: for
<span class="math notranslate nohighlight">\(i = 1,2\)</span>, the probability that a data point belongs to a class
<span class="math notranslate nohighlight">\(C_{i}\)</span> is a sigmoid curve <span class="math notranslate nohighlight">\(\sigma\left( a_{i} \right)\)</span> of
some parameter <span class="math notranslate nohighlight">\(a_{i}\)</span>. It turns out that <span class="math notranslate nohighlight">\(a\)</span> has nice
interpretation and therefore the assumption makes sense. Given a feature
data <span class="math notranslate nohighlight">\(\mathbf{\phi}\)</span>, assume</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[p\left( C_{\]</div>
<p class="last">i}|mathbf{phi} rig
ht) = sigmaleft( <a href="#id71"><span class="problematic" id="id72">a_</span></a>
{i} right) = frac{1
}{1 + e^{- a_{i}}},i
= 1,2</p>
</td>
<td>&#160;</td>
<td>(2‑41)</td>
</tr>
</tbody>
</table>
<p>where “<span class="math notranslate nohighlight">\(p\left( C_{i}|\mathbf{\phi} \right)\)</span>” is simplified
notation for
“<span class="math notranslate nohighlight">\(p\left( \mathbf{\phi} \in C_{i}|\mathbf{\phi} \right)\)</span>”.
Then we can solve <span class="math notranslate nohighlight">\(a_{1}\)</span> by</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[p\left( C_{\]</div>
<p>1}|mathbf{phi} rig
ht) = frac{pleft( mathbf{phi}|C_{1} r
ight)pleft( C_{1} r
ight)}{pleft( mathb
f{phi}|C_{1} right)
pleft( C_{1} right)</p>
<blockquote>
<div><ul class="simple">
<li>pleft( mathbf{p</li></ul></blockquote>
<p>hi}|C_{2} right)ple
ft( C_{2} right)} =
sigmaleft( a_{1} r
ight) = frac{1}{1 +
e^{- a_{1}}} Rightar
row a_{1} = lnfrac{
sigma}{1 - sigma} =</p>
<blockquote>
<div>lnfrac{pleft( ma</div></blockquote>
<p class="last">thbf{phi}|C_{1} rig
ht)pleft( C_{1} rig
ht)}{pleft( mathbf{
phi}|C_{2} right)pleft( C_{2} right)}
= lnfrac{pleft( m
athbf{phi},C_{1} ri
ght)}{pleft( mathbf
{phi},C_{2} right)}</p>
</td>
<td>&#160;</td>
<td>(2‑42)</td>
</tr>
</tbody>
</table>
<p>And we have
<span class="math notranslate nohighlight">\(a_{2} = \ln\frac{p\left( \mathbf{\phi}|C_{2} \right)p\left( C_{2} \right)}{p\left( \mathbf{\phi}|C_{1} \right)p\left( C_{1} \right)} = \ln\frac{p\left( \mathbf{\phi},C_{2} \right)}{p\left( \mathbf{\phi},C_{1} \right)} = - a_{1}\)</span>,
which is consistent with (2‑39). We can also verify</p>
<div class="math notranslate nohighlight">
\[p\left( C_{1}|\mathbf{\phi} \right) + p\left( C_{2}|\mathbf{\phi} \right) = \frac{1}{1 + e^{- a_{1}}} + \frac{1}{1 + e^{- a_{2}}} = \frac{e^{a_{1}}}{e^{a_{1}} + 1} + \frac{1}{1 + e^{a_{1}}} = 1\]</div>
<p>These expressions are highly <em>interpretable</em>: note
<span class="math notranslate nohighlight">\(p\left( \mathbf{\phi} \right) = p\left( \mathbf{\phi},C_{1} \right) + p\left( \mathbf{\phi},C_{2} \right)\)</span>,
then if <span class="math notranslate nohighlight">\(p\left( \mathbf{\phi},C_{1} \right)\)</span> is much larger than
<span class="math notranslate nohighlight">\(p\left( \mathbf{\phi},C_{2} \right)\)</span>, then naturally it is more
likely for <span class="math notranslate nohighlight">\(\mathbf{x}\mathbf{\in}C_{1}\)</span>, and the
increase/decrease of the probability is S-shaped. Now for the general
case of multiple classes <span class="math notranslate nohighlight">\(C_{i},i = 1,\ldots,K\)</span>, we assume</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[p\left( C_{\]</div>
<p class="last">i}|mathbf{phi} rig
ht) = sigma_{i}left
( mathbf{alpha} ri
ght) = frac{e^{alph
a_{i}}}{sum_{k = 1}^
{K}e^{alpha_{k}}}</p>
</td>
<td>&#160;</td>
<td>(2‑43)</td>
</tr>
</tbody>
</table>
<p>Expand (2‑43) and we further have</p>
<div class="math notranslate nohighlight">
\[p\left( C_{i}|\mathbf{\phi} \right) = \frac{p\left( \mathbf{\phi}|C_{i} \right)p\left( C_{i} \right)}{\sum_{k = 1}^{K}{p\left( \mathbf{\phi}|C_{k} \right)p\left( C_{k} \right)}} = \frac{e^{\alpha_{i}}}{\sum_{k = 1}^{K}e^{\alpha_{k}}},i = 1,\ldots,K\]</div>
<p>The solution for <span class="math notranslate nohighlight">\(\alpha_{i},i = 1,\ldots,K\)</span> is not unique, but
the most intuitive one is</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[e^{\alpha_{\]</div>
<p class="last">i}} = pleft( mathbf
{phi}|C_{i} right)p
left( C_{i} right)
Rightarrow alpha_{i
} = ln{pleft( math
bf{phi}|C_{i} right
)pleft( C_{i} right
)} = ln{pleft( mat
hbf{phi,}C_{i} righ
t)}</p>
</td>
<td>&#160;</td>
<td>(2‑44)</td>
</tr>
</tbody>
</table>
<p><em>We can now turn to</em> model both
<span class="math notranslate nohighlight">\(p\left( \mathbf{\phi}|C_{i} \right)\)</span> and
<span class="math notranslate nohighlight">\(p\left( C_{i} \right)\)</span>; for example, <em>Lemma 2‑1</em> shows the
maximum likelihood of <span class="math notranslate nohighlight">\(p\left( C_{i} \right)\)</span> is proportional to
the class size observed in the training data regardless of what
<span class="math notranslate nohighlight">\(p\left( \mathbf{\phi}|C_{i} \right)\)</span> is, and <em>Theorem 2‑9</em> shows
<span class="math notranslate nohighlight">\(p\left( \mathbf{\phi}|C_{i} \right)\)</span> can be modelled Gaussian
maximum likelihood. If both <span class="math notranslate nohighlight">\(p\left( \mathbf{\phi}|C_{i} \right)\)</span>
and <span class="math notranslate nohighlight">\(p\left( C_{i} \right)\)</span>have analytical form, then
<span class="math notranslate nohighlight">\(\alpha_{i}\)</span> will have an analytical form. <em>In practice</em>, we could
find
<span class="math notranslate nohighlight">\(\alpha_{i} = \ln c + \ln{p\left( \mathbf{\phi,}C_{i} \right)}\)</span>
for some constant <span class="math notranslate nohighlight">\(c\)</span>. This does not matter as it is scaling every
<span class="math notranslate nohighlight">\(e^{\alpha_{i}}\)</span> by the constant <span class="math notranslate nohighlight">\(c\)</span> (e.g. see (2‑49)),</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[e^{\alpha_{\]</div>
<p>i}} = c times pleft
( mathbf{phi}|C_{i}</p>
<blockquote>
<div>right)pleft( C_{i}
right) Rightarrow</div></blockquote>
<p class="last">alpha_{i} = ln c +
ln{pleft( mathbf{phi,}C_{i} right)}</p>
</td>
<td>&#160;</td>
<td>(2‑44)</td>
</tr>
</tbody>
</table>
<p><em>For the special case</em> of <span class="math notranslate nohighlight">\(K = 2\)</span>, (2‑43) is consistent with
(2‑42), because by (2‑40) we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[a_{1} = \al\]</div>
<p>pha_{1} - alpha_{2}
= ln{pleft( mathbf
{phi,}C_{1} right)}</p>
<blockquote>
<div><ul class="simple">
<li>ln{pleft( mathb</li></ul></blockquote>
<p class="last">f{phi,}C_{2} right)
} = lnfrac{pleft(
mathbf{phi,}C_{1} right)}{pleft( math
bf{phi,}C_{2} right
)}</p>
</td>
<td>&#160;</td>
<td>(2‑45)</td>
</tr>
</tbody>
</table>
<p>At last, we note a multinomial distribution
<span class="math notranslate nohighlight">\(p\left( C_{i}|\mathbf{\phi} \right)\)</span> is analogous to the
deterministic membership vector defined in <em>Theorem 2‑6</em>, and can be
referred to as <strong>probabilistic membership</strong> or <strong>mixed membership</strong>, and
we say membership defined by (2‑43) is <strong>softmax membership</strong>. One
standard measure of the performance of a model that yields mixed
memberships is <strong>cross-entropy error</strong> as discussed earlier. In the case
of classification, it is
<span class="math notranslate nohighlight">\(\mathcal{e}_{c} = \sum_{i = 1}^{N}{\ln{p\left( y_{i}|\mathbf{\phi}_{i} \right)}}\)</span>
given data
<span class="math notranslate nohighlight">\(\mathbf{\Phi =}\left( \mathbf{\phi}_{1}\mathbf{,\ldots,}\mathbf{\phi}_{N} \right),\mathbf{y =}\left( y_{1},\ldots,y_{n} \right)^{T}\)</span>,
simply adding up the negative log probabilities of observed labels. The
negative cross entropy <span class="math notranslate nohighlight">\(\mathcal{- e}\)</span> also equals the
log-likelihood of <span class="math notranslate nohighlight">\(p\left( \mathbf{\Phi}|\mathbf{y} \right)\)</span>;
thus, maximizing the likelihood
<span class="math notranslate nohighlight">\(p\left( \mathbf{\Phi}|\mathbf{y} \right)\)</span> is equivalent to
minimizing the cross-entropy error. The <a class="reference external" href="#logistic-regression">logistic
regression</a> later aims at maximizing
<span class="math notranslate nohighlight">\(p\left( \mathbf{\Phi}|\mathbf{y} \right)\)</span> and hence minimizing
the cross-entropy error.</p>
</div>
<div class="section" id="class-probability-ml">
<h5>Class Probability ML<a class="headerlink" href="#class-probability-ml" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><strong>Lemma</strong> <strong>2‑1</strong><strong>Class Probability ML</strong>. We refer to
<span class="math notranslate nohighlight">\(p\left( C_{1} \right),\ldots,p\left( C_{K} \right)\)</span> as <strong>class
probabilities</strong>. We now show the MLE of class probabilities are
proportional to class size. For binary classification, we have the
likelihood</li>
</ul>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[p\left( \ma\]</div>
<dl class="docutils">
<dt>thbf{Phi},mathbf{y}</dt>
<dd>right) = pleft( m</dd>
</dl>
<p>athbf{Phi}|mathbf{y
} right)pleft( mat
hbf{y} right) = pro
d_{i = 1}^{N}{left(
pleft( C_{1} right)
pleft( mathbf{phi}
_{i}|C_{1} right) r
ight)^{y_{i}}left( p
left( C_{2} right)p
left( mathbf{phi}_
{i}|C_{2} right) ri
ght)^{1 - y_{i}}} Ri
ghtarrow ln p = sum
_{i = 1}^{N}left( <a href="#id73"><span class="problematic" id="id74">y_</span></a>
{i}left( ln{pleft(</p>
<blockquote>
<div>C_{1} right)} + ln</div></blockquote>
<p>{pleft( mathbf{phi
}_{i}|C_{1} right)}
right) + left( 1 -
y_{i} right)left( ln{pleft( C_{2} rig
ht)} + ln{pleft( m
athbf{phi}_{i}|C_{2}</p>
<blockquote>
<div>right)} right) ri</div></blockquote>
<p class="last">ght)</p>
</td>
<td>&#160;</td>
<td>(2‑46)</td>
</tr>
</tbody>
</table>
<p>Let <span class="math notranslate nohighlight">\(p\left( C_{1} \right) = \pi\)</span>, then
<span class="math notranslate nohighlight">\(p\left( C_{2} \right) = 1 - \pi\)</span>, and the terms dependent on
<span class="math notranslate nohighlight">\(\pi\)</span> are only</p>
<div class="math notranslate nohighlight">
\[\ln p \propto \sum_{i = 1}^{N}\left( y_{i}\ln\pi + \left( 1 - y_{i} \right)\ln\left( 1 - \pi \right) \right)\]</div>
<p>Taking derivative, we have</p>
<div class="math notranslate nohighlight">
\[\sum_{i = 1}^{N}\left( \frac{y_{i}}{\pi} - \frac{1 - y_{i}}{1 - \pi} \right) = 0 \Rightarrow \frac{1}{\pi}\sum_{i = 1}^{N}y_{i} = \frac{1}{1 - \pi}\sum_{i = 1}^{N}{1 - y_{i}} = 0 \Rightarrow \frac{1}{\pi}N_{1} = \frac{1}{1 - \pi}N_{2} = 0 \Rightarrow \pi = \frac{N_{1}}{N_{1} + N_{2}} = \frac{N_{1}}{N}\]</div>
<p>where <span class="math notranslate nohighlight">\(N_{1}\)</span> is the size of class <span class="math notranslate nohighlight">\(C_{1}\)</span>, and
<span class="math notranslate nohighlight">\(N_{2}\)</span> is the size of class <span class="math notranslate nohighlight">\(C_{2}\)</span>. This can be easily
extended to multiple classes. Let
<span class="math notranslate nohighlight">\(p\left( C_{i} \right) = \pi_{i},i = 1,\ldots,K\)</span>, then note
<span class="math notranslate nohighlight">\(\pi_{K} = 1 - \pi_{1} - \ldots - \pi_{K - 1}\)</span> is dependent of
previous probabilities, and</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[p\left( \ma\]</div>
<dl class="docutils">
<dt>thbf{Phi},mathbf{y}</dt>
<dd>right) = prod_{ma</dd>
</dl>
<p>thbf{phi} in C_{1}}
^{}{pi_{1}pleft( m
athbf{phi}|C_{1} ri
ght)} times ldots times prod_{mathbf{
phi} in C_{K}}^{}{pi_{K}pleft( mathbf
{phi}|C_{K} right)}</p>
<blockquote>
<div>Rightarrow ln p p</div></blockquote>
<p>ropto sum_{i = 1}^{N
_{1}}{lnpi_{1}} + ldots + sum_{i = 1}^
{N_{K}}{lnpi_{K}} =</p>
<blockquote>
<div>N_{1}lnpi_{1} + l</div></blockquote>
<p class="last">dots + N_{K}lnpi_{K
}</p>
</td>
<td>&#160;</td>
<td>(2‑47)</td>
</tr>
</tbody>
</table>
<p>Taking derivatives w.r.t. <span class="math notranslate nohighlight">\(\pi_{1},\ldots,\pi_{K - 1}\)</span> we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\frac{N_{i}\]</div>
<p class="last">}{pi_{i}} = frac{<a href="#id75"><span class="problematic" id="id76">N_</span></a>
{K}}{pi_{K}} Righta
rrow pi_{i} = frac{
N_{i}}{N_{K}}pi_{K},
i = 1,ldots,K - 1</p>
</td>
<td>&#160;</td>
<td>(2‑48)</td>
</tr>
</tbody>
</table>
<p>which implies</p>
<div class="math notranslate nohighlight">
\[1 - \pi_{K} = \sum_{i = 1}^{K - 1}\pi_{i} = \pi_{K}\sum_{i = 1}^{K - 1}\frac{N_{i}}{N_{K}} = \pi_{K}\frac{N - N_{K}}{N_{K}} \Rightarrow \pi_{K} = \frac{N_{K}}{N}\]</div>
<p>Plug this back in (2‑48), we have a general result</p>
<div class="math notranslate nohighlight">
\[{\widehat{\pi}}_{i} = \frac{N_{i}}{N},i = 1,\ldots,K\]</div>
</div>
<div class="section" id="gaussianml-softmax-discriminant">
<h5>GaussianML-Softmax Discriminant<a class="headerlink" href="#gaussianml-softmax-discriminant" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><strong>Theorem</strong> <strong>2‑9</strong><strong>GaussianML-Softmax Discriminant</strong>. For this
model, we assume the feature points in each class are Gaussian
distributed. The Gaussians of each class could have different means
<span class="math notranslate nohighlight">\(\mathbf{\mu}_{1},\ldots,\mathbf{\mu}_{K}\)</span> but the same
covariance <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span> to make the inferences for each
class dependent. That is,</li>
</ul>
<div class="math notranslate nohighlight">
\[p\left( \mathbf{\phi}|C_{i} \right)\sim\operatorname{Gaussian}\left( \mathbf{\mu}_{i},\mathbf{\Sigma} \right),i = 1,\ldots,K\]</div>
<p><em>Note</em> we may not assume each class has its own covariance, otherwise
this model reduces to independent maximum likelihoods of Gaussian
distributions. The shared covariance is clearly one limitation of
Gaussian ML; the other main limitation is it high complexity with
quadratically growing number of parameters (<span class="math notranslate nohighlight">\(K\)</span> considered fixed).
We show also again emphasize, like other MLE, it tends to suffer the
problem of overfitting and not robust to outliers (see <em>Theorem 2‑2</em>).
Using (2‑45), we have</p>
<div class="math notranslate nohighlight">
\[\ln p \propto \sum_{\mathbf{\phi \in}C_{1}}^{}{\ln{p\left( \mathbf{\phi}|C_{1} \right)}} + \ldots + \sum_{\mathbf{\phi \in}C_{K}}^{}{\ln{p\left( \mathbf{\phi}|C_{K} \right)}}\]</div>
<p>Clearly
<span class="math notranslate nohighlight">\(\frac{\partial\ln p}{\partial\mathbf{\mu}_{i}} = \frac{\partial}{\partial\mathbf{\mu}_{i}}\left( \sum_{\mathbf{\phi \in}C_{i}}^{}{\ln{p\left( \mathbf{\phi}|C_{i} \right)}} \right),i = 1,\ldots,K\)</span>,
which is the same as the MLE for <span class="math notranslate nohighlight">\(\mathbf{\mu}_{i}\)</span> Gaussian
likelihood
<span class="math notranslate nohighlight">\(\operatorname{Gaussian}\left( \mathbf{\mu}_{i},\mathbf{\Sigma} \right)\)</span>
given only the data in class <span class="math notranslate nohighlight">\(C_{i}\)</span>, and therefore by (1‑4) of
<em>Theorem 1‑4</em>,</p>
<div class="math notranslate nohighlight">
\[{\widehat{\mathbf{\mu}}}_{i} = \frac{1}{N_{i}}\sum_{\mathbf{\phi \in}C_{i}}^{}\mathbf{\phi},i = 1,\ldots,K\]</div>
<p>For covariance <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>, using (1‑3) of <em>Theorem 1‑4</em>, we
have</p>
<div class="math notranslate nohighlight">
\[\frac{\partial\ln p}{\partial\mathbf{\Sigma}^{- 1}} = \sum_{i = 1}^{K}\left( \frac{N_{i}}{2}\mathbf{\Sigma} - \frac{1}{2}\sum_{\mathbf{\phi \in}C_{i}}^{}{\left( \mathbf{\phi} - \mathbf{\mu}_{i} \right)\left( \mathbf{\phi} - \mathbf{\mu}_{i} \right)^{T}} \right) = \frac{N}{2}\mathbf{\Sigma -}\frac{1}{2}\sum_{i = 1}^{K}\left( \sum_{\mathbf{\phi \in}C_{i}}^{}{\left( \mathbf{\phi} - \mathbf{\mu}_{i} \right)\left( \mathbf{\phi} - \mathbf{\mu}_{i} \right)^{T}} \right) = 0 \Rightarrow \widehat{\mathbf{\Sigma}}\mathbf{=}\frac{1}{N}\sum_{i = 1}^{K}\left( \sum_{\mathbf{\phi \in}C_{i}}^{}{\left( \mathbf{\phi} - \mathbf{\mu}_{i} \right)\left( \mathbf{\phi} - \mathbf{\mu}_{i} \right)^{T}} \right)\]</div>
<p>Let
<span class="math notranslate nohighlight">\({\widehat{\mathbf{\Sigma}}}_{i} = \frac{1}{N_{i}}\sum_{\mathbf{\phi \in}C_{i}}^{}{\left( \mathbf{\phi} - \mathbf{\mu}_{i} \right)\left( \mathbf{\phi} - \mathbf{\mu}_{i} \right)^{T}},i = 1,\ldots,K\)</span>,
which is the biased sample covariance of each class, or the MLE of
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span> based only on the data from class <span class="math notranslate nohighlight">\(C_{i}\)</span>,
then</p>
<div class="math notranslate nohighlight">
\[\widehat{\mathbf{\Sigma}}\mathbf{=}\sum_{i = 1}^{K}{\frac{N_{i}}{N}{\widehat{\mathbf{\Sigma}}}_{i}} = \sum_{i = 1}^{K}{{\widehat{\pi}}_{i}{\widehat{\mathbf{\Sigma}}}_{i}}\]</div>
<p>Recall our eventual goal of a probabilistic discriminant is to solve
<span class="math notranslate nohighlight">\(p\left( C_{i}|\mathbf{\phi} \right)\)</span>. With sigmoid assumption,
<span class="math notranslate nohighlight">\(p\left( C_{i}|\mathbf{\phi} \right) = \sigma\left( \mathbf{\alpha} \right)\)</span>.
Note by discussion of (2‑43) and (2‑44), the constant is not important
and can be removed, and therefore</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\ln{p\left(
\mathbf{\phi}|C_{i}\]</div>
<p>right)pleft( C_{i}
right)} = lnfrac{1
}{left( 2pi right)
^{frac{m}{2}}} + ln
frac{1}{left| wide
hat{mathbf{Sigma}}
right|^{frac{1}{2}}
} - frac{1}{2}left(</p>
<blockquote>
<div>mathbf{phi} - {wi</div></blockquote>
<p class="last">dehat{mathbf{mu}}}_
{i} right)^{T}{wide
hat{mathbf{Sigma}}}
^{- 1}left( mathbf{
phi} - {widehat{ma
thbf{mu}}}_{i} righ
t) + lnfrac{N_{i}}{
N} Rightarrow alpha
_{i} = left( {wideh
at{mathbf{Sigma}}}^
{- 1}{widehat{mathb
f{mu}}}_{i} right)^
{T}mathbf{phi}math
bf{-}frac{1}{2}{wid
ehat{mathbf{mu}}}_{
i}^{T}{widehat{math
bf{Sigma}}}^{- 1}{w
idehat{mathbf{mu}}}
_{i} + lnfrac{N_{i}
}{N}</p>
</td>
<td>&#160;</td>
<td>(2‑49)</td>
</tr>
</tbody>
</table>
<p>We can rewrite</p>
<div class="math notranslate nohighlight">
\[\mathbf{\alpha} = \mathbf{W}^{T}\mathbf{\phi}\mathbf{+}\mathbf{b}\]</div>
<p>where
<span class="math notranslate nohighlight">\(\mathbf{W} = \left( \mathbf{w}_{1},\ldots,\mathbf{w}_{K} \right)\)</span>,
<span class="math notranslate nohighlight">\(\mathbf{w}_{i} = {\widehat{\mathbf{\Sigma}}}^{- 1}{\widehat{\mathbf{\mu}}}_{i}\)</span>,
and
<span class="math notranslate nohighlight">\(\mathbf{b}\mathbf{=}\left( b_{1}\mathbf{,\ldots,}b_{K} \right)\mathbf{,}b_{i} = \mathbf{-}\frac{1}{2}{\widehat{\mathbf{\mu}}}_{i}^{T}{\widehat{\mathbf{\Sigma}}}^{- 1}{\widehat{\mathbf{\mu}}}_{i} + \ln\frac{N_{i}}{N}\)</span>.
Therefore, the softmax parameter of Gaussian ML discriminant is linear
in <span class="math notranslate nohighlight">\(\mathbf{\phi}\)</span>.</p>
</div>
<div class="section" id="logistic-regression">
<h5>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h5>
<ul>
<li><p class="first">The complexity of above Gaussian ML discriminant in <em>Theorem 2‑9</em> is
usually considered too high. To reduce the complexity, the linearity
of softmax parameter in <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> provides inspiration. We
may conversely first restrict softmax parameter
<span class="math notranslate nohighlight">\(\mathbf{\alpha} = \mathbf{W}^{T}\mathbf{\phi}\)</span> with
<span class="math notranslate nohighlight">\(\mathbf{W}\)</span> as parameters. Such model has linear complexity if
<span class="math notranslate nohighlight">\(K\)</span> is fixed. Logistic regression is also more robust (see
(2‑55)) with Newton’s method for optimization. However, with reduced
model complexity, it loses a closed form solution for the multi-class
classification, as shown below.</p>
<p><strong>Binary logistic regression</strong>. For simplicity, we first consider
binary classification with labels <span class="math notranslate nohighlight">\(l_{1} = 1,l_{2} = 0\)</span>. The
model makes an i.i.d. Bernoulli <em>assumption</em> that
<span class="math notranslate nohighlight">\(y_{i}\sim\text{Bernoulli}\left( \sigma\left( \mathbf{\phi}_{i}^{T}\mathbf{w} \right) \right),\ i = 1,\ldots,N\)</span>,
or equivalently,</p>
</li>
</ul>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[p\left( C_{\]</div>
<p class="last">1}|mathbf{phi}_{i}
right) = sigmaleft
( mathbf{phi}_{i}^{
T}mathbf{w} right),
i = 1,ldots,N</p>
</td>
<td>&#160;</td>
<td>(2‑51)</td>
</tr>
</tbody>
</table>
<p>And we optimize the following likelihood (negative cross entropy),</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[p\left( \ma\]</div>
<p>thbf{Phi,y} right)
propto pleft( math
bf{y|Phi} right) =
prod_{i = 1}^{N}{le
ft( sigmaleft( mat
hbf{phi}_{i}^{T}mat
hbf{w} right) right
)^{y_{i}}left( 1 - sigmaleft( mathbf{phi}_{i}^{T}mathbf{w
} right) right)^{1
- y_{i}}} Rightarrow</p>
<blockquote>
<div>ln p = sum_{i = 1}</div></blockquote>
<p class="last">^{N}{y_{i}ln{sigmaleft( mathbf{phi}_{
i}^{T}mathbf{w} rig
ht)}} + sum_{i = 1}^
{N}{left( 1 - y_{i}
right)lnleft( 1 -
sigmaleft( mathbf{
phi}_{i}^{T}mathbf{
w} right) right)}</p>
</td>
<td>&#160;</td>
<td>(2‑52)</td>
</tr>
</tbody>
</table>
<p><em>Closed form solution</em>. The derivative of sigmoid
<span class="math notranslate nohighlight">\(\sigma\left( a \right) = \frac{1}{1 + e^{- a}}\)</span> is
<span class="math notranslate nohighlight">\(\frac{d\sigma}{da} = \sigma\left( 1 - \sigma \right)\)</span>. Applying
this and <em>Fact 1‑1</em> we have</p>
<div class="math notranslate nohighlight">
\[\nabla_{\mathbf{w}}\ln p = \sum_{i = 1}^{N}{\frac{y_{i}}{\sigma}\sigma\left( 1 - \sigma \right)\mathbf{\phi}_{i}} + \sum_{i = 1}^{N}{- \frac{\left( 1 - y_{i} \right)}{1 - \sigma}\sigma\left( 1 - \sigma \right)\mathbf{\phi}_{i}}\mathbf{=}\sum_{i = 1}^{N}{y_{i}\left( 1 - \sigma \right)\mathbf{\phi}_{i} - \left( 1 - y_{i} \right)\sigma\mathbf{\phi}_{i}}\mathbf{=}\sum_{i = 1}^{N}{\left( y_{i} - \sigma\left( \mathbf{\phi}_{i}^{T}\mathbf{w} \right) \right)\mathbf{\phi}_{i}}\]</div>
<p>Let :math:<a href="#id37"><span class="problematic" id="id38">`</span></a>mathbf{sigma =}begin{pmatrix}
sigma_{1} \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>sigma_{N} \
end{pmatrix} = begin{pmatrix}
sigmaleft( mathbf{phi}_{1}^{T}mathbf{w} right) \</p>
<blockquote>
<div>vdots \</div></blockquote>
<p>sigmaleft( mathbf{phi}_{N}^{T}mathbf{w} right) \
end{pmatrix}`, then</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\nabla_{\ma\]</div>
<p class="last">thbf{w}}ln p = math
bf{Phi}left( mathb
f{y}mathbf{-}mathbf
{sigma} right)</p>
</td>
<td>&#160;</td>
<td>(2‑53)</td>
</tr>
</tbody>
</table>
<p>and <span class="math notranslate nohighlight">\(\nabla_{\mathbf{w}}\ln p = \mathbf{0}\)</span> yields</p>
<div class="math notranslate nohighlight">
\[\mathbf{\sigma}^{\mathbf{*}}\mathbf{=}\left( \mathbf{\Phi} \right)^{\mathbf{\dagger}}\mathbf{\text{Φy}}\]</div>
<p>Let
<span class="math notranslate nohighlight">\(\mathbf{\sigma}^{*} = \left( \sigma_{1}^{*},\ldots,\sigma_{N}^{*} \right)^{T}\)</span>,
above can be further solved as</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{\Phi}^{T}\mathbf{w} = \begin{pmatrix}
\ln\frac{\sigma_{1}^{*}}{1 - \sigma_{1}^{*}} \\
 \vdots \\
\ln\frac{\sigma_{N}^{*}}{1 - \sigma_{N}^{*}} \\
\end{pmatrix} \Rightarrow \mathbf{w}^{\mathbf{*}}\mathbf{=}\left( \mathbf{\Phi}^{T} \right)^{\dagger}\begin{pmatrix}
\ln\frac{\sigma_{1}^{*}}{1 - \sigma_{1}^{*}} \\
 \vdots \\
\ln\frac{\sigma_{N}^{*}}{1 - \sigma_{N}^{*}} \\
\end{pmatrix}\end{split}\]</div>
<p><em>Iterative solutions</em>. Notice <span class="math notranslate nohighlight">\(\ln p\)</span> in (2‑50) is a strictly
concave function w.r.t. <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> since logarithm is strictly
concave and every <span class="math notranslate nohighlight">\(\mathbf{\phi}_{i}^{T}\mathbf{w}\)</span> is linear, so
the MLE for <span class="math notranslate nohighlight">\(\ln p\)</span> has unique solution and is solvable by classic
convex optimization algorithms like gradient ascent using (2‑51). Let
<span class="math notranslate nohighlight">\({\overline{\mathbf{\phi}}}_{1}\)</span> denote the sample mean of the
first class, and
<span class="math notranslate nohighlight">\(\mathbb{E}_{C_{1}}\left\lbrack \mathbf{\phi} \right\rbrack\)</span>
denote the expected data of the first class, then
<span class="math notranslate nohighlight">\(\mathbf{\Phi y =}N_{1}{\overline{\mathbf{\phi}}}_{1}\)</span> is the
sample feature sum of the first class, and
<span class="math notranslate nohighlight">\(\mathbf{\text{Φσ}}\mathbf{=}\sum_{i = 1}^{N}\left( p\left( C_{1}|\mathbf{\phi}_{i} \right)\mathbf{\phi}_{i} \right) = N\mathbb{E}_{C_{1}}\left\lbrack \mathbf{\phi} \right\rbrack\)</span>
is the expected feature sum of the first class, and therefore
<span class="math notranslate nohighlight">\(\nabla_{\mathbf{w}}\ln p = N_{1}{\overline{\mathbf{\phi}}}_{1} - N\mathbb{E}_{C_{1}}\left\lbrack \mathbf{\phi} \right\rbrack\)</span>,
i.e. the fastest ascending direction of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> points from
the expected sum to the sample sum, intuitively meaning the model is
evolving from the prior assumed distribution to fit the observed data.</p>
<p>We many also use <strong>Newton’s method</strong> that comes with quadratic
convergence, and its update is as the following,</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{w}^\]</div>
<p class="last">{left( t + 1 right)
} = mathbf{w}^{left
( t right)} - mathb
f{H}_{mathbf{w}}^{-
1}nabla_{mathbf{w}}
ln p</p>
</td>
<td>&#160;</td>
<td>(2‑51)</td>
</tr>
</tbody>
</table>
<p>where <span class="math notranslate nohighlight">\(\mathbf{H}_{\mathbf{w}}\)</span> is the negative definite (because
of being strictly concave) Hessian matrix of <span class="math notranslate nohighlight">\(\ln p\)</span> w.r.t.
<span class="math notranslate nohighlight">\(\mathbf{w}\)</span>, consisting of all second-order derivatives of
<span class="math notranslate nohighlight">\(\ln p\)</span> w.r.t. components of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>. Recall Hessian
matrix is the Jacobian of gradient. Denote Jacobian matrix using bold
symbol “<span class="math notranslate nohighlight">\(\mathbf{\nabla}\)</span>”, we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{\nabla}_{\mathbf{w}}\left( \mathbf{\sigma} \right)\mathbf{=}\begin{pmatrix}
\sigma_{1}\left( 1 - \sigma_{1} \right)\mathbf{\phi}_{1}^{T} \\
 \vdots \\
\sigma_{N}\left( 1 - \sigma_{N} \right)\mathbf{\phi}_{N}^{T} \\
\end{pmatrix} = \begin{pmatrix}
\sigma_{1}\left( 1 - \sigma_{1} \right) &amp; &amp; \\
 &amp; \ddots &amp; \\
 &amp; &amp; \sigma_{N}\left( 1 - \sigma_{N} \right) \\
\end{pmatrix}\mathbf{\Phi}^{T}\end{split}\]</div>
<p>Recall the model makes an i.i.d. Bernoulli assumption s.t.
<span class="math notranslate nohighlight">\(y_{i}\sim\text{Bernoulli}\left( \sigma\left( \mathbf{\phi}_{i}^{T}\mathbf{w} \right) \right)\)</span>,
and therefore the diagonal matrix :math:<a href="#id39"><span class="problematic" id="id40">`</span></a>begin{pmatrix}
sigma_{1}left( 1 - sigma_{1} right) &amp; &amp; \</p>
<blockquote>
<div>&amp; ddots &amp; \
&amp; &amp; sigma_{N}left( 1 - sigma_{N} right) \</div></blockquote>
<p>end{pmatrix}` is the covariance matrix of RV <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>. Denote
it as <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>, we arrive at</p>
<div class="math notranslate nohighlight">
\[\mathbf{\nabla}_{\mathbf{w}}\mathbf{\Phi}\left( \mathbf{y}\mathbf{-}\mathbf{\sigma} \right)\mathbf{=}\mathbf{\nabla}_{\mathbf{w}}\left( \mathbf{-}\mathbf{\text{Φσ}} \right)\mathbf{= -}\mathbf{\text{ΦΣ}}\mathbf{\Phi}^{T}\mathbf{\Rightarrow}\mathbf{H}_{\mathbf{w}} = \mathbf{\nabla}_{\mathbf{w}}\mathbf{\Phi}\left( \mathbf{y}\mathbf{-}\mathbf{\sigma} \right)\mathbf{= -}\mathbf{\text{ΦΣ}}\mathbf{\Phi}^{T}\]</div>
<p>Plug this back to (2‑51); <em>note</em> both
<span class="math notranslate nohighlight">\(\mathbf{\Sigma},\mathbf{\sigma}\)</span> are dependent on
<span class="math notranslate nohighlight">\(\mathbf{w}^{\left( t \right)}\)</span> and hence on <span class="math notranslate nohighlight">\(t\)</span>, but we
omit the superscript for simplicity. Then we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{w}^\]</div>
<p>{left( t + 1 right)
} = mathbf{w}^{left
( t right)} + left(</p>
<blockquote>
<div>mathbf{text{ΦΣ}}m</div></blockquote>
<p>athbf{Phi}^{T} righ
t)^{- 1}mathbf{Phi}
left( mathbf{y - s
igma} right)mathbf{
=}left( mathbf{tex
t{ΦΣ}}mathbf{Phi}^{
T} right)^{- 1}left
( mathbf{text{ΦΣ}}mathbf{Phi}^{T}math
bf{w}^{left( t righ
t)} + mathbf{Phi}l
eft( mathbf{y - sig
ma} right) right) =</p>
<blockquote>
<div>left( mathbf{text</div></blockquote>
<p>{ΦΣ}}mathbf{Phi}^{T
} right)^{- 1}mathb
f{text{ΦΣ}}left( m
athbf{Phi}^{T}mathb
f{w}^{left( t right
)} + mathbf{Sigma}^
{- 1}left( mathbf{y</p>
<blockquote>
<div><ul class="simple">
<li>sigma} right) r</li></ul></blockquote>
<p class="last">ight)</p>
</td>
<td>&#160;</td>
<td>(2‑54)</td>
</tr>
</tbody>
</table>
<p>Note (<em>2</em>‑<em>54</em>) coincide with the solution of weighted LSE as in EX
1, and therefore we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{w}^\]</div>
<p>{left( t + 1 right)
} = arg{operatornam
e{}left| mathbf{S
igma}^{frac{1}{2}}l
eft( mathbf{Phi}^{T
}mathbf{w}^{left( t</p>
<blockquote>
<div>right)} + mathbf{</div></blockquote>
<p>Sigma}^{- 1}left( m
athbf{y - sigma} ri
ght) - mathbf{Phi}^
{T}mathbf{w}^{left(</p>
<blockquote>
<div>t right)} right) </div></blockquote>
<p>right|_{2}^{2}} = a
rg{operatorname{}le
ft| mathbf{Sigma}^
{- frac{1}{2}}left(</p>
<blockquote>
<div>mathbf{y - sigma}</div></blockquote>
<p class="last">right) right|_{2}^
{2}}</p>
</td>
<td>&#160;</td>
<td>(2‑55)</td>
</tr>
</tbody>
</table>
<p>That is, <span class="math notranslate nohighlight">\(\mathbf{w}^{\left( t + 1 \right)}\)</span> is trying to minimize
the squared error between <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{\sigma}\)</span>
weighted by the current inversed standard deviation
<span class="math notranslate nohighlight">\(\left( \mathbf{\Sigma}^{- \frac{1}{2}} \right)^{\left( t \right)}\)</span>.
Now if <span class="math notranslate nohighlight">\(\mathbf{w}^{\left( t \right)}\)</span> goes to extreme values that
make some <span class="math notranslate nohighlight">\(\sigma_{i} \approx y_{i}\)</span>, then corresponding inversed
standard deviation in the diagonal of
<span class="math notranslate nohighlight">\(\left( \mathbf{\Sigma}^{- \frac{1}{2}} \right)^{\left( t \right)}\)</span>
will increase to upweight the corresponding errors
<span class="math notranslate nohighlight">\(\sigma_{i} - y_{i}\)</span>; therefore, we see weights in
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}^{- \frac{1}{2}}\)</span> make it harder for each
<span class="math notranslate nohighlight">\(\sigma\)</span> to overfit <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>, or equivalently prevent
components of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> from becoming very large or very small.
The algorithm of (2‑54) also falls into the category of
<strong>iteratively-reweighted least square algorithms</strong>.</p>
<p><strong>Multi-Class logistic regression</strong>. For multi-class classification, we
first make an assumption similar to (2‑49) using softmax. Let
<span class="math notranslate nohighlight">\(\mathbf{W} = \left( \mathbf{w}_{1},\ldots,\mathbf{w}_{K} \right)\)</span>,
and let <span class="math notranslate nohighlight">\(\sigma_{k}\)</span> denote the <span class="math notranslate nohighlight">\(k\)</span>th component of the
softmax function <span class="math notranslate nohighlight">\(\sigma\)</span>, then</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[p\left( C_{\]</div>
<p>k}|mathbf{phi}_{i}
right) = sigma_{k}left( mathbf{W}^{T}mathbf{phi}_{i} rig
ht) = frac{e^{mathb
f{w}_{k}^{T}mathbf{phi}_{i}}}{sum_{j =
1}^{K}e^{mathbf{w}_{
j}^{T}mathbf{phi}_{
i}}},i = 1,ldots,N,k</p>
<blockquote class="last">
<div>= 1,ldots,K</div></blockquote>
</td>
<td>&#160;</td>
<td>(2‑57)</td>
</tr>
</tbody>
</table>
<p>The log-likelihood of <span class="math notranslate nohighlight">\(p\left( C_{k}|\mathbf{\phi}_{i} \right)\)</span>
(negative cross-entropy) is</p>
<div class="math notranslate nohighlight">
\[\ln p \propto \sum_{\mathbf{\phi \in}C_{1}}^{}{\ln{p\left( C_{1}|\mathbf{\phi} \right)}} + \ldots + \sum_{\mathbf{\phi \in}C_{K}}^{}{\ln{p\left( C_{K}|\mathbf{\phi} \right)}} = \sum_{\mathbf{\phi \in}C_{1}}^{}{\ln\frac{e^{\mathbf{w}_{1}^{T}\mathbf{\phi}}}{\sum_{j = 1}^{K}e^{\mathbf{w}_{j}^{T}\mathbf{\phi}}}} + \ldots + \sum_{\mathbf{\phi \in}C_{K}}^{}{\ln\frac{e^{\mathbf{w}_{K}^{T}\mathbf{\phi}}}{\sum_{j = 1}^{K}e^{\mathbf{w}_{j}^{T}\mathbf{\phi}}}} = \sum_{\mathbf{\phi \in}C_{1}}^{}\left( \mathbf{w}_{1}^{T}\mathbf{\phi -}\ln\left( \sum_{j = 1}^{K}e^{\mathbf{w}_{j}^{T}\mathbf{\phi}} \right) \right) + \ldots + \sum_{\mathbf{\phi \in}C_{K}}^{}\left( \mathbf{w}_{K}^{T}\mathbf{\phi -}\ln\left( \sum_{j = 1}^{K}e^{\mathbf{w}_{j}^{T}\mathbf{\phi}} \right) \right)\]</div>
<p>Let <span class="math notranslate nohighlight">\({\overline{\mathbf{\phi}}}_{k}\)</span> denote the sample mean of the
<span class="math notranslate nohighlight">\(k\)</span>th class, and
<span class="math notranslate nohighlight">\(\mathbb{E}_{C_{k}}\left\lbrack \mathbf{\phi} \right\rbrack\)</span>
denote the expected data of the <span class="math notranslate nohighlight">\(k\)</span>th class. Taking derivative
of the above likelihood, and we have</p>
<div class="math notranslate nohighlight">
\[\frac{\partial\ln p}{\partial\mathbf{w}_{k}} = \sum_{\mathbf{\phi \in}C_{k}}^{}\mathbf{\phi} - \sum_{l = 1}^{K}{\sum_{\mathbf{\phi \in}C_{l}}^{}\left( \frac{e^{\mathbf{w}_{k}^{T}\mathbf{\phi}}}{\sum_{j = 1}^{K}e^{\mathbf{w}_{j}^{T}\mathbf{\phi}}}\mathbf{\phi} \right)} = \sum_{\mathbf{\phi \in}C_{k}}^{}\mathbf{\phi} - \sum_{i = 1}^{N}\left( p\left( C_{k}|\mathbf{\phi}_{i} \right)\mathbf{\phi}_{i} \right) = N_{k}{\overline{\mathbf{\phi}}}_{k} - N\mathbb{E}_{C_{k}}\left\lbrack \mathbf{\phi} \right\rbrack\]</div>
<p>Again, we can iteratively apply gradient ascent for each
<span class="math notranslate nohighlight">\(\mathbf{w}_{k}\)</span>, and the fastest ascending direction of
<span class="math notranslate nohighlight">\(\mathbf{w}_{k}\)</span> points from the expected sum to the sample sum,
consistent with the binary logistic regression, intuitively meaning the
model is evolving from the prior assumed distribution to fit the
observed data.</p>
<p><strong>Bayesian Logistic regression</strong>.</p>
<ul class="simple">
<li>Probit regression.</li></ul>
<div class="section" id="support-vector-machine">
<h4><strong>Support Vector Machine</strong><a class="headerlink" href="#support-vector-machine" title="Permalink to this headline">¶</a></h4>
<p>Let’s consider binary classification and assume the label set
<span class="math notranslate nohighlight">\(\mathbb{L =}\left\{ + 1, - 1 \right\}\)</span>. Given a
<span class="math notranslate nohighlight">\(m \times n\)</span> data set <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> and its labels
<span class="math notranslate nohighlight">\(\mathbf{y}\)</span>, the basic goal of <strong>Support Vector Machine</strong> (SVM)
is to find a hyperplane <span class="math notranslate nohighlight">\(H:\mathbf{a}^{T}\mathbf{x} + \mathbf{b}\)</span>
that best separates the data points with different labels, same as all
other linear classifiers discussed earlier; <em>in addition</em>, it requires
equal distance from <span class="math notranslate nohighlight">\(H\)</span> to the nearest positive point and the
nearest negative point be equal, and it also wants this distance as wide
as possible; such hyperplane is named <strong>maximum-margin hyperplane</strong>, and
the positive/negative points nearest to <span class="math notranslate nohighlight">\(H\)</span> are named <strong>support
vectors</strong>. If we apply some <strong>basis functions</strong>
<span class="math notranslate nohighlight">\(\phi(\mathbf{x}):\mathbb{R}^{m} \rightarrow \mathbb{R}^{M}\)</span> to
transform the data, just as before, then we aim to find the hyperplane
<span class="math notranslate nohighlight">\(H:\mathbf{a}^{T}\mathbf{\phi}\left( \mathbf{x} \right) + \mathbf{b}\)</span>
in the space transformed by <span class="math notranslate nohighlight">\(\phi\)</span>. The basis functions are
referred to as the <strong>kernel</strong> in the context of SVM.</p>
<p>TODO Illustration of 2D MMH</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><span class="math notranslate nohighlight">\(l\)</span> is too near positive
points, and the “street” is not
wide enough</td>
<td>a better choice of <span class="math notranslate nohighlight">\(l\)</span></td>
</tr>
<tr class="row-even"><td><em>Figure</em> <em>2‑2 In (a), (b) and (c)
the hyperplane</em> <span class="math notranslate nohighlight">\(H\)</span> <em>makes
correct classification, but in
(a)</em> <span class="math notranslate nohighlight">\(H\)</span> <em>does not have
maximum margin, in (b)</em> <span class="math notranslate nohighlight">\(H\)</span>
<em>does have equal distance to
support vectors. (c) is the
solution chosen by SVM.</em></td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<p>For a labeled point <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, we denote it as
<span class="math notranslate nohighlight">\(\mathbf{x}_{+}\)</span> if it is positively labelled, and
<span class="math notranslate nohighlight">\(\mathbf{x}_{-}\)</span> if it is negatively labelled. We then try to
solve <span class="math notranslate nohighlight">\(\mathbf{\omega}\)</span> and <span class="math notranslate nohighlight">\(b\)</span> by
<span class="math notranslate nohighlight">\(\left\{ \begin{matrix}
\mathbf{\omega \cdot}\mathbf{x}_{\mathbf{+}} + b \geq 1 \\
\mathbf{\omega \cdot}\mathbf{x}_{\mathbf{-}} + b \leq - 1 \\
\end{matrix} \right.\ \)</span> for every <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathbf{+}}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{x}_{\mathbf{-}}\)</span>. Note on the right-hand side of the
inequalities, the constants are <span class="math notranslate nohighlight">\(\pm 1\)</span>, not <span class="math notranslate nohighlight">\(0\)</span>. That is
because in the above decision rule
<span class="math notranslate nohighlight">\(\frac{\mathbf{\omega \cdot u}}{\left| \mathbf{\omega} \right|^{2}} = 1\)</span>
is the median line, and we want the nearest positive point and the
nearest negative point have certain equal distance to the median line,
i.e., <span class="math notranslate nohighlight">\(\left\{ \begin{matrix}
\frac{\mathbf{\omega \cdot}\mathbf{x}_{\mathbf{+}}}{\left| \mathbf{\omega} \right|^{2}} \geq 1 + \epsilon \\
\frac{\mathbf{\omega \cdot}\mathbf{x}_{\mathbf{-}}}{\left| \mathbf{\omega} \right|^{2}} \leq 1 - \epsilon \\
\end{matrix} \right.\  \Rightarrow \left\{ \begin{matrix}
\mathbf{\omega \cdot}\mathbf{x}_{\mathbf{+}} + b \geq \epsilon \\
\mathbf{\omega \cdot}\mathbf{x}_{\mathbf{-}} + b \leq - \epsilon \\
\end{matrix} \right.\  \Rightarrow \left\{ \begin{matrix}
\frac{\mathbf{\omega}}{\epsilon}\mathbf{\cdot}\mathbf{x}_{\mathbf{+}} + \frac{b}{\epsilon} \geq 1 \\
\frac{\mathbf{\omega}}{\epsilon}\mathbf{\cdot}\mathbf{x}_{\mathbf{-}} + \frac{b}{\epsilon} \leq - 1 \\
\end{matrix} \right.\ \)</span> for some <span class="math notranslate nohighlight">\(\epsilon \geq 0\)</span> as the
distance. The normalization by <span class="math notranslate nohighlight">\(\epsilon\)</span> does not affect the
nature of our problem since <span class="math notranslate nohighlight">\(\mathbf{\omega,}b\)</span> are unknowns, and
thus <span class="math notranslate nohighlight">\(\left\{ \begin{matrix}
\mathbf{\omega \cdot}\mathbf{x}_{\mathbf{+}} + b \geq 1 \\
\mathbf{\omega \cdot}\mathbf{x}_{\mathbf{-}} + b \leq - 1 \\
\end{matrix} \right.\ \)</span> is indeed the inequalities we are looking for.
We notice we can further simplify it by applying the label of a point
:math:<a href="#id41"><span class="problematic" id="id42">`</span></a>y = left{ begin{matrix}</p>
<blockquote>
<div><ul class="simple">
<li>1 &amp; text{for}mathbf{x}_{+} \</li>
</ul>
<ul class="simple">
<li>1 &amp; text{for}mathbf{x}_{-} \</li></ul></blockquote>
<p>end{matrix} right.` on both sides of both inequalities, we merge
them into a single form
<span class="math notranslate nohighlight">\(y(\mathbf{x})(\mathbf{\omega \cdot x} + b) \geq 1\)</span> for every
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. Note that</p>
<ol class="arabic simple">
<li>From this moment on <span class="math notranslate nohighlight">\(\mathbf{\omega}\)</span> does not necessarily have
its end point on the median line due to the normalization of
<span class="math notranslate nohighlight">\(\epsilon\)</span> to <span class="math notranslate nohighlight">\(1\)</span>, but is still a vector perpendicular to
the median line.</div></div></div></li><li>We have deliberately let positive points on the right-hand side to
have this neat inequality, otherwise it would be
“<span class="math notranslate nohighlight">\(\leq - 1\)</span>”.</li>
</ol>
<p>Now we want to implement the idea that the “street” should be as wide as
possible. Note there must be at least one positive point
<span class="math notranslate nohighlight">\(\mathbf{x}_{+}^{'}\)</span> and one negative point
<span class="math notranslate nohighlight">\(\mathbf{x}_{-}^{'}\)</span> on each side of the street (so at least two
support vectors), and it is not hard to see the width of the street is
exactly</p>
<div class="math notranslate nohighlight">
\[\frac{\mathbf{\omega}}{\mathbf{|}\mathbf{\omega}\mathbf{|}} \cdot \mathbf{x}_{+}^{'} - \frac{\mathbf{\omega}}{\left| \mathbf{\omega} \right|} \cdot \mathbf{x}_{-}^{'} = \frac{\mathbf{\omega}}{\left| \mathbf{\omega} \right|} \cdot \mathbf{x}_{+}^{'} + b - \left( \frac{\mathbf{\omega}}{\left| \mathbf{\omega} \right|} \cdot \mathbf{x}_{-}^{'} + b \right) = \ \frac{\mathbf{\omega}}{\left| \mathbf{\omega} \right|} \cdot \left( \mathbf{x}_{+}^{'} - \mathbf{x}_{-}^{'} \right) = \frac{2}{|\mathbf{\omega}|}\]
<p>Thus we want to maximize <span class="math notranslate nohighlight">\(\frac{2}{|\mathbf{\omega}|}\)</span>, and
equivalently we can minimize
<span class="math notranslate nohighlight">\(\frac{1}{2}\left| \mathbf{\omega} \right|^{2}\)</span> for mathematical
convenience of taking derivatives later. Now the SVM construction is
converted to an optimization problem</p>
<p><span class="math notranslate nohighlight">\(\min{\ \frac{1}{2}\left| \mathbf{\omega} \right|^{2}}\)</span> s.t.
<span class="math notranslate nohighlight">\(y(\mathbf{x})(\mathbf{\omega \cdot x} + b) \geq 1\)</span> for every
<span class="math notranslate nohighlight">\(\mathbf{x \in}D\)</span></p>

<div class="section" id="generalized-linear-models">
<h4><strong>Generalized Linear Models</strong><a class="headerlink" href="#generalized-linear-models" title="Permalink to this headline">¶</a></h4>


<div class="section" id="graphical-models">
<h3>Graphical Models<a class="headerlink" href="#graphical-models" title="Permalink to this headline">¶</a></h3>


<div class="section" id="clustering">
<h2><strong>Clustering</strong><a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classic-clustering-analysis-classic-clustering-methods-are-typically-based-on-mutual-distances-of-data-points-and-some-threshold-distances-we-first-introduce-the-hierarchical-clustering-analysis-hca-from-which-data-points-are-visualized-through-a-tree-like-structure-called-dendrogram-tree-where-each-non-leaf-node-is-a-set-of-partitions-and-each-leaf-is-a-set-of-data-points-one-algorithm-is-called-agglomerative-hca-described-as-below">
<h3>Classic Clustering Analysis. Classic clustering methods are typically based on mutual distances of data points and some threshold distances. We first introduce the <strong>Hierarchical Clustering Analysis</strong> (HCA), from which data points are visualized through a tree-like structure, called <strong>dendrogram tree</strong>, where each non-leaf node is a set of partitions, and each leaf is a set of data points. One algorithm is called <strong>agglomerative HCA</strong>, described as below,<a class="headerlink" href="#classic-clustering-analysis-classic-clustering-methods-are-typically-based-on-mutual-distances-of-data-points-and-some-threshold-distances-we-first-introduce-the-hierarchical-clustering-analysis-hca-from-which-data-points-are-visualized-through-a-tree-like-structure-called-dendrogram-tree-where-each-non-leaf-node-is-a-set-of-partitions-and-each-leaf-is-a-set-of-data-points-one-algorithm-is-called-agglomerative-hca-described-as-below" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>At the beginning, each data point is treated as a cluster itself,
i.e. a singleton cluster.</div></div></div></div></div></div></li><li>Merge two “closest” clusters to merge together, where different
measures of closeness might apply.</li><li>Repeat step 2) until only one cluster remains.</li>
</ol>
<p>Taking the following simple example with data <span class="math notranslate nohighlight">\(\{ a,b,c,d,e\}\)</span> in
<em>Figure 0‑1</em>. At the beginning we have singleton clusters
<span class="math notranslate nohighlight">\(\left\{ a \right\},\left\{ b \right\},\left\{ c \right\},\left\{ d \right\},\{ e\}\)</span>,
and we use minimum point distance <span class="math notranslate nohighlight">\(\mathcal{d}\)</span> below as the
distance measure of two clusters, where <span class="math notranslate nohighlight">\(d\)</span> could be any metric of
points,</p>
<div class="math notranslate nohighlight">
\[\mathcal{d}\left( C_{1},C_{2} \right) = \min{\{ d\left( x_{1},x_{2} \right):x_{1} \in C_{1},x_{2} \in C_{2}\}}\]
<p>For example, by <em>Figure 0‑1</em> we have</p>
<div class="math notranslate nohighlight">
\[\mathcal{d}\left( \left\{ a \right\},\left\{ b \right\} \right) = d\left( a,b \right)\mathcal{,\ d}\left( \left\{ b \right\},\left\{ c,d \right\} \right) = d\left( b,c \right)\mathcal{,d}\left( \left\{ a,b \right\},\left\{ c,d \right\} \right) = d(b,c)\]
<p>We first merge two nearest clusters <span class="math notranslate nohighlight">\(\{ c\}\)</span> and <span class="math notranslate nohighlight">\(\{ d\}\)</span> to
derive four clusters
<span class="math notranslate nohighlight">\(\left\{ a \right\},\left\{ b \right\},\left\{ c,d \right\},\{ e\}\)</span>.
Again we merge two nearest clusters <span class="math notranslate nohighlight">\(\{ a\}\)</span> and <span class="math notranslate nohighlight">\(\{ b\}\)</span>,
and then merge <span class="math notranslate nohighlight">\(\{ a,b\}\)</span> and <span class="math notranslate nohighlight">\(\{ c,d\}\)</span>. The last step is
to merge <span class="math notranslate nohighlight">\(\{ e\}\)</span> to form a single cluster. Then we might draw a
line of threshold time for desired clusters.</p>
<p><em>Figure</em> <em>0‑1 An example of agglomerative HCA</em></p>
<p>One may look for other closeness measures like</p>
<div class="math notranslate nohighlight">
\[\mathcal{d}\left( C_{1},C_{2} \right) = \max{\{ d\left( x_{1},x_{2} \right):x_{1} \in C_{1},x_{2} \in C_{2}\}}\]
<ol class="arabic simple">
<li>average distance:</li>
</ol>
<div class="math notranslate nohighlight">
\[\mathcal{d}\left( C_{1},C_{2} \right) = \operatorname{}{\{ d\left( x_{1},x_{2} \right):x_{1} \in C_{1},x_{2} \in C_{2}\}}\]
<ol class="arabic simple" start="2">
<li>centroid distance:</li>
</ol>
<div class="math notranslate nohighlight">
\[\mathcal{d}\left( C_{1},C_{2} \right) = d\left( \frac{1}{\left| C_{1} \right|}\sum_{x \in C_{1}}^{}x,\frac{1}{|C_{2}|}\sum_{x \in C_{2}}^{}x \right)\]
<p>Note <span class="math notranslate nohighlight">\(\mathcal{d}\)</span> is not generally a metric, due to that it might
not satisfy the triangular inequality. Still taking <em>Figure 0‑1</em> and
minimum distance for example, we have</p>
<div class="math notranslate nohighlight">
\[\mathcal{d}\left( \left\{ a,b \right\},\left\{ c,d \right\} \right)\mathcal{+ d}\left( \left\{ c,d \right\},\left\{ e \right\} \right) = d\left( b,c \right) + d\left( d,e \right)\mathcal{&lt; d}\left( \left\{ a,b \right\},\left\{ e \right\} \right) = d(b,e)\]
<p>Another simple algorithm is <strong>divisive HCA</strong>, which is kind of converse
of agglomerative HCA. Divisive HCA starts with the whole dataset as a
single cluster, and at each step points with farthest distance to the
remaining points in the same cluster are picked out, until in each
cluster every point has equal distance to the remaining part and no new
clusters can be formed. In <em>Figure 0‑1</em>, that process would be</p>
<ol class="arabic simple">
<li>First picking out <span class="math notranslate nohighlight">\(\{ e\}\)</span> and it is easy to verify that
<span class="math notranslate nohighlight">\(\{ e\}\)</span> has the farthest distance to the remaining part.</li><li>Then we look at non-singleton cluster <span class="math notranslate nohighlight">\(\{ a,b,c,d\}\)</span> and find
<span class="math notranslate nohighlight">\(a,b\)</span> have the equal distance to the remaining part of that
cluster, and hence <span class="math notranslate nohighlight">\(\{ a,b\}\)</span> are picked out to form a cluster
itself. Note no new cluster can be found in <span class="math notranslate nohighlight">\(\{ a,b\}\)</span>.</li>
<li>Last, <span class="math notranslate nohighlight">\(\{ c,d\}\)</span> form a cluster where no further cluster can be
found, and the divisive HCA is done.</li>
</ol>

<div class="section" id="spectral-clustering">
<h3>Spectral Clustering<a class="headerlink" href="#spectral-clustering" title="Permalink to this headline">¶</a></h3>


<div class="section" id="probabilistic-modeling">
<h2><strong>Probabilistic Modeling</strong><a class="headerlink" href="#probabilistic-modeling" title="Permalink to this headline">¶</a></h2>
<div class="section" id="basic-distributions-some-frequently-used-distributions-like-exponential-distribution-poisson-distribution-and-gaussian-distribution-arise-from-analysis-of-random-process-to-our-purpose-we-can-consider-a-random-process-as-a-family-of-rvs-where-is-an-index-set-even-although-random-process-is-a-very-sophisticated-mathematical-concept-whose-rigorous-treatment-requires-advanced-mathematical-knowledge-such-like-measure-theory-probability-theory-etc">
<h3>Basic Distributions. Some frequently used distributions, like exponential distribution, Poisson distribution and Gaussian distribution arise from analysis of <strong>random process</strong>. To our purpose, we can consider a random process as a family of RVs <span class="math notranslate nohighlight">\(X_{t},t \in T\)</span> where <span class="math notranslate nohighlight">\(T\)</span> is an index set. Even although random process is a very sophisticated mathematical concept whose rigorous treatment requires advanced mathematical knowledge such like measure theory, probability theory, etc.<a class="headerlink" href="#basic-distributions-some-frequently-used-distributions-like-exponential-distribution-poisson-distribution-and-gaussian-distribution-arise-from-analysis-of-random-process-to-our-purpose-we-can-consider-a-random-process-as-a-family-of-rvs-where-is-an-index-set-even-although-random-process-is-a-very-sophisticated-mathematical-concept-whose-rigorous-treatment-requires-advanced-mathematical-knowledge-such-like-measure-theory-probability-theory-etc" title="Permalink to this headline">¶</a></h3>
<p>A <strong>discrete-time Bernoulli process</strong> is a countable random process
<span class="math notranslate nohighlight">\(X_{t},t = 1,2,\ldots\)</span> where each RV <span class="math notranslate nohighlight">\(X_{t}\)</span> obeys
<strong>Bernoulli distribution</strong> <span class="math notranslate nohighlight">\(Bernoulli(p)\)</span>, and the number of
successes before time <span class="math notranslate nohighlight">\(t = n\)</span> follows <strong>binomial distribution</strong>
<span class="math notranslate nohighlight">\(\text{Binomial}(n,p)\)</span>. Bernoulli process is equivalent to a
random walk on a trivial Markov chain characterized by two states
<span class="math notranslate nohighlight">\(\{ 0,1\}\)</span>, initial distribution
<span class="math notranslate nohighlight">\(\mathbf{\mu} = \left( 1 - p,p \right)\)</span> and transition matrix
<span class="math notranslate nohighlight">\(\mathbf{P} = \begin{pmatrix}
1 - p &amp; p \\
1 - p &amp; p \\
\end{pmatrix}\)</span>. Since <span class="math notranslate nohighlight">\(\mathbf{\mu} = \mathbf{\text{μP}}\)</span>,
<span class="math notranslate nohighlight">\(\mathbf{\mu}\)</span> is also the stationary distribution.</p>
<p>Binomial distribution can be viewed as a model of drawing balls from an
urn containing <span class="math notranslate nohighlight">\(N\)</span> balls of which <span class="math notranslate nohighlight">\(K\)</span> are red balls and the
rest are blue balls. The drawing is with replacement, i.e. the drawn
ball will be put back into the urn. When considered this way, the
probability distribution of drawing <span class="math notranslate nohighlight">\(k\)</span> red balls in <span class="math notranslate nohighlight">\(n\)</span>
trials is <span class="math notranslate nohighlight">\(\mathbb{P\{}X = k\} = \begin{pmatrix}
n \\
k \\
\end{pmatrix}{(\frac{K}{N})}^{k}{(\frac{N - K}{N})}^{n - k}\)</span>. These
drawings with replacements are independent Bernoulli trials.</p>
<p>Now if the drawn balls are not returned to the urn, then the
distribution of drawing <span class="math notranslate nohighlight">\(k\)</span> red balls in <span class="math notranslate nohighlight">\(n\)</span> trials becomes
<strong>hypergeometric distribution</strong>. The support of a binomial distribution
ranges from <span class="math notranslate nohighlight">\(0\)</span> to <span class="math notranslate nohighlight">\(n\)</span>, while the support of the
hypergeometric distribution is
<span class="math notranslate nohighlight">\(\left\lbrack \max\left( 0,n - \left( N - K \right) \right),\min\left( n,K \right) \right\rbrack\)</span>
since</p>
<ol class="arabic simple">
<li>At least <span class="math notranslate nohighlight">\(n - (N - K)\)</span> red balls are drawn when the number of
trials <span class="math notranslate nohighlight">\(n\)</span> is more than the total number of blue balls
<span class="math notranslate nohighlight">\(N - K\)</span>;</div></div></div></div></div></li><li>it is impossible to draw more than <span class="math notranslate nohighlight">\(K\)</span> red balls from the urn.</li>
</ol>
<p>For example, if the urn has <span class="math notranslate nohighlight">\(7\)</span> red balls and <span class="math notranslate nohighlight">\(3\)</span> blue
balls, and we conduct <span class="math notranslate nohighlight">\(5\)</span> trials, then minimum number of possible
red balls is <span class="math notranslate nohighlight">\(2\)</span> and the maximum is <span class="math notranslate nohighlight">\(5\)</span>. The distribution is
given by the following formula:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbb{P\{}X = k\} = \frac{\begin{pmatrix}
K \\
k \\
\end{pmatrix}\begin{pmatrix}
N - K \\
n - k \\
\end{pmatrix}}{\begin{pmatrix}
N \\
n \\
\end{pmatrix}}\end{split}\]
<p>where <span class="math notranslate nohighlight">\(\begin{pmatrix}
N \\
n \\
\end{pmatrix}\)</span> is the total number of ways of drawing <span class="math notranslate nohighlight">\(n\)</span> balls
from a population of <span class="math notranslate nohighlight">\(N\)</span>, <span class="math notranslate nohighlight">\(\begin{pmatrix}
K \\
k \\
\end{pmatrix}\)</span> is the total number of ways of drawing <span class="math notranslate nohighlight">\(k\)</span> red
balls from a total of <span class="math notranslate nohighlight">\(K\)</span> red balls, and <span class="math notranslate nohighlight">\(\begin{pmatrix}
N - K \\
n - k \\
\end{pmatrix}\)</span> is the total number of ways of drawing <span class="math notranslate nohighlight">\(n - k\)</span> blue
balls from a total of <span class="math notranslate nohighlight">\(N - K\)</span> blue balls. If a random variable
<span class="math notranslate nohighlight">\(X\)</span> follows the hypergeometric distribution, it is denoted as
<span class="math notranslate nohighlight">\(X\sim\text{Hypergeometric}(N,K,n)\)</span> or <span class="math notranslate nohighlight">\(X\sim H(N,K,n)\)</span> for
short.</p>
<p>The numerator of the formula can be interpreted as a two-step selection
– first choosing <span class="math notranslate nohighlight">\(k\)</span> red balls from a total of <span class="math notranslate nohighlight">\(K\)</span> red
balls, and then choosing <span class="math notranslate nohighlight">\(n - k\)</span> blue balls from a total of
<span class="math notranslate nohighlight">\(N - K\)</span> blue balls, and the total number of different combinations
are <span class="math notranslate nohighlight">\(\begin{pmatrix}
K \\
k \\
\end{pmatrix}\begin{pmatrix}
N - K \\
n - k \\
\end{pmatrix}\)</span>. The support can also be seen directly from the formula,
i.e. <span class="math notranslate nohighlight">\(k \leq K\)</span> and <span class="math notranslate nohighlight">\(n - k \leq N - K\)</span>, which yields the
above-mentioned support.</p>
<ul class="simple">
<li><em>Theorem</em> <em>0‑1</em> <strong>Vandermonde’s identity</strong> <span class="math notranslate nohighlight">\(\begin{pmatrix}
m + n \\
r \\
\end{pmatrix} = \sum_{k = 0}^{r}{\begin{pmatrix}
m \\
k \\
\end{pmatrix}\begin{pmatrix}
n \\
r - k \\
\end{pmatrix}}\)</span>. The PMF of hypergeometric distribution sums to
<span class="math notranslate nohighlight">\(1\)</span>: <span class="math notranslate nohighlight">\(\sum_{k = 0}^{n}\frac{\begin{pmatrix}
K \\
k \\
\end{pmatrix}\begin{pmatrix}
N - K \\
n - k \\
\end{pmatrix}}{\begin{pmatrix}
N \\
n \\
\end{pmatrix}} = \frac{\sum_{k = 0}^{n}{\begin{pmatrix}
K \\
k \\
\end{pmatrix}\begin{pmatrix}
N - K \\
n - k \\
\end{pmatrix}}}{\begin{pmatrix}
N \\
n \\
\end{pmatrix}} = 1\)</span>, whereby we can see that
<span class="math notranslate nohighlight">\(\sum_{k = 0}^{n}{\begin{pmatrix}
K \\
k \\
\end{pmatrix}\begin{pmatrix}
N - K \\
n - k \\
\end{pmatrix}} = \begin{pmatrix}
N \\
n \\
\end{pmatrix}\)</span>. Replace <span class="math notranslate nohighlight">\(n\)</span> by <span class="math notranslate nohighlight">\(k\)</span>, and <span class="math notranslate nohighlight">\(K\)</span> by
<span class="math notranslate nohighlight">\(m\)</span> reassign <span class="math notranslate nohighlight">\(n = N - K = N - m\)</span>, then
<span class="math notranslate nohighlight">\(\sum_{k = 0}^{r}{\begin{pmatrix}
m \\
k \\
\end{pmatrix}\begin{pmatrix}
n \\
r - k \\
\end{pmatrix}} = \begin{pmatrix}
m + n \\
r \\
\end{pmatrix}\)</span>.</li><li><em>Theorem</em> <em>0‑2</em> Sum of independent Binomial RVs is still Binomial.
Suppose <span class="math notranslate nohighlight">\(X_{1}\sim\text{Binomial}(n_{1},p)\)</span> and
<span class="math notranslate nohighlight">\(X_{2}\sim\text{Binomial}(n_{2},p)\)</span> and they are independent,
then the mass function of <span class="math notranslate nohighlight">\(X_{1} + X_{2}\)</span> is</li>
</ul>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}p\left\{ X_{1} + X_{2} = k \right\} = \sum_{k_{1} + k_{2} = k}^{}\begin{pmatrix}
n_{1} \\
k_{1} \\
\end{pmatrix}\left( 1 - p \right)^{n_{1} - k_{1}}p^{k_{1}}\begin{pmatrix}
n_{2} \\
k_{2} \\
\end{pmatrix}\left( 1 - p \right)^{n_{2} - k_{2}}p^{k_{2}} = \begin{pmatrix}
n_{1} + n_{2} \\
k \\
\end{pmatrix}\left( 1 - p \right)^{n_{1} + n_{2} - k}p^{k}\sum_{k_{1} + k_{2} = k}^{}\frac{\begin{pmatrix}
n_{1} \\
k_{1} \\
\end{pmatrix}\begin{pmatrix}
n_{2} \\
k_{2} \\
\end{pmatrix}}{\begin{pmatrix}
n_{1} + n_{2} \\
k \\
\end{pmatrix}} = \begin{pmatrix}
n_{1} + n_{2} \\
k \\
\end{pmatrix}{(1 - p)}^{n_{1} + n_{2} - k}p^{k}\end{split}\\\begin{split}where :math:`\sum_{k_{1} + k_{2} = k}^{}\frac{\begin{pmatrix}
n_{1} \\
k_{1} \\
\end{pmatrix}\begin{pmatrix}
n_{2} \\
k_{2} \\
\end{pmatrix}}{\begin{pmatrix}
n_{1} + n_{2} \\
k \\
\end{pmatrix}}` is the sum of individual probabilities of the PMF of
the hypergeometric distribution. This indicates
:math:`X_{1} + X_{2}\sim\text{Binomial}(n_{1} + n_{2},\ p)`.\end{split}\end{aligned}\end{align} \]
<ul>
<li><p class="first">The <strong>first arrival time</strong> <span class="math notranslate nohighlight">\(\tau\)</span> of Bernoulli process is a RV
representing the time of first success. It is easy to see
<span class="math notranslate nohighlight">\(\mathbb{P}\left\{ \tau = t \right\} = \left( 1 - p \right)^{t - 1}p\)</span>
with support <span class="math notranslate nohighlight">\(t \in \lbrack 1, + \infty)\)</span>. The distribution
with this PMF is called the <strong>geometric distribution</strong>.</p>
<p>Fix <span class="math notranslate nohighlight">\(\tau_{0} = 0\)</span>, and let <span class="math notranslate nohighlight">\(\tau_{k}\)</span> denote the
<strong>waiting time</strong> for the <span class="math notranslate nohighlight">\(k\)</span>th arrival, then
<span class="math notranslate nohighlight">\(\omega_{k} = \tau_{k} - \tau_{k - 1}\)</span> is the <strong>inter-arrival
time</strong> for the <span class="math notranslate nohighlight">\(k\)</span>th arrival. The PMF of <span class="math notranslate nohighlight">\(\tau_{k}\)</span> is
<span class="math notranslate nohighlight">\(P\left\{ \tau_{k} = t \right\} = \begin{pmatrix}
t - 1 \\
k - 1 \\
\end{pmatrix}\left( 1 - p \right)^{t - 1 - (k - 1)}p^{k - 1}p = \begin{pmatrix}
t - 1 \\
k - 1 \\
\end{pmatrix}\left( 1 - p \right)^{t - k}p^{k}\)</span> where
<span class="math notranslate nohighlight">\(t \geq k\)</span>, since all trials before the <span class="math notranslate nohighlight">\(k\)</span>th arrival
are <span class="math notranslate nohighlight">\(t - 1\)</span> times of independent Bernoulli trials with
<span class="math notranslate nohighlight">\(k - 1\)</span> successes. The distribution of this PMF is named
<strong>Pascal distribution</strong>, whose special case <span class="math notranslate nohighlight">\(k = 1\)</span> is the
geometric distribution.</p>
</li>
</ul>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><a class="reference internal" href="media/image7.png"><img alt="image8" src="media/image7.png" style="width: 2.41085in; height: 1.5in;" /></a></th>
<th class="head"><a class="reference internal" href="media/image8.png"><img alt="image9" src="media/image8.png" style="width: 2.40013in; height: 1.5in;" /></a></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><p class="first"><em>Pascal distribution with the
same</em> <span class="math notranslate nohighlight">\(k = 10\)</span> <em>but
varying</em> <span class="math notranslate nohighlight">\(p\)</span><em>.</em>
<span class="math notranslate nohighlight">\(\tau_{k}\)</span> <em>is more likely
to have smaller value with
larger</em> <span class="math notranslate nohighlight">\(p\)</span><em>, as
expected.</em></p>
<div class="last math notranslate nohighlight">
\[p = 0.4,\ p = 0.5,\ p =
0.6\]
</td>
<td><p class="first"><em>Pascal distribution with the
same</em> <span class="math notranslate nohighlight">\(p = 0.4\)</span> <em>but
varying</em> <span class="math notranslate nohighlight">\(k\)</span><em>.</em>
<span class="math notranslate nohighlight">\(\tau_{k}\)</span> <em>is more likely
to have large value when</em>
<span class="math notranslate nohighlight">\(k\)</span> <em>grows, as expected.</em></p>
<div class="last math notranslate nohighlight">
\[k = 5,\ k = 8,\ k = 10\]
</td>
</tr>
<tr class="row-odd"><td><em>Figure</em> <em>0‑1 Illustrations of
Pascal Distribution.</em></td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<p><span class="math notranslate nohighlight">\(\{\tau_{k}\}\)</span> are not independent, since for any
<span class="math notranslate nohighlight">\(i &lt; j,s &lt; t\)</span>, we have
<span class="math notranslate nohighlight">\(\mathbb{P}\left\{ \tau_{j} = t|\tau_{i} = s \right\} = 0\)</span> for
<span class="math notranslate nohighlight">\(t \leq s\)</span> (if the <span class="math notranslate nohighlight">\(i\)</span>th success happens at time
<span class="math notranslate nohighlight">\(s\)</span>, a later <span class="math notranslate nohighlight">\(j\)</span>th success must happen later than time
<span class="math notranslate nohighlight">\(s\)</span>), however,
<span class="math notranslate nohighlight">\(\mathbb{P}\left\{ \tau_{j} = t \right\} \neq 0\)</span> for any
<span class="math notranslate nohighlight">\(t \geq j\)</span> and it is possible that <span class="math notranslate nohighlight">\(j \leq s\)</span>.</p>
<p><span class="math notranslate nohighlight">\(\{\omega_{k}\}\)</span> are independent and they obey the geometric
distribution. A rigorous way to see this is the strong Markov property.
Note <span class="math notranslate nohighlight">\(\tau_{k}\)</span> is a stopping time, since the event
<span class="math notranslate nohighlight">\(\{\tau_{k} = t\}\)</span> can be determined by just looking at
<span class="math notranslate nohighlight">\(X_{1},\ldots,X_{t}\)</span>, and hence waiting times
<span class="math notranslate nohighlight">\(\omega_{1} = \tau_{1},\omega_{2} = \tau_{2} - \tau_{1},\ldots,\omega_{n} = \tau_{n} - \tau_{n - 1}\)</span>
are independent.</p>
<p>The <strong>continuous-time Bernoulli process</strong> is a set of RVs
<span class="math notranslate nohighlight">\(X_{t},t \in (0, + \infty)\)</span> where each <span class="math notranslate nohighlight">\(X_{t}\)</span> obeys
Bernoulli distribution <span class="math notranslate nohighlight">\(Bernoulli(p)\)</span>. The objective is to find
the probability of having <span class="math notranslate nohighlight">\(k\)</span> arrivals before time <span class="math notranslate nohighlight">\(t\)</span>. The
assumption is that if <span class="math notranslate nohighlight">\(t\)</span> is divided into <span class="math notranslate nohighlight">\(n\)</span> time slots of
equal length <span class="math notranslate nohighlight">\(\delta\)</span>, then the probability of having <span class="math notranslate nohighlight">\(k\)</span>
arrivals in each interval is</p>
<div class="math notranslate nohighlight">
\[\begin{split}p\left( k,\delta \right) = o\left( \delta^{2} \right) + \left\{ \begin{matrix}
1 - \lambda\delta &amp; k = 0 \\
\text{λδ} &amp; k = 1 \\
0 &amp; k &gt; 1 \\
\end{matrix} \right.\\end{split}\]
<p>where <span class="math notranslate nohighlight">\(o\left( \delta^{2} \right)\)</span> is a second-order infinitesimal
of <span class="math notranslate nohighlight">\(\delta\)</span> and <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span>. This assumption has following
implications,</p>
<ol class="arabic simple">
<li>The probability of have one arrival in the small time window is
proportional to its length by a constant ratio <span class="math notranslate nohighlight">\(\lambda\)</span>, which
is named <strong>arrival rate</strong> or <strong>success rate</strong>.</li><li>When <span class="math notranslate nohighlight">\(\delta \rightarrow 0\)</span>, the probability of have no
arrivals in the small time interval <span class="math notranslate nohighlight">\(\delta\)</span> approaches 1.</li><li>When <span class="math notranslate nohighlight">\(\delta \rightarrow 0\)</span>, the probability of getting two or
more arrivals in the small interval <span class="math notranslate nohighlight">\(\delta\)</span> approaches 0;
moreover, this probability degenerates quadratically, faster than the
probability of having one arrival.</li>
</ol>
<p>Let <span class="math notranslate nohighlight">\(\mathbb{P(}k;\lambda,t)\)</span> be the probability of have <span class="math notranslate nohighlight">\(k\)</span>
arrivals before time <span class="math notranslate nohighlight">\(t\)</span> with arrival rate <span class="math notranslate nohighlight">\(\lambda\)</span>. Under
above assumption, <span class="math notranslate nohighlight">\(\mathbb{P(}k;\lambda,t)\)</span> becomes the PMF of a
binomial distribution, that is, <span class="math notranslate nohighlight">\(k\)</span> successes in
<span class="math notranslate nohighlight">\(n = \frac{t}{\delta}\)</span> trials. To see this, check that</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbb{P}\left( k;\lambda,t \right) = \lim_{n \rightarrow \infty}\sum_{n_{0} + n_{1} + n_{2} = n}^{}{\left( 1 - \frac{\text{λt}}{n} + o\left( \delta^{2} \right) \right)^{n_{0}}\left( \frac{\text{λt}}{n} + o\left( \delta^{2} \right) \right)^{n_{1}}}\left( o\left( \delta^{2} \right) \right)^{n_{2}} = \lim_{n \rightarrow \infty}\begin{pmatrix}
n \\
k \\
\end{pmatrix}\left( \frac{\text{λt}}{n} \right)^{k}\left( 1 - \frac{\text{λt}}{n} \right)^{n - k}\end{split}\]
<p>where <span class="math notranslate nohighlight">\(n_{0}\)</span> is the number of slots without arrivals,
<span class="math notranslate nohighlight">\(n_{1}\)</span> the number of slots with one arrival and <span class="math notranslate nohighlight">\(n_{2}\)</span> the
number of slots with more than one arrivals. Continue the limit
calculation we will have</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbb{P}\left( k;\lambda,t \right) = \lim_{n \rightarrow \infty}\begin{pmatrix}
n \\
k \\
\end{pmatrix}\left( \frac{\text{λt}}{n} \right)^{k}\left( 1 - \frac{\text{λt}}{n} \right)^{n - k} = \frac{\left( \text{λt} \right)^{k}}{k!}\lim_{n \rightarrow \infty}\frac{n!}{\left( n - k \right)! \times n^{k}}\lim_{n \rightarrow \infty}\left( 1 - \frac{\text{λt}}{n} \right)^{n - k} = \frac{\left( \text{λt} \right)^{k}}{k!}e^{- \text{λt}}\end{split}\]
<p>where
<span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty}\frac{n!}{\left( n - k \right)! \times n^{k}} = 1\)</span>
and
<span class="math notranslate nohighlight">\(\lim_{n \rightarrow \infty}\left( 1 - \frac{\text{λt}}{n} \right)^{n - k} = e^{- \lambda t}\)</span>.
Define a discrete distribution of a RV <span class="math notranslate nohighlight">\(X\)</span> with PMF
<span class="math notranslate nohighlight">\(\mathbb{P}\left\{ X = k \right\} = \frac{\lambda^{k}}{k!}e^{- \lambda}\)</span>
as the <strong>Poisson distribution</strong> with parameter <span class="math notranslate nohighlight">\(\lambda\)</span>, which is
the probability of have <span class="math notranslate nohighlight">\(k\)</span> arrivals before time <span class="math notranslate nohighlight">\(1\)</span>, and we
use <span class="math notranslate nohighlight">\(X\sim\text{Poisson}(\lambda)\)</span> to say <span class="math notranslate nohighlight">\(X\)</span> obeys Poisson
distribution with parameter <span class="math notranslate nohighlight">\(\lambda\)</span>.
<span class="math notranslate nohighlight">\(\mathbb{P(}k;\lambda,t)\)</span> obeys Poisson distribution with
parameter <span class="math notranslate nohighlight">\(\text{λt}\)</span>. <span class="math notranslate nohighlight">\(\text{λt}\)</span> is both the expected
value of the Poisson distribution and the underlying binomial
distribution. <span class="math notranslate nohighlight">\(\text{λt}\)</span> is also the variance of the Poisson, as
well as the limiting variance of the underlying binomial distribution:
as <span class="math notranslate nohighlight">\(\delta \rightarrow 0\)</span>, <span class="math notranslate nohighlight">\(p = \lambda\delta \rightarrow 0\)</span>
and <span class="math notranslate nohighlight">\((1 - p) \rightarrow 1\)</span>, therefore
<span class="math notranslate nohighlight">\(\text{np}\left( 1 - p \right) \rightarrow np = n\lambda\delta = \lambda t\)</span>.</p>
<ul class="simple">
<li>Sum of independent Poisson RVs is also a Poisson. Suppose
<span class="math notranslate nohighlight">\(X_{1}\sim\text{Poisson}\left( \lambda_{1} \right)\)</span>,
<span class="math notranslate nohighlight">\(X_{2}\sim\text{Poisson}\left( \lambda_{2} \right)\)</span>, then the
PMF of <span class="math notranslate nohighlight">\(X_{1} + X_{2}\)</span> is calculated as the following,</li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}{\mathbb{P}\left\{ X_{1} + X_{2} = k \right\} = \sum_{k_{1} + k_{2} = k}^{}{\frac{\lambda_{1}^{k_{1}}}{k_{1}!}e^{- \lambda_{1}} \times \frac{\lambda_{2}^{k_{2}}}{k_{2}!}e^{- \lambda_{2}}} = \frac{e^{- (\lambda_{1} + \lambda_{2})}}{k!}\sum_{k_{1} + k_{2} = k}^{}\frac{k!}{k_{1}!k_{2}!}\lambda_{1}^{k_{1}}\lambda_{2}^{k_{2}}
}{= \frac{e^{- (\lambda_{1} + \lambda_{2})}}{k!}\sum_{k_{1} + k_{2} = k}^{}\begin{pmatrix}
k \\
k_{1} \\
\end{pmatrix}\lambda_{1}^{k_{1}}\lambda_{2}^{k_{2}} = \frac{e^{- (\lambda_{1} + \lambda_{2})}}{k!}{(\lambda_{1} + \lambda_{2})}^{k}}\end{split}\]
<p>where<span class="math notranslate nohighlight">\({(\lambda_{1} + \lambda_{2})}^{k} = \sum_{k_{1} + k_{2} = k}^{}\begin{pmatrix}
k \\
k_{1} \\
\end{pmatrix}\lambda_{1}^{k_{1}}\lambda_{2}^{k_{2}}\)</span> is by the famous
binomial theorem. It follows that
<span class="math notranslate nohighlight">\(X_{1} + X_{2}\sim\ \text{Poisson}\left( \lambda_{1} + \lambda_{2} \right)\)</span>.</p>
<ul class="simple">
<li>The <strong>first arrival time</strong> <span class="math notranslate nohighlight">\(\text{τ\ }\)</span>for the continuous
Bernoulli process is derived by calculating the probability of no
success taking places within time <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(1\)</span> success
happening between time <span class="math notranslate nohighlight">\(t\)</span> and time <span class="math notranslate nohighlight">\(t + \delta\)</span>, and
then let <span class="math notranslate nohighlight">\(\delta \rightarrow 0\)</span>, as shown below.</li>
</ul>
<blockquote>
<div>The probability of this particular event happening is
<span class="math notranslate nohighlight">\(\mathbb{P}\left( 0;\lambda,t \right) \times \left( \lambda\delta + o\left( \delta^{2} \right) \right)\)</span>.
Denote the density function of <span class="math notranslate nohighlight">\(\tau\)</span> as <span class="math notranslate nohighlight">\(f(t;\lambda)\)</span>
and we have
<span class="math notranslate nohighlight">\(\int_{t}^{t + \delta}{f(t;\lambda)dt}\mathbb{= P}\left( 0;\lambda,t \right) \times (\lambda\delta + o(\delta^{2}))\)</span>.
As <span class="math notranslate nohighlight">\(\delta \rightarrow 0\)</span></blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}f\left( t;\lambda \right) = \frac{\partial\left( \int_{t}^{t + \delta}{f\left( t;\lambda \right)\text{dt}} \right)}{\partial\delta} = \operatorname{}\frac{\int_{t}^{t + \delta}{f(t;\lambda)dt}}{\delta} = \operatorname{}{\frac{\mathbb{P}\left( 0;\lambda,t \right)\left( \lambda\delta + o\left( \delta^{2} \right) \right)}{\delta} = \lambda e^{- \lambda t}}\\Define a distribution with PDF
:math:`f\left( x \right) = \lambda e^{- \lambda x}` as the
**exponential distribution** with parameter :math:`\lambda`. Clearly
the first arrival time :math:`\tau` obeys exponential distribution
with parameter :math:`\lambda`.The probability of not getting a
success along with time decreases exponentially. Exponential
distribution can be viewed as the continuous version of geometric
distribution. Generally, when :math:`p` is smaller, the geometric
distribution is more near the exponential distribution with parameter
:math:`\lambda = p`.\end{aligned}\end{align} \]
<p><a class="reference internal" href="media/image10.png"><img alt="image10" src="media/image10.png" style="width: 3.39855in; height: 2.15229in;" /></a></p>
<p><span class="math notranslate nohighlight">\(p = \lambda = 0.2,\)</span> <span class="math notranslate nohighlight">\(p = \lambda = 0.8\)</span></p>
<p><em>Figure</em> <em>0‑2 Comparison between exponential distribution and geometric
distribution</em></p>
<ul class="simple">
<li>The <strong>waiting time</strong> for the <span class="math notranslate nohighlight">\(k\)</span>th success (<span class="math notranslate nohighlight">\(k \geq 1\)</span>)
is derived by letting <span class="math notranslate nohighlight">\(k - 1\)</span> successes happen within time
<span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(1\)</span> success happen between time <span class="math notranslate nohighlight">\(t\)</span> and
time <span class="math notranslate nohighlight">\(t + \delta\)</span>, and them making
<span class="math notranslate nohighlight">\(\delta \rightarrow 0\)</span>. By a similar inference shown above, we
have the PDF
<span class="math notranslate nohighlight">\(f\left( t;\lambda,k \right) = \frac{\left( \text{λτ} \right)^{k - 1}}{(k - 1)!}\text{λe}^{- \text{λτ}}\)</span>
(<span class="math notranslate nohighlight">\(k \geq 1\)</span>). The distribution of this PDF is named <strong>Erlang
Distribution</strong>, of which the special case <span class="math notranslate nohighlight">\(k = 1\)</span> is the
exponential distribution.</li>
</ul>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><a class="reference internal" href="media/image11.emf"><img alt="image13" src="media/image11.emf" style="width: 2.61789in; height: 1.5in;" /></a></th>
<th class="head"><a class="reference internal" href="media/image12.png"><img alt="image14" src="media/image12.png" style="width: 2.47718in; height: 1.5in;" /></a></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><p class="first"><em>Erlang distribution with the
same</em> <span class="math notranslate nohighlight">\(k = 10\)</span> <em>but
varying</em> <span class="math notranslate nohighlight">\(\lambda\)</span></p>
<div class="last math notranslate nohighlight">
\[p = 0.4,\ p = 0.5,\ p =
0.6\]
</td>
<td><p class="first"><em>Erlang distribution with the
same</em> <span class="math notranslate nohighlight">\(\lambda = 0.4\)</span> <em>but
varying</em> <span class="math notranslate nohighlight">\(k\)</span></p>
<div class="last math notranslate nohighlight">
\[k = 5,\ k = 8,\ k = 10\]
</td>
</tr>
</tbody>
</table>
<blockquote>
<div><p><em>Figure</em> <em>0‑3 Illustrations of Erlang Distribution.</em></p>
<p>Not surprisingly, Erlang distribution is the continuous version of
Pascal distribution, and generally when <span class="math notranslate nohighlight">\(p\)</span> is smaller, the
Pascal distribution is more near the Erlang with parameter
<span class="math notranslate nohighlight">\(\lambda = p\)</span>.</p>
</blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><a class="reference internal" href="media/image13.png"><img alt="image16" src="media/image13.png" style="width: 3.86623in; height: 2.4in;" /></a></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><p class="first"><em>Figure</em> <em>0‑4 Comparison between Erlang distribution and Pascal
distribution when</em> <span class="math notranslate nohighlight">\(k = 5\)</span></p>
<div class="last math notranslate nohighlight">
\[p = \lambda = 0.2,\ p = \lambda = 0.4\]
</td>
</tr>
</tbody>
</table>
<p>With the above discussion, the relation between discrete-time and
continuous-time Bernoulli process can be clearly seen from the following
table.</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">&#160;</th>
<th class="head">Continuous-time</th>
<th class="head">Discrete-time</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Time continuity</td>
<td>Continuous</td>
<td>Discrete</td>
</tr>
<tr class="row-odd"><td>Arrival rate</td>
<td><span class="math notranslate nohighlight">\(\lambda\)</span> per
unit time</td>
<td><span class="math notranslate nohighlight">\(p\)</span> per time
slot</td>
</tr>
<tr class="row-even"><td># of arrivals within
a time interval</td>
<td>Poisson</td>
<td>Binomial</td>
</tr>
<tr class="row-odd"><td>Waiting time for
arrival</td>
<td>Exponential</td>
<td>Geometric</td>
</tr>
<tr class="row-even"><td>Time of the
<span class="math notranslate nohighlight">\(\mathbf{k}\)</span>t
h
arrival</td>
<td>Erlang</td>
<td>Pascal</td>
</tr>
</tbody>
</table>

<div class="section" id="mle-map-naive-bayes">
<h3>MLE, MAP &amp; Naïve Bayes<a class="headerlink" href="#mle-map-naive-bayes" title="Permalink to this headline">¶</a></h3>
<p><strong>Maximum Likelihood Estimator</strong> (MLE) is the most classic estimator for
parameters or latent variables. It is taking derivatives of logarithms
of <span class="math notranslate nohighlight">\(\mathbb{P(}X|\mathbf{\theta})\)</span> for discrete distributions or
<span class="math notranslate nohighlight">\(f(X|\mathbf{\theta})\)</span> for continuous distributions w.r.t.
<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span> where <span class="math notranslate nohighlight">\(X\)</span> is the sample, and estimate
<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span> as the one <span class="math notranslate nohighlight">\(\widehat{\mathbf{\theta}}\)</span>
that maximizes <span class="math notranslate nohighlight">\(\mathbb{P(}X|\mathbf{\theta})\)</span> or
<span class="math notranslate nohighlight">\(f(X|\mathbf{\theta})\)</span>. For example, if <span class="math notranslate nohighlight">\(X_{1},\ldots,X_{n}\)</span>
are i.i.d. RV from an exponential distribution, then</p>
<div class="math notranslate nohighlight">
\[L\left( X_{1},\ldots,X_{n}|\theta \right) = \log{f\left( X_{1},\ldots,X_{n} \middle| \theta \right)} = \log{\prod_{i = 1}^{n}{\theta e^{- \theta x_{i}}}} = \sum_{i = 1}^{n}{\log{\theta e^{- \theta x_{i}}}} = n\log\theta - \theta\sum_{i = 1}^{n}x_{i} \Rightarrow \frac{dL}{d\theta} = \frac{n}{\theta} - \sum_{i = 1}^{n}x_{i} \Rightarrow \widehat{\theta} = \frac{1}{\overline{X}}\]</div>
<p>In general, we write
<span class="math notranslate nohighlight">\({\widehat{\mathbf{\theta}}}_{\text{MLE}} = \arg{\max{\mathbb{P(}X|\mathbf{\theta})}}\)</span>
or
<span class="math notranslate nohighlight">\({\widehat{\mathbf{\theta}}}_{\text{MLE}} = \arg{\max{f(X|\mathbf{\theta})}}\)</span>.
On the contrary, <strong>Maximum a Posterior Estimator</strong> (MAP) finds
<span class="math notranslate nohighlight">\({\widehat{\mathbf{\theta}}}_{\text{MAP}} = \arg{\max{\mathbb{P(}\mathbf{\theta}|X)}}\)</span>
or
<span class="math notranslate nohighlight">\({\widehat{\mathbf{\theta}}}_{\text{MAP}} = \arg{\max{f(\mathbf{\theta}|X)}}\)</span>.
WLOG, from this point on we “misuse” <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> to also
represent density. Check that</p>
<div class="math notranslate nohighlight">
\[{\widehat{\mathbf{\theta}}}_{\text{MAP}} = \arg{\max{\mathbb{P(}\mathbf{\theta}|X)}} = {\widehat{\mathbf{\theta}}}_{\text{MAP}} = \arg{\max\frac{\mathbb{P}\left( X \middle| \mathbf{\theta} \right)\mathbb{P(}\mathbf{\theta})}{\mathbb{P(}X)}} = \arg{\max{\mathbb{P}\left( X \middle| \mathbf{\theta} \right)\mathbb{P(}\mathbf{\theta})}}\]</div>
<p>The last equation holds since <span class="math notranslate nohighlight">\(\mathbb{P(}X)\)</span> is not dependent on
<span class="math notranslate nohighlight">\(\theta\)</span> so it can be treated like a constant in the maximization,
even though it might be hard to compute what it really is. MAP allows
specification of prior distribution. When
<span class="math notranslate nohighlight">\(\mathbb{P(}\mathbf{\theta})\)</span> is uniform, MAP degenerates to an
MLE.</p>
<p><strong>Naïve Bayes</strong> is a simplest probabilistic classification model making
direct use of Bayes Theorem. Given an i.i.d. labelled sample
<span class="math notranslate nohighlight">\(\left( X^{\left( i \right)}\mathbf{,}Y_{i} \right)\mathbf{\sim}\mathbb{P}_{\mathbf{\theta}},i = 1,\ldots,n\)</span>
where <span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span> is the parameter vector of
<span class="math notranslate nohighlight">\(\mathbb{P}\)</span> and each <span class="math notranslate nohighlight">\(X^{\left( i \right)}\)</span> is equipped
with <span class="math notranslate nohighlight">\(k\)</span> featuers, i.e.
<span class="math notranslate nohighlight">\(X^{\left( i \right)} = (X_{1}^{\left( i \right)},\ldots,X_{k}^{\left( i \right)})\)</span>.
We then evaluate the label of new observation
<span class="math notranslate nohighlight">\(X\mathbf{= (}X_{1}\mathbf{,\ldots,}X_{k}\mathbf{)}\)</span> by the
following,</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}_{\mathbf{\theta}}\left( Y \middle| X \right) = \frac{\mathbb{P}_{\mathbf{\theta}}(X|Y)\mathbb{P}_{\mathbf{\theta}}(Y)}{\mathbb{P}_{\mathbf{\theta}}(X)} \propto \mathbb{P}_{\mathbf{\theta}}(X|Y)\mathbb{P}_{\mathbf{\theta}}(Y)\]</div>
<p>The <strong>Naive Bayes assumption</strong> is that: given the label <span class="math notranslate nohighlight">\(Y\)</span>, the
features are independent (but not necessarily identically distributed).
Thus,</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}_{\mathbf{\theta}}\left( Y = y \middle| X \right) \propto \mathbb{P}_{\mathbf{\theta}}(Y = y)\prod_{i = 1}^{k}{\mathbb{P}_{\mathbf{\theta}}(X_{i}|Y = y)}\]</div>
<p>The model is now obviously
<span class="math notranslate nohighlight">\(\widehat{y} = \arg{\operatorname{}{\mathbb{P}_{\widehat{\mathbf{\theta}}}(Y = y)\prod_{i = 1}^{k}{\mathbb{P}_{\widehat{\mathbf{\theta}}}(X_{i}|Y = y)}}}\)</span>.
The interpretation of this model is that the data are generated from the
following process:</p>
<ol class="arabic simple">
<li>The label is first drawn from according to
<span class="math notranslate nohighlight">\(\mathbb{P}_{\widehat{\mathbf{\theta}}}(Y = y)\)</span>.</div></div></div></li><li>Then each feature of <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is drawn from
<span class="math notranslate nohighlight">\(\mathbb{P}_{\widehat{\mathbf{\theta}}}\left( X \middle| Y = y \right) = \prod_{i = 1}^{k}{\mathbb{P}_{\mathbf{\theta}}(X_{i}|Y = y)}\)</span>.</li>
</ol>
<p>We typically assume
<span class="math notranslate nohighlight">\(\mathbb{P}_{\widehat{\mathbf{\theta}}}(Y = y)\)</span> is a multinomial,
while <span class="math notranslate nohighlight">\(\mathbb{P}_{\widehat{\mathbf{\theta}}}(X|Y = y)\)</span> is subject
to choice. An important reason for the Naïve Bayes assumption is that it
makes estimation of <span class="math notranslate nohighlight">\(\theta\)</span> much easier by using every feature as
a sample point; an assumption on the joint distribution
<span class="math notranslate nohighlight">\(\mathbb{P}_{\mathbf{\theta}}(X|Y)\)</span> might work, however it uses
every single feature vector <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> as a sample point and
requires a larger size of data for estimation. That is also a main
rational behind the claim that “inaccurate but simple models could work
better than accurate but complex models”.</p>
<p>If we assume the labels are from a multinomial <span class="math notranslate nohighlight">\(\mathbf{\Phi}\)</span>,
and given the label, features are also from a multinomial
<span class="math notranslate nohighlight">\(\mathbf{\Phi}_{l}\)</span> dependent on <span class="math notranslate nohighlight">\(l\)</span>, then we can simply
evaluate both <span class="math notranslate nohighlight">\(\mathbb{P(}l)\)</span> and
<span class="math notranslate nohighlight">\(\mathbb{P(}\mathbf{x(}i\mathbf{)}|l)\)</span> by counts, and let</p>
<div class="math notranslate nohighlight">
\[\widehat{l} = \arg{\operatorname{}{\left( \frac{1}{n}\sum_{i = 1}^{n}\mathbb{I}_{l\left( \mathbf{x}_{i} \right) = l} \right) \times \prod_{i = 1}^{k}\frac{\mathbb{I}_{l\left( \mathbf{x}_{i} \right) = l}\sum_{j = 1}^{n}\mathbb{I}_{\mathbf{x}\left( j \right) = \mathbf{x}_{i}(j)}}{}}}\]

<div class="section" id="em-algorithm-expectation-maximization-algorithm-em-algorithm-is-to-perform-mle-or-map-when-some-variables-are-unobservable-lets-first-see-an-example-the-algorithm-emerges-from-estimating-the-latent-means-of-gaussian-mixtures-suppose-we-have-a-set-of-data-and-they-are-assumed-to-be-generated-from-the-following-process">
<h3>EM Algorithm. <strong>Expectation Maximization Algorithm</strong> (EM Algorithm) is to perform MLE or MAP when some variables are unobservable. Let’s first see an example. The algorithm emerges from estimating the latent means of <strong>Gaussian mixtures</strong>. Suppose we have a set of data <span class="math notranslate nohighlight">\(X_{1},X_{2},\ldots,X_{n}\)</span>, and they are assumed to be generated from the following process,<a class="headerlink" href="#em-algorithm-expectation-maximization-algorithm-em-algorithm-is-to-perform-mle-or-map-when-some-variables-are-unobservable-lets-first-see-an-example-the-algorithm-emerges-from-estimating-the-latent-means-of-gaussian-mixtures-suppose-we-have-a-set-of-data-and-they-are-assumed-to-be-generated-from-the-following-process" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>Let
<span class="math notranslate nohighlight">\((\mathbf{\mu}_{1},\mathbf{\Sigma}_{1}),\ldots,(\mathbf{\mu}_{k},\mathbf{\Sigma}_{k})\)</span>
be the set of possible Gaussians, draw indexes
<span class="math notranslate nohighlight">\(Z_{1},\ldots,Z_{n}\)</span> from a multinomial
<span class="math notranslate nohighlight">\((\phi_{1},\ldots,\phi_{k})\)</span> where it is possible that
<span class="math notranslate nohighlight">\(Z_{i} = Z_{j}\)</span> for some <span class="math notranslate nohighlight">\(i \neq j\)</span>.</div></li><li><span class="math notranslate nohighlight">\(X_{1},X_{2},\ldots,X_{n}\)</span> are drawn from
<span class="math notranslate nohighlight">\(N\text{orm}\text{al}\left( \mathbf{\mu}_{Z_{1}},\mathbf{\Sigma}_{Z_{1}} \right),\ldots,\text{Normal}(\mathbf{\mu}_{Z_{n}},\mathbf{\Sigma}_{Z_{n}})\)</span>.</li>
</ol>
<p>Here <span class="math notranslate nohighlight">\(Z_{1},\ldots,Z_{n}\)</span> are latent variables. If we just assume
<span class="math notranslate nohighlight">\(Z_{1} = z_{1},\ldots,Z_{n} = z_{n}\)</span> and
<span class="math notranslate nohighlight">\(z_{1},\ldots,z_{n}\)</span> are known, then by MLE <span class="math notranslate nohighlight">\(\phi_{i}\)</span> is
estimated by counts, and <span class="math notranslate nohighlight">\(\mu_{i}\)</span> is estimated by the mean of the
data generated from
<span class="math notranslate nohighlight">\(\text{Normal}\left( \mathbf{\mu}_{i},\mathbf{\Sigma}_{i} \right)\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{ \begin{matrix}
{\widehat{\phi}}_{j} = \frac{1}{n}\sum_{i = 1}^{n}\mathbb{I}_{z_{i} = j} \\
{\widehat{\mathbf{\mu}}}_{j} = \frac{\sum_{i = 1}^{n}{X_{i}\mathbb{I}_{z_{i} = j}}}{\sum_{i = 1}^{n}\mathbb{I}_{z_{i} = j}} \\
{\widehat{\mathbf{\Sigma}}}_{j} = \frac{\sum_{i = 1}^{n}{\left( X_{i} - {\widehat{\mathbf{\mu}}}_{j} \right)^{T}\left( X_{i} - {\widehat{\mathbf{\mu}}}_{j} \right)\mathbb{I}_{z_{i} = j}}}{\sum_{i = 1}^{n}\mathbb{I}_{z_{i} = j}} \\
\end{matrix} \right.\ ,j = 1,\ldots,k\end{split}\]
<p>Now by Bayesian rules,</p>
<div class="math notranslate nohighlight">
\[\omega_{i,j}\mathbb{:: = P}\left( Z_{i} = j \middle| X_{i} \right) = \frac{\mathbb{P}\left( X_{i} \middle| Z_{i} = j \right)\mathbb{P}\left( Z_{i} = j \right)}{\sum_{j = 1}^{k}{\mathbb{P}\left( X_{i} \middle| Z_{i} = j \right)\mathbb{P}\left( Z_{i} = j \right)}}\]
<p>where (omits parameters for clarity)</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X_{i} \middle| Z_{i} = j \right)\mathbb{P}\left( Z_{i} = j \right) = \left( \frac{1}{\left( 2\pi \right)^{\frac{n}{2}}\left| \mathbf{\Sigma}_{j} \right|^{\frac{1}{2}}}\exp{( - \frac{1}{2}\left( \mathbf{x}_{i} - \mathbf{\mu}_{j} \right)^{T}\mathbf{\Sigma}_{j}^{- 1}(\mathbf{x}_{i} - \mathbf{\mu}_{j}))} \right) \times \phi_{j}\]
<p>The E-Step for EM Algorithm for Gaussian Mixtures is first guess some
initial values for <span class="math notranslate nohighlight">\(\phi_{j}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{\mu}_{j}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{j}\)</span>, and them compute the quantity
<span class="math notranslate nohighlight">\(\omega_{i,j}\)</span> for every <span class="math notranslate nohighlight">\(i,j\)</span>, and then the M-step updates
<span class="math notranslate nohighlight">\(\phi_{j}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{\mu}_{j}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}_{j}\)</span> by the following formula, where basically
<span class="math notranslate nohighlight">\(\omega_{i,j}\)</span> takes place of <span class="math notranslate nohighlight">\(\mathbb{I}_{z_{i} = j}\)</span> of
those estimations of MLE.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{ \begin{matrix}
{\widehat{\phi}}_{j} = \frac{1}{n}\sum_{i = 1}^{n}\omega_{i,j} \\
{\widehat{\mathbf{\mu}}}_{j} = \frac{\sum_{i = 1}^{n}{X_{i}\omega_{i,j}}}{\sum_{i = 1}^{n}\omega_{i,j}} \\
{\widehat{\mathbf{\Sigma}}}_{j} = \frac{1}{\sum_{i = 1}^{n}\omega_{i,j}}\sum_{i = 1}^{n}{\left( X_{i} - {\widehat{\mathbf{\mu}}}_{j} \right)^{T}\left( X_{i} - {\widehat{\mathbf{\mu}}}_{j} \right)\omega_{i,j}} \\
\end{matrix} \right.\ ,j = 1,\ldots,k\end{split}\]
<p>The above formulas are to be derived later. The EM Algorithm iteratively
repeats the E-step and M-step until a satisfactory convergence is
reached. Now we introduce the general EM algorithm. Given a
probabilistic model <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> parameterized by
<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>, and data
<span class="math notranslate nohighlight">\(X_{1} = \mathbf{x}_{1},\ldots,X_{n} = \mathbf{x}_{n}\)</span>, a mixture
model over a set of distributions <span class="math notranslate nohighlight">\(\mathbb{P}_{k},k \in K\)</span>, where
<span class="math notranslate nohighlight">\(K\)</span> is an index set, assumes the data is generated by the
following process,</p>
<ol class="arabic simple">
<li>Indexes <span class="math notranslate nohighlight">\(Z_{1},\ldots,Z_{n}\)</span> are drawn from a distribution
<span class="math notranslate nohighlight">\(\mathbb{Q}\)</span> over <span class="math notranslate nohighlight">\(K\)</span>.</li><li><span class="math notranslate nohighlight">\(X_{1},X_{2},\ldots,X_{n}\)</span> are drawn<span class="math notranslate nohighlight">\(\ \)</span>from
<span class="math notranslate nohighlight">\(\mathbb{P}_{Z_{1}},\mathbb{P}_{Z_{2}},\ldots,\mathbb{P}_{Z_{n}}\)</span>.</li>
</ol>
<p>And we want to maximize the following objective function,</p>
<div class="math notranslate nohighlight">
\[L\left( \mathbf{\theta} \right) = \sum_{i = 1}^{n}{\log{\mathbb{P(}X_{i}|\mathbf{\theta})}} = \sum_{i = 1}^{n}{\log{\sum_{Z_{i} \in K}^{}{\mathbb{P(}X_{i},Z_{i}|\mathbf{\theta})}}}\  = \sum_{i = 1}^{n}{\log{\sum_{Z_{i} \in K}^{}\frac{\mathbb{Q(}Z_{i}\mathbb{)P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)}{\mathbb{Q(}Z_{i})}}} = \sum_{i = 1}^{n}{\log{\mathbb{E}_{Z_{i}}\left\lbrack \frac{\mathbb{P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)}{\mathbb{Q(}Z_{i})} \right\rbrack}}\]
<p>where <span class="math notranslate nohighlight">\(\mathbb{Q}\)</span> is the model of <span class="math notranslate nohighlight">\(Z_{i}\)</span>s and
<span class="math notranslate nohighlight">\(\mathbb{E}_{Z_{i}}\)</span> is an expectation w.r.t. <span class="math notranslate nohighlight">\(Z_{i}\)</span>. Now
we need a called Jensen’s inequality (a rigorous proof requires measure
theory), which states,</p>
<ol class="arabic simple">
<li>If <span class="math notranslate nohighlight">\(f\)</span> is a convex function, then
<span class="math notranslate nohighlight">\(f\left( \mathbb{E}X \right)\mathbb{\leq E}\left\lbrack f(X) \right\rbrack\)</span>
for any random variable <span class="math notranslate nohighlight">\(X\)</span>.</li><li>If <span class="math notranslate nohighlight">\(f\)</span> is strictly convex, then
<span class="math notranslate nohighlight">\(f\left( \mathbb{E}X \right)\mathbb{= E}\left\lbrack f(X) \right\rbrack\)</span>
iff <span class="math notranslate nohighlight">\(X = \mathbb{E}X\)</span> almost surely (in this case <span class="math notranslate nohighlight">\(X\)</span> is
almost surely a constant).</li>
</ol>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>Figure ‑ The intuition behind EM.</td>
</tr>
</tbody>
</table>
<p>We also need to discuss the motive behind EM. EM is actually a method of
lower bounds. The idea is that <span class="math notranslate nohighlight">\(L\left( \mathbf{\theta} \right)\)</span>
is very often a concave function, and we can approach its maximum by, at
the <span class="math notranslate nohighlight">\(i\)</span>th step, first constructing a concave lower tight bounds
<span class="math notranslate nohighlight">\(l_{i}(\mathbf{\theta})\)</span> s.t.
<span class="math notranslate nohighlight">\(L\left( \mathbf{\theta} \right) \geq l_{i}(\mathbf{\theta})\)</span> and
<span class="math notranslate nohighlight">\(L\left( \mathbf{\theta}_{i}^{\mathbf{*}} \right) = l_{i}(\mathbf{\theta}_{i}^{*})\)</span>
for a given <span class="math notranslate nohighlight">\(\mathbf{\theta}_{i}^{*}\)</span>, and then climbing up by
finding the maximum of <span class="math notranslate nohighlight">\(l_{i}\)</span> as
<span class="math notranslate nohighlight">\(\mathbf{\theta}_{i + 1}^{*}\)</span>. Now we carry on the calculation,
using the fact that logarithm is a concave function,</p>
<div class="math notranslate nohighlight">
\[L\left( \mathbf{\theta} \right) = \sum_{i = 1}^{n}{\log{\mathbb{E}_{Z_{i}}\left\lbrack \frac{\mathbb{P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)}{\mathbb{Q(}Z_{i})} \right\rbrack}} \geq \sum_{i = 1}^{n}{\mathbb{E}_{Z_{i}}\left\lbrack \log\frac{\mathbb{P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)}{\mathbb{Q}\left( Z_{i} \right)} \right\rbrack} = \sum_{i = 1}^{n}{\sum_{Z_{i} \in K}^{}{\mathbb{Q}\left( Z_{i} \right)\log\frac{\mathbb{P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)}{\mathbb{Q}\left( Z_{i} \right)}}} = l\mathbb{(Q,}\mathbf{\theta})\]
<p>We need to further identify when the equality holds. Note the equality
holds when
<span class="math notranslate nohighlight">\(\frac{\mathbb{P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)}{\mathbb{Q(}Z_{i})}\)</span>
is a constant, and it is positive since both numerator and denominator
are probabilities (or densities), then</p>
<div class="math notranslate nohighlight">
\[\mathbb{Q}\left( Z_{i} \right)\mathbb{\propto P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)\mathbb{\Rightarrow Q}\left( Z_{i} \right) = \frac{\mathbb{P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)}{\sum_{Z_{i} \in K}^{}{\mathbb{P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)}} = \frac{\mathbb{P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)}{\mathbb{P}\left( X_{i} \middle| \mathbf{\theta} \right)}\mathbb{= P}\left( Z_{i} \middle| X_{i}\mathbf{,\theta} \right)\]
<p>Thus
<span class="math notranslate nohighlight">\(L\left( \mathbf{\theta} \right) = l\mathbb{(Q,}\mathbf{\theta})\)</span>
if
<span class="math notranslate nohighlight">\(\mathbb{Q = P}\left( Z_{i} \middle| X_{i}\mathbf{,\theta} \right)\)</span>,
and we then maximize <span class="math notranslate nohighlight">\(l\)</span> w.r.t. <span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>. This
gives the general version of EM algorithm,</p>
<ol class="arabic simple">
<li>Initialize <span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span> to some initial guess.</li><li>E-step: set
<span class="math notranslate nohighlight">\(\mathbb{Q}\left( Z_{i} \right)\mathbb{= P}\left( Z_{i} \middle| X_{i}\mathbf{,\theta} \right)\)</span>.</li>
<li>M-step: updates
<span class="math notranslate nohighlight">\(\mathbf{\theta} = \arg{\max{\sum_{i = 1}^{n}{\sum_{Z_{i} \in K}^{}{\mathbb{Q}\left( Z_{i} \right)\log\frac{\mathbb{P}\left( X_{i},Z_{i} \middle| \mathbf{\theta} \right)}{\mathbb{Q}\left( Z_{i} \right)}}}}}\)</span>.</li>
<li>Repeat E-step and M-step until a satisfactory convergence is reached.</li>
</ol>
<p>Back to our intuition <a class="reference external" href="#b3">above</a>,
<span class="math notranslate nohighlight">\(\mathbb{Q,}\mathbf{\theta}\)</span> are both arguments of <span class="math notranslate nohighlight">\(l\)</span>. When
we initialize the EM, we let <span class="math notranslate nohighlight">\(\mathbf{\theta}_{0}^{*}\)</span> be a proper
guess, and
<span class="math notranslate nohighlight">\(\mathbb{Q}_{0}^{*}\mathbb{= P}\left( Z_{i} \middle| X_{i}\mathbf{,}\mathbf{\theta}_{0}^{*} \right)\)</span>,
then <span class="math notranslate nohighlight">\(L = l\)</span>. We then perform maximization to acquire
<span class="math notranslate nohighlight">\(\mathbf{\theta}_{1}^{*}\)</span>, and let
<span class="math notranslate nohighlight">\(\mathbb{Q}_{1}^{*}\mathbb{= P}\left( Z_{i} \middle| X_{i}\mathbf{,}\mathbf{\theta}_{1}^{*} \right)\)</span>,
and so on. Note in this process clearly
<span class="math notranslate nohighlight">\(l\left( \mathbb{Q}_{i}^{*},\mathbf{\theta}_{i}^{*} \right) \leq l\left( \mathbb{Q}_{i}^{*},\mathbf{\theta}_{i + 1}^{*} \right)\)</span>,
and
<span class="math notranslate nohighlight">\(l\left( \mathbb{Q}_{i}^{*},\mathbf{\theta}_{i + 1}^{*} \right) \leq l\left( \mathbb{Q}_{i + 1}^{*},\mathbf{\theta}_{i + 1}^{*} \right) = L\)</span>.
Thus <span class="math notranslate nohighlight">\(l\)</span> is monotonically increasing for every E-step and M-step.
This process is also actually a coordinate ascent.</p>
<p>We now derive the EM formulas for Gaussian mixture. <a class="reference external" href="http://cs229.stanford.edu/notes/cs229-notes8.pdf">FUTURE
WORK</a>.</p>

<div class="section" id="bayesian-network-given-rvs-we-know-that-its-joint-probability-distribution-which-is-a-probability-mass-function-or-a-probability-density-function-can-be-factorized-by-the-chain-rule">
<h3>Bayesian Network. Given RVs <span class="math notranslate nohighlight">\(X_{1},\ldots,X_{n}\)</span>, we know that its joint probability distribution <span class="math notranslate nohighlight">\(\mathbb{P(}X)\)</span>, which is a probability mass function or a probability density function, can be factorized by the chain rule,<a class="headerlink" href="#bayesian-network-given-rvs-we-know-that-its-joint-probability-distribution-which-is-a-probability-mass-function-or-a-probability-density-function-can-be-factorized-by-the-chain-rule" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X_{1},\ldots,X_{n} \right)\mathbb{= P(}X_{n}|X_{1},\ldots,X_{n - 1}\mathbb{)\ldots P(}X_{3}|X_{1},X_{2}\mathbb{)P}\left( X_{2} \middle| X_{1} \right)\mathbb{P(}X_{1})\]
<p>where notation like <span class="math notranslate nohighlight">\(\mathbb{P}(Y|X)\)</span> is short for
<span class="math notranslate nohighlight">\(\mathbb{P(}Y = y|X = x)\)</span>. We draw a graph
<span class="math notranslate nohighlight">\(G = (\left\{ 1,\ldots,n \right\},E)\)</span> by letting
<span class="math notranslate nohighlight">\(\left( i,j \right) \in E\)</span> if there is a factor of form
<span class="math notranslate nohighlight">\(\mathbb{P(}X_{j}|\ldots,X_{i},\ldots)\)</span>. Taking <span class="math notranslate nohighlight">\(n = 4\)</span> for
example, the resulting graph for the chain rule would look like the one
in <em>Figure 0‑1</em> <em>(a)</em>. It is obvious that the graph representation of
the chain rule is a complete directed acyclic graph (DAG), whose edge
set is <span class="math notranslate nohighlight">\(E = \{\left( i,j \right):i &lt; j\}\)</span>.</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><a class="reference internal" href="media/image15.emf"><img alt="image19" src="media/image15.emf" style="width: 1.73776in; height: 1.74205in;" /></a></th>
<th class="head"><a class="reference internal" href="media/image16.emf"><img alt="image20" src="media/image16.emf" style="width: 1.7375in; height: 1.7046in;" /></a></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><em>(a) chain rule</em></td>
<td><em>(b) with</em>
<span class="math notranslate nohighlight">\(X_{2}\bot X_{3}|X_{1}\)</span></td>
</tr>
<tr class="row-odd"><td><em>Figure</em> <em>0‑1 The DAGs of a 4-RV
factorization.</em></td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<p>We can have other factorizations of the joint distribution given
information of conditional independence. For example, if
<span class="math notranslate nohighlight">\(X_{2}\bot X_{3}|X_{1}\)</span>, then
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X_{3} \middle| X_{1},X_{2} \right)\mathbb{= P(}X_{3}|X_{1})\)</span>
(see <a class="reference external" href="#b8">remark</a> below), and <span class="math notranslate nohighlight">\(2 \rightarrow 3\)</span> edge of
<em>Figure 0‑1</em> <em>(a)</em> will be removed to form <em>Figure 0‑1</em> <em>(b)</em>.
Conversely, given a DAG <span class="math notranslate nohighlight">\(G = (\left\{ 1,\ldots,n \right\},E)\)</span>, we
can construct a factorization by letting</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X_{1},\ldots,X_{n} \right) = \prod_{i = 1}^{n}{\mathbb{P(}X_{i}\mathcal{|p(}X_{i}))}\]
<p>where <span class="math notranslate nohighlight">\(\mathcal{p}\left( X_{i} \right)\)</span> denotes the set of all
parents of <span class="math notranslate nohighlight">\(X_{i}\)</span> in <span class="math notranslate nohighlight">\(G\)</span> and could be <span class="math notranslate nohighlight">\(\varnothing\)</span>
for those without parents. Note when
<span class="math notranslate nohighlight">\(\mathbb{P(}X_{i}\mathcal{|p(}X_{i}))\)</span> is a well-defined
distribution, then <span class="math notranslate nohighlight">\(\mathbb{P}\left( X_{1},\ldots,X_{n} \right)\)</span>
is well defined. Recall that a DAG has a topological order
<span class="math notranslate nohighlight">\(\mathcal{X}_{1},\ldots,\mathcal{X}_{k}\)</span>. WLOG, assume
<span class="math notranslate nohighlight">\(X_{i}\)</span> are indexed according to their topological order, that is,
<span class="math notranslate nohighlight">\(\mathcal{X}_{1}\)</span> consists of RV indexed by
<span class="math notranslate nohighlight">\(1,\ldots,i_{1}\)</span>, <span class="math notranslate nohighlight">\(\mathcal{X}_{2}\)</span> consists of RVs indexed
by <span class="math notranslate nohighlight">\(i_{1} + 1,\ldots,i_{2}\)</span>, etc.</p>
<div class="math notranslate nohighlight">
\[\sum_{x_{1},\ldots,x_{n}}^{}{\mathbb{P}\left( X_{1} = x_{1},\ldots,X_{n} = x_{n} \right)} = \sum_{x_{1},\ldots,x_{n}}^{}{\prod_{i = 1}^{n}{\mathbb{P(}X_{i}\mathcal{|p(}X_{i}))}} = \sum_{x_{1},\ldots,x_{k - 1}}^{}\left( \sum_{x_{i_{k - 1} + 1},\ldots,x_{i_{k}}}^{}{\prod_{i = 1}^{n}{\mathbb{P}\left( X_{i} \middle| \mathcal{p}\left( X_{i} \right) \right)}} \right) = \left( \sum_{x_{i_{k - 1} + 1},\ldots,x_{i_{k}}}^{}{\prod_{i = i_{k - 1} + 1}^{i_{k}}{\mathbb{P}\left( X_{i} \middle| \mathcal{p}\left( X_{i} \right) \right)}} \right)\left( \sum_{x_{1},\ldots,x_{k - 1}}^{}{\prod_{i = 1}^{i_{k - 1}}{\mathbb{P}\left( X_{i} \middle| \mathcal{p}\left( X_{i} \right) \right)}} \right)\]
<p>Here the “summation” is misused to represent integration if
<span class="math notranslate nohighlight">\(\mathbb{P}\)</span> is a PDF. The above last identity is because only
factors in
<span class="math notranslate nohighlight">\(\prod_{i = i_{k - 1} + 1}^{i_{k}}{\mathbb{P}\left( X_{i} \middle| \mathcal{p}\left( X_{i} \right) \right)}\)</span>
are dependent on <span class="math notranslate nohighlight">\(x_{i_{k - 1} + 1},\ldots,x_{i_{k}}\)</span>. Then check
that</p>
<div class="math notranslate nohighlight">
\[\sum_{x_{i_{k - 1} + 1},\ldots,x_{i_{k}}}^{}{\prod_{i = i_{k - 1} + 1}^{i_{k}}{\mathbb{P}\left( X_{i} \middle| \mathcal{p}\left( X_{i} \right) \right)}} = \prod_{i = i_{k - 1} + 1}^{i_{k}}{\sum_{x_{i}}^{}{\mathbb{P}\left( X_{i} \middle| \mathcal{p}\left( X_{i} \right) \right)}} = 1\]
<p>since each factor in
<span class="math notranslate nohighlight">\(\prod_{i = i_{k - 1} + 1}^{i_{k}}{\mathbb{P}\left( X_{i} \middle| \mathcal{p}\left( X_{i} \right) \right)}\)</span>
is only dependent on <span class="math notranslate nohighlight">\(x_{i}\)</span>, and we arrive at</p>
<div class="math notranslate nohighlight">
\[\sum_{x_{1},\ldots,x_{n}}^{}{\mathbb{P}\left( X_{1} = x_{1},\ldots,X_{n} = x_{n} \right)} = \sum_{x_{1},\ldots,x_{k - 1}}^{}{\prod_{i = 1}^{i_{k - 1}}{\mathbb{P}\left( X_{i} \middle| \mathcal{p}\left( X_{i} \right) \right)}}\]
<p>Now only factors in
<span class="math notranslate nohighlight">\(\prod_{i = i_{k - 2} + 1}^{i_{k - 1}}{\mathbb{P}\left( X_{i} \middle| \mathcal{p}\left( X_{i} \right) \right)}\)</span>
are dependent on <span class="math notranslate nohighlight">\(x_{i_{k - 2} + 1},\ldots,x_{i_{k - 1}}\)</span>. Repeat
the same trick above until we have
<span class="math notranslate nohighlight">\(\sum_{x_{1},\ldots,x_{n}}^{}{\mathbb{P}\left( X_{1} = x_{1},\ldots,X_{n} = x_{n} \right)} = 1\)</span>,
which validates <span class="math notranslate nohighlight">\(\mathbb{P}\left( X_{1},\ldots,X_{n} \right)\)</span> is
indeed a probability distribution. We call the above DAG representation
of a factorization of joint distribution as a <strong>Directed Graph Model</strong>,
or more commonly the <strong>Bayesian Network</strong>, and we say joint distribution
<span class="math notranslate nohighlight">\(\mathbb{P}\)</span> <strong>respects</strong> <span class="math notranslate nohighlight">\(G\)</span> if <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> can be
represented by <span class="math notranslate nohighlight">\(G\)</span>. Pay attention that a <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> might
respect more than one DAGs. Every <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> at least respects
the complete DAG as a result of the chain rule, and conditional
independence makes <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> respect more DAGs; one example is
the above <em>Figure 0‑1</em>.</p>
<p><em>Theorem</em> <em>0‑1</em> Before further discussion, we want to discuss a basic
theorem regarding conditional independence. We claim two RVs <span class="math notranslate nohighlight">\(X,Y\)</span>
are conditionally independent given <span class="math notranslate nohighlight">\(Z\)</span>, i.e.</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X = x,Y = y \middle| Z = z \right)\mathbb{= P}\left( X = x \middle| Z = z \right)\mathbb{P(}Y = y|Z = z)\]</div>
<p>for any <span class="math notranslate nohighlight">\(x,y,z\)</span>, or in short
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X,Y \middle| Z \right)\mathbb{= P}\left( X \middle| Z \right)\mathbb{P(}Y|Z)\)</span>,
iff one of the following conditions holds. Note for
<span class="math notranslate nohighlight">\(\{ z\mathbb{:P}\left( Z = z \right) = 0\}\)</span> the equation
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X,Y \middle| Z \right)\mathbb{= P}\left( X \middle| Z \right)\mathbb{P(}Y|Z)\)</span>
automatically holds, so in the proof we only consider
<span class="math notranslate nohighlight">\(\mathbb{P}\left( Z \right) &gt; 0\)</span>.</p>
<ol class="arabic">
<li><p class="first"><span class="math notranslate nohighlight">\(\mathbb{P}\left( X \middle| Y,Z \right)\mathbb{= P(}X|Z)\)</span> on
<span class="math notranslate nohighlight">\(\{\left( y,z \right)\mathbb{:P}\left( Y = y,Z = z \right) &gt; 0\}\)</span>.
Note it is possible that
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X \middle| Y,Z \right) = 0\)</span> but
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X \middle| Z \right) \neq 0\)</span> on
<span class="math notranslate nohighlight">\(\{\left( y,z \right)\mathbb{:P}\left( Y = y,Z = z \right) = 0\}\)</span>.</p>
<p><em>Necessity</em>. When <span class="math notranslate nohighlight">\(\mathbb{P}\left( Y,Z \right) &gt; 0\)</span>, we have</p>
</li>
</ol>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X \middle| Y,Z \right) = \frac{\mathbb{P}\left( X,Y|Z \right)\mathbb{P(}Z)}{\mathbb{P(}Y,Z)} = \frac{\mathbb{P}\left( X \middle| Z \right)\mathbb{P}\left( Y \middle| Z \right)\mathbb{P(}Z)}{\mathbb{P(}Y,Z)} = \frac{\mathbb{P}\left( X \middle| Z \right)\mathbb{P(}Y,Z)}{\mathbb{P(}Y,Z)}\mathbb{= P(}X|Z)\]</div>
<p><em>Sufficiency</em>. When <span class="math notranslate nohighlight">\(\mathbb{P}\left( Z \right) = 0\)</span>, independence
trivially holds by
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X,Y \middle| Z \right)\mathbb{= P}\left( X \middle| Z \right)\mathbb{P}\left( Y \middle| Z \right) = 0\)</span>.
When <span class="math notranslate nohighlight">\(\mathbb{P}\left( X \middle| Y,Z \right)\mathbb{= P(}X|Z)\)</span>
given <span class="math notranslate nohighlight">\(\mathbb{P}\left( Y,Z \right) &gt; 0\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X,Y \middle| Z \right)\mathbb{P}\left( Z \right)\mathbb{= P}\left( X \middle| Y,Z \right)\mathbb{P}\left( Y,Z \right)\mathbb{= P}\left( X \middle| Z \right)\mathbb{P}\left( Y,Z \right)\mathbb{\Rightarrow P}\left( X,Y \middle| Z \right)\mathbb{= P}\left( X \middle| Z \right)\frac{\mathbb{P}\left( Y,Z \right)}{\mathbb{P}\left( Z \right)}\mathbb{= P}\left( X \middle| Z \right)\mathbb{P(}Y|Z)\]</div>
<p>Independence automatically holds for
<span class="math notranslate nohighlight">\(\{\left( y,z \right)\mathbb{:P}\left( Y = y,Z = z \right) = 0\}\)</span>,
in which case
<span class="math notranslate nohighlight">\(\mathbb{P}\left( Y \middle| Z \right)\mathbb{P}\left( Z \right) = 0\)</span>,
then <span class="math notranslate nohighlight">\(\mathbb{P}\left( Y \middle| Z \right) = 0\)</span>, implying
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X,Y \middle| Z \right)\mathbb{= P}\left( X \middle| Z \right)\mathbb{P}\left( Y \middle| Z \right) = 0\)</span>.</p>
<ol class="arabic" start="2">
<li><p class="first"><span class="math notranslate nohighlight">\(\mathbb{P}\left( X \middle| Y,Z \right) = f(X,Z)\)</span> for some
function <span class="math notranslate nohighlight">\(f\)</span> dependent only on <span class="math notranslate nohighlight">\(X,Z\)</span> (or not dependent on
<span class="math notranslate nohighlight">\(Y\)</span>).</p>
<p><em>Necessity</em>. When <span class="math notranslate nohighlight">\(X\bot Y\)</span>, then the following holds,</p>
</li>
</ol>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X,Y,Z \right)\mathbb{= P}\left( X,Y \middle| Z \right)\mathbb{P}\left( Z \right)\mathbb{= P}\left( X \middle| Z \right)\mathbb{P}\left( Y \middle| Z \right)\mathbb{P}\left( Z \right)\mathbb{\Rightarrow P}\left( X,Z \right)\mathbb{P}\left( Y,Z \right)\mathbb{= P}\left( X,Y,Z \right)\mathbb{P}\left( Z \right)\mathbb{= P}\left( X|Y,Z \right)\mathbb{P}\left( Y,Z \right)\mathbb{P}\left( Z \right)\mathbb{\Rightarrow P}\left( X,Y,Z \right)\mathbb{= P}\left( X|Y,Z \right)\mathbb{P}\left( Y,Z \right)\]</div>
<p>For <span class="math notranslate nohighlight">\(\{(y,z\mathbb{):P}\left( Y = y,Z = z \right) &gt; 0\}\)</span>, we have
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X|Y,Z \right) = \frac{\mathbb{P}\left( X,Z \right)}{\mathbb{P(}Z)\ }\)</span>,
which is a function dependent only on <span class="math notranslate nohighlight">\(X,Z\)</span>. For
<span class="math notranslate nohighlight">\(\{(y,z\mathbb{):P}\left( Y = y,Z = z \right) = 0\}\)</span>, we have
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X \middle| Y = y,Z = z \right) = 0\)</span>, which is a
constant not dependent on <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p><em>Sufficiency</em>. By 1), we can instead show
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X \middle| Y,Z \right) = f\left( X,Z \right)\)</span>
implies
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X \middle| Z \right) = f\left( X,Z \right)\mathbb{= P}\left( X \middle| Y,Z \right)\)</span>
for any <span class="math notranslate nohighlight">\(f\)</span> on
<span class="math notranslate nohighlight">\(\{(y,z\mathbb{):P}\left( Y = y,Z = z \right) &gt; 0\}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X,Y,Z \right) = \mathbb{P}\left( X \middle| Y,Z \right)\mathbb{P}\left( Y,Z \right)\mathbb{= P}\left( Y,Z \right)f\left( X,Z \right)\mathbb{\Rightarrow P}\left( X,Z \right) = \sum_{y}^{}{\mathbb{P}\left( Y = y,Z \right)f\left( X,Z \right)} = f\left( X,Z \right)\sum_{y}^{}{\mathbb{P}\left( Y = y,Z \right)} = f\left( X,Z \right)\mathbb{P}\left( Z \right) \Rightarrow f\left( X,Z \right) = \frac{\mathbb{P}\left( X,Z \right)}{\mathbb{P}\left( Z \right)}\mathbb{= P(}X|Z)\]</div>
<ol class="arabic" start="3">
<li><p class="first"><span class="math notranslate nohighlight">\(\mathbb{P}\left( X,Y \middle| Z \right) = f\left( X,Z \right)g\left( Y,Z \right)\)</span>
for some function <span class="math notranslate nohighlight">\(f,g\)</span> dependent on <span class="math notranslate nohighlight">\(X,Z\)</span> and
<span class="math notranslate nohighlight">\(Y,Z\)</span> respectively.</p>
<p><em>Necessity</em> is trivial. When <span class="math notranslate nohighlight">\(X\bot Y\)</span>,
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X,Y \middle| Z \right)\mathbb{= P}\left( X \middle| Z \right)\mathbb{P(}Y|Z)\)</span>,
which are functions dependent on <span class="math notranslate nohighlight">\(X,Z\)</span> and <span class="math notranslate nohighlight">\(Y,Z\)</span>
respectively.</p>
<p><em>Sufficiency.</em> We have</p>
</li>
</ol>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X,Y \middle| Z \right) = f\left( X,Z \right)g\left( Y,Z \right)\mathbb{\Rightarrow P}\left( X,Y,Z \right)\mathbb{= P}\left( X,Y \middle| Z \right)\mathbb{P(}Z) = f\left( X,Z \right)g\left( Y,Z \right)\mathbb{P(}Z)\]</div>
<p>Then check the following,</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X,Z \right) = \sum_{y}^{}{\mathbb{P}\left( X,Y = y,Z \right)} = \sum_{y}^{}{f\left( X,Z \right)g\left( Y = y,Z \right)\mathbb{P(}Z)} = f\left( X,Z \right)\mathbb{P}\left( Z \right)\left( \sum_{y}^{}{g\left( Y = y,Z \right)} \right)\mathbb{\Rightarrow P}\left( Z \right)\mathbb{= P}\left( Z \right)\left( \sum_{x}^{}{f\left( X = x,Z \right)} \right)\left( \sum_{y}^{}{g\left( Y = y,Z \right)} \right) \Rightarrow \left( \sum_{x}^{}{f\left( X = x,Z \right)} \right)\left( \sum_{y}^{}{g\left( Y = y,Z \right)} \right) = 1\]</div>
<p>The above implies independence
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X \middle| Z \right)\mathbb{P}\left( Y \middle| Z \right)\mathbb{= P}\left( X,Y \middle| Z \right)\)</span>,</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X \middle| Z \right)\mathbb{P}\left( Y \middle| Z \right) = \frac{\mathbb{P}\left( X,Z \right)\mathbb{P}\left( Y,Z \right)}{\mathbb{P}^{2}\left( Z \right)} = \frac{\sum_{y}^{}{\mathbb{P}\left( X,Y = y,Z \right)}\sum_{x}^{}{\mathbb{P}\left( X = x,Y,Z \right)}}{\mathbb{P}^{2}\left( Z \right)} = \frac{\mathbb{P}^{2}\left( Z \right)\left( \sum_{x}^{}{f\left( X = x,Z \right)g\left( Y,Z \right)} \right)\left( \sum_{y}^{}{f\left( X,Z \right)g\left( Y = y,Z \right)} \right)}{\mathbb{P}^{2}\left( Z \right)} = f\left( X,Z \right)g\left( Y,Z \right)\left( \sum_{x}^{}{f\left( X = x,Z \right)} \right)\left( \sum_{y}^{}{g\left( Y = y,Z \right)} \right) = f\left( X,Z \right)g\left( Y,Z \right)\mathbb{= P}\left( X,Y \middle| Z \right)\]</div>
<ol class="arabic simple" start="4">
<li><span class="math notranslate nohighlight">\(\mathbb{P(}X,Y,Z) = f(X,Z)g(Y,Z)\)</span> for some function
<span class="math notranslate nohighlight">\(f,g\)</span> dependent on <span class="math notranslate nohighlight">\(X,Z\)</span> and <span class="math notranslate nohighlight">\(Y,Z\)</span> respectivelys.</li>
</ol>
<blockquote>
<div><p><em>Necessity</em> is trivial. When <span class="math notranslate nohighlight">\(X\bot Y\)</span>,
<span class="math notranslate nohighlight">\(\mathbb{P}(X,Y,Z\mathbb{) = P}\left( X \middle| Z \right)\mathbb{P}\left( Y \middle| Z \right)\mathbb{P(}Z)\)</span>,
where we can let
<span class="math notranslate nohighlight">\(f\left( X,Z \right)\mathbb{= P}\left( X \middle| Z \right),g\left( Y,Z \right)\mathbb{= P}\left( Y \middle| Z \right)\mathbb{P}\left( Z \right)\)</span>.</p>
<p><em>Sufficiency.</em> We have</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X,Y,Z \right) = f\left( X,Z \right)g\left( Y,Z \right)\mathbb{\Rightarrow P}\left( X,Y \middle| Z \right) = \frac{\mathbb{P}\left( X,Y,Z \right)}{\mathbb{P(}Z)} = \frac{f\left( X,Z \right)}{\mathbb{P(}Z)} \times g\left( Y,Z \right)\]</div>
<p>By 3) it is clear that the conditional independence holds.</p>
<p>Define the <strong>ancestral set</strong> of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> in a DAG graph as
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> union all its ancestors, denoted as
<span class="math notranslate nohighlight">\(\mathcal{a(X)}\)</span>. For an example shown below, in the following
graph,
<span class="math notranslate nohighlight">\(\mathcal{a}\left( \left\{ G,I \right\} \right) = \{ J,L,G,I,K,M\}\)</span>.
Say <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is self-ancestral if
<span class="math notranslate nohighlight">\(\mathcal{a}\left( \mathcal{X} \right)\mathcal{= X}\)</span>. Define a
node with no outbound edges as a <strong>leaf</strong>.</p>
<blockquote>
<div><p><a class="reference internal" href="media/image17.emf"><img alt="image21" src="media/image17.emf" style="width: 4.74068in; height: 2.21523in;" /></a></p>
<p><em>Figure</em> <em>0‑2 Illustration of a Bayesian Network and ancestral set</em>
<span class="math notranslate nohighlight">\(\mathcal{a(\{}G,I\})\)</span><em>.</em></p>
</div></blockquote>
<ul class="simple">
<li><em>Lemma</em> <em>0‑1</em> A set <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is self-ancestral iff
<span class="math notranslate nohighlight">\(\mathcal{p}\left( W \right)\mathcal{\subseteq X}\)</span> for any
<span class="math notranslate nohighlight">\(W \subseteq X\)</span>. <em>Necessity</em> is by definition of self-ancestral
set. <em>Sufficiency</em>. If <span class="math notranslate nohighlight">\(W\)</span> is an ancestor of <span class="math notranslate nohighlight">\(W\)</span>, then
there must be a
<span class="math notranslate nohighlight">\(X \rightarrow W_{k} \rightarrow \ldots \rightarrow W_{1} \rightarrow W\)</span>
path. Inductively
<span class="math notranslate nohighlight">\(W_{1}\mathcal{\in p}\left( W \right)\mathcal{\subseteq X,\ldots,}W_{k}\mathcal{\in p}\left( W_{k - 1} \right)\mathcal{\subseteq X,}X \in \mathcal{p}\left( W_{k} \right)\mathcal{\subseteq X}\)</span>.</div></div></div></li><li><em>Lemma</em> <em>0‑2</em> Let <span class="math notranslate nohighlight">\(Y\)</span> be a leaf node. Let
<span class="math notranslate nohighlight">\(\mathcal{X = N\backslash\{}Y\}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> be all
RVs in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, then
<span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{N}}\mathcal{(X)}\mathbf{=}\mathbb{P}_{\mathcal{X}}\mathcal{(X)}\)</span>,
where <span class="math notranslate nohighlight">\(\mathbb{P}_{\mathcal{N}}\)</span> is used to denote a
distribution w.r.t. the Bayesian network <span class="math notranslate nohighlight">\(\mathcal{N}\)</span>, and we
overload <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> to also represent a sub network induced
by node set <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Check that</li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbb{P}_{\mathcal{N}}\mathcal{(X)}\mathbf{=}\sum_{y}^{}{\mathbb{P}_{\mathcal{N}}\mathcal{(X,}Y = y)}\mathbf{=}\sum_{y}^{}{\prod_{X\mathbf{\in}\mathcal{X}}^{}{\mathbb{P}_{\mathcal{N}}\left( X \middle| \mathcal{p}\left( X \right) \right)\mathbb{P}_{\mathcal{N}}(Y = y|\mathcal{p(}Y))}}\mathbf{=}\prod_{X\mathbf{\in}\mathcal{X}}^{}{\mathbb{P}_{\mathcal{N}}\left( X \middle| \mathcal{p}\left( X \right) \right)}\sum_{y}^{}{\mathbb{P}_{\mathcal{N}}(Y = y|\mathcal{p(}Y))}\mathbf{=}\prod_{X\mathbf{\in}\mathcal{X}}^{}{\mathbb{P}_{\mathcal{N}}\left( X \middle| \mathcal{p}\left( X \right) \right)}\mathbf{=}\mathbb{P}_{\mathcal{X}}(X)\]
<ul class="simple">
<li><em>Lemma</em> <em>0‑3</em> Suppose <span class="math notranslate nohighlight">\(\mathcal{X \subseteq N}\)</span> is
self-ancestral, then the marginal probability</li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbb{P}_{\mathcal{N}}\left( \mathcal{X} \right) = \prod_{W \in \mathcal{X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)} = \mathbb{P}_{\mathcal{X}}\mathcal{(X)}\]
<p>We use two methods to prove this lemma. First by <em>Lemma 0‑1</em>, Check that</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}_{\mathcal{N}}\left( \mathcal{X} \right) = \sum_{W \in \mathcal{N\backslash X}}^{}{\mathbb{P}\left( \mathcal{N} \right)} = \sum_{W \in \mathcal{N\backslash X}}^{}{\prod_{W \in \mathcal{N}}^{}{\mathbb{P(}W|\mathcal{p(}W))}} = \sum_{W \in \mathcal{N\backslash X}}^{}{\left( \prod_{W \in \mathcal{X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)} \right)\left( \prod_{W \in \mathcal{N\backslash X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)} \right)} = \left( \prod_{W \in \mathcal{X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)} \right)\sum_{W \in \mathcal{N\backslash X}}^{}\left( \prod_{W \in \mathcal{N\backslash X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)} \right) = \prod_{W \in \mathcal{X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)}\]
<p>where
<span class="math notranslate nohighlight">\(\sum_{W \in \mathcal{N\backslash X}}^{}\left( \prod_{W \in \mathcal{N\backslash X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)} \right) = \prod_{W \in \mathcal{N\backslash X}}^{}{\sum_{W \in \mathcal{N\backslash X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)}} = 1\)</span>
for the same reason as <a class="reference external" href="#b10">above</a>. It is important that
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> has to be self-ancestral, otherwise there is no way
to guarantee that a RV in <span class="math notranslate nohighlight">\(\mathcal{N\backslash X}\)</span> is not a
parent of RV in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, and then there would be</p>
<div class="math notranslate nohighlight">
\[\sum_{W \in \mathcal{N\backslash X}}^{}{\left( \prod_{W \in \mathcal{X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)} \right)\left( \prod_{W \in \mathcal{N\backslash X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)} \right)} \neq \left( \prod_{W \in \mathcal{X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)} \right)\sum_{W \in \mathcal{N\backslash X}}^{}\left( \prod_{W \in \mathcal{N\backslash X}}^{}{\mathbb{P}\left( W \middle| \mathcal{p}\left( W \right) \right)} \right)\]
<p>It can also be proved by <em>Lemma 0‑2</em>. When
<span class="math notranslate nohighlight">\(\mathcal{N\backslash X}\)</span> is not empty, we can always find a leaf
in it (because of the finite many nodes). Removing this leave does not
change the probability by <em>Lemma 0‑2</em>. Repeat removal of leaf until
<span class="math notranslate nohighlight">\(\mathcal{N\backslash X}\)</span> is empty.</p>
<ul class="simple">
<li>In a Bayesian network, given a set of RV <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, two
other RVs <span class="math notranslate nohighlight">\(X,Y\)</span> are said to be directional-separated, or
<strong>d-separated</strong> w.r.t. <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, or <strong>d-blocked</strong> w.r.t.
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> iff one of the following is true for every
undirected <span class="math notranslate nohighlight">\(X\sim Y\)</span> simple path. An undirected simple path
does not have cycles and disregards the edge directions. For example,
in <em>Figure 0‑2</em> <span class="math notranslate nohighlight">\(F \rightarrow C \leftarrow E\)</span> is considered as
an undirected path. For another example,
<span class="math notranslate nohighlight">\(K \rightarrow H \rightarrow D \leftarrow B \leftarrow E\)</span> is an
undirected path. However,
<span class="math notranslate nohighlight">\(L \rightarrow J \rightarrow G \leftarrow J\)</span> is not an
undirected simple path because it has cycle. We denote an undirected
simple path from node <span class="math notranslate nohighlight">\(X\)</span> to <span class="math notranslate nohighlight">\(Y\)</span> as an <span class="math notranslate nohighlight">\(X\sim Y\)</span>
path.</li>
</ul>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><ol class="first last arabic simple">
<li></li>
</ol>
</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td><ol class="first last arabic simple" start="2">
<li></li>
</ol>
</td>
<td><ol class="first last arabic simple" start="3">
<li></li>
</ol>
</td>
</tr>
</tbody>
</table>
<ol class="arabic simple">
<li>The <span class="math notranslate nohighlight">\(X\sim Y\)</span> path is either a
<span class="math notranslate nohighlight">\(X\sim A \rightarrow \mathcal{Z \rightarrow}B\sim Y\)</span> path or a
<span class="math notranslate nohighlight">\(X\sim A \leftarrow \mathcal{Z \leftarrow}B\sim Y\)</span> path, where
it is possible that <span class="math notranslate nohighlight">\(X = A,Y = B\)</span>; we also say there is a
serial connection at <span class="math notranslate nohighlight">\(W \notin \mathcal{Z}\)</span>;</div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></li><li>The <span class="math notranslate nohighlight">\(X\sim Y\)</span> path is a
<span class="math notranslate nohighlight">\(X\sim A \leftarrow \mathcal{Z \rightarrow}B\sim Y\)</span> path, where
it is possible that <span class="math notranslate nohighlight">\(X = A,Y = B\)</span>; we also say there exists a
diverging connection at <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>;</div></li><li>The <span class="math notranslate nohighlight">\(X\sim Y\)</span> path has a fourth RV <span class="math notranslate nohighlight">\(W \notin \mathcal{Z}\)</span>
in the path s.t. <span class="math notranslate nohighlight">\(W\)</span> and its descendants (those nodes reachable
from <span class="math notranslate nohighlight">\(W\)</span> by directed paths) are not in <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, and
the path has the form
<span class="math notranslate nohighlight">\(X\sim A \rightarrow \mathcal{Z \leftarrow}B\sim Y\)</span>; we also
say there exists a converging connection at <span class="math notranslate nohighlight">\(W\)</span>. For this
condition, it is possible that <span class="math notranslate nohighlight">\(\mathcal{Z = \varnothing}\)</span>.
This condition is the reason that we say “<span class="math notranslate nohighlight">\(X,Y\)</span> d-separated
w.r.t. <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>” rather than “<span class="math notranslate nohighlight">\(X,Y\)</span> d-separated
by <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>”, because <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> might not be
in the path. For the previous two conditions, we might say “blocked
by”.</li>
</ol>
<blockquote>
<div>We say two sets of RV <span class="math notranslate nohighlight">\(\mathcal{X,Y}\)</span> are d-separated by a
third set <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> if <span class="math notranslate nohighlight">\(X,Y\)</span> are d-separated by
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> for every
<span class="math notranslate nohighlight">\(\left( X,Y \right)\mathcal{\in X \times Y}\)</span>. Taking <em>Figure
0‑2</em> for example,</blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">cal{X}</p>
</th>
<th class="head"><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">cal{Y}</p>
</th>
<th class="head"><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">cal{Z}</p>
</th>
<th class="head">d-separated?</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><div class="first last math notranslate nohighlight">
\[C\]
</td>
<td><div class="first last math notranslate nohighlight">
\[C\]
</td>
<td>Any</td>
<td>No. A RV is
always not
d-separated
from itself,
regardless of
<span class="math notranslate nohighlight">\(\mathcal
{Z}\)</span>.</td>
</tr>
<tr class="row-odd"><td><div class="first last math notranslate nohighlight">
\[C\]</div>
</td>
<td><div class="first last math notranslate nohighlight">
\[E\]</div>
</td>
<td>Any</td>
<td>No. Adjacent
RVs are always
not
d-separated,
regardless of
<span class="math notranslate nohighlight">\(\mathcal
{Z}\)</span>.</td>
</tr>
<tr class="row-even"><td><div class="first last math notranslate nohighlight">
\[L\]</div>
</td>
<td><div class="first last math notranslate nohighlight">
\[E\]</div>
</td>
<td><div class="first math notranslate nohighlight">
\[\{ F,\]</div>
<p class="last">C}</p>
</td>
<td>No. Converging
connection at
:math:<a href="#id43"><span class="problematic" id="id44">`</span></a>{ F,C}
`
in the only
path.</td>
</tr>
<tr class="row-odd"><td><div class="first last math notranslate nohighlight">
\[I\]</div>
</td>
<td><div class="first last math notranslate nohighlight">
\[D\]</div>
</td>
<td><div class="first math notranslate nohighlight">
\[\{ M,\]</div>
<p class="last">K}</p>
</td>
<td>No.
<span class="math notranslate nohighlight">\(I \right
arrow E \righta
rrow B \rightar
row E\)</span>
path is not
blocked by
:math:<a href="#id45"><span class="problematic" id="id46">`</span></a>{ M,K}
`</td>
</tr>
<tr class="row-even"><td><div class="first last math notranslate nohighlight">
\[F\]</div>
</td>
<td><div class="first last math notranslate nohighlight">
\[E\]</div>
</td>
<td><div class="first last math notranslate nohighlight">
\[B\]</div>
</td>
<td>Yes. Only path
has converging
connection at a
fourth node
<span class="math notranslate nohighlight">\(C\)</span>.</td>
</tr>
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\{ L,\]</div>
<p class="last">G}</p>
</td>
<td><div class="first math notranslate nohighlight">
\[\{ A,\]</div>
<p class="last">M}</p>
</td>
<td><div class="first last math notranslate nohighlight">
\[E\]</div>
</td>
<td>Yes. All
<span class="math notranslate nohighlight">\(\{ A,M\}
\sim I \rightar
row E \rightarr
ow C\sim\{ L,G\
}\)</span>
paths are
blocked by a
serial
connection at
<span class="math notranslate nohighlight">\(E\)</span>; all
<span class="math notranslate nohighlight">\(\{ A,M\}
\sim B \leftarr
ow E \rightarro
w C\sim\{ L,B\}
`
paths blocked
by a diverging
connection at
:math:`E\)</span>.</td>
</tr>
<tr class="row-even"><td><div class="first last math notranslate nohighlight">
\[I\]</div>
</td>
<td><div class="first math notranslate nohighlight">
\[\{ F,\]</div>
<p class="last">A}</p>
</td>
<td><div class="first math notranslate nohighlight">
\[\{ K,\]</div>
<p class="last">B}</p>
</td>
<td><p class="first">Yes. The only
<span class="math notranslate nohighlight">\(I\sim F\)</span>
path has a
converging
connection at
<span class="math notranslate nohighlight">\(C\)</span> and
:math:<a href="#id47"><span class="problematic" id="id48">`</span></a>C notin</p>
<blockquote>
<div>{ K,B}`;</div></blockquote>
<p class="last">the
<span class="math notranslate nohighlight">\(I\sim B\
sim A\)</span>
path is serial
at <span class="math notranslate nohighlight">\(B\)</span>;
the
<span class="math notranslate nohighlight">\(I\sim K\
sim A\)</span>
path has a
diverging
connection at
<span class="math notranslate nohighlight">\(K\)</span>.</p>
</td>
</tr>
</tbody>
</table>
<p><em>Lemma</em> <em>0‑4</em> Let <span class="math notranslate nohighlight">\(\mathcal{X,Y,Z}\)</span> be a partition of
<span class="math notranslate nohighlight">\(\mathcal{N}\)</span>, if <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span> d-separates
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, then
<span class="math notranslate nohighlight">\(\mathcal{X\bot Y}\)</span>. Let
<span class="math notranslate nohighlight">\(\mathcal{Z}_{1} = \{ z \in \mathcal{Z,p}\left( z \right)\mathcal{\subseteq X\}}\)</span>
and <span class="math notranslate nohighlight">\(\mathcal{Z}_{2}\mathcal{= Z\backslash}\mathcal{Z}_{1}\)</span>. Now</p>
<div class="math notranslate nohighlight">
\[\forall X \in \mathcal{X\bigcup}\mathcal{Z}_{1}\mathcal{,p}\left( X \right)\mathcal{\subseteq X\bigcup}\mathcal{Z}_{1}\]</div>
<div class="math notranslate nohighlight">
\[\forall Y \in \mathcal{Y\bigcup}\mathcal{Z}_{2}\mathcal{,p}\left( Y \right)\mathcal{\subseteq Y\bigcup}\mathcal{Z}_{2}\]</div>
<p>Consider</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{X,Y,Z} \right) = \prod_{W \in \mathcal{N}}^{}{\mathbb{P(}W|\mathcal{p(}W))} = \prod_{W \in \mathcal{X\bigcup}\mathcal{Z}_{1}}^{}{\mathbb{P(}W|\mathcal{p(}W))}\prod_{W \in \mathcal{Y\bigcup}\mathcal{Z}_{2}}^{}{\mathbb{P(}W|\mathcal{p(}W))}\]</div>
<p>where
<span class="math notranslate nohighlight">\(\prod_{W \in \mathcal{X\bigcup}\mathcal{Z}_{1}}^{}{\mathbb{P(}W|\mathcal{p(}W))}\)</span>
is a function dependent on <span class="math notranslate nohighlight">\(\mathcal{X,Z}\)</span>, and
<span class="math notranslate nohighlight">\(\prod_{W \in \mathcal{Y\bigcup}\mathcal{Z}_{2}}^{}{\mathbb{P(}W|\mathcal{p(}W))}\)</span>
is a function dependent on <span class="math notranslate nohighlight">\(\mathcal{Y,Z}\)</span>, thus
<span class="math notranslate nohighlight">\(\mathcal{X\bot Y}\)</span> (see <a class="reference external" href="#b8">remark</a> below for proof).</p>
<blockquote>
<div><em>Theorem</em> <em>0‑2</em> D-separation is the tool to recognize independence in
a Bayesian network. We now come to the most important theorem for
Bayesian network, the <strong>D-Separation Theorem</strong>, or the <strong>Global
Markov Property for Bayesian Network</strong>. Given two sets of RVs
<span class="math notranslate nohighlight">\(\mathcal{X,Y}\)</span> s.t. any two of <span class="math notranslate nohighlight">\(\mathcal{X,Y,Z}\)</span> have no
intersection, if every pair of
<span class="math notranslate nohighlight">\(X \in \mathcal{X,}Y \in \mathcal{Y}\)</span> are d-separated by
<span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, then <span class="math notranslate nohighlight">\(\mathcal{X,Y}\)</span> are independent
conditioned on <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>. For example, based on above
table, we already see
<span class="math notranslate nohighlight">\(F\bot E\left| B,\left\{ L,G \right\}\bot\left\{ A,M \right\} \right|E,I\bot\{ F,A\}|\{ K,B\}\)</span>.
Note this theorem does not imply anything on <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> that are not d-separated. <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> could be conditional independent or
non-conditional independent when they are not d-separated.</div></blockquote>
<p>Let <span class="math notranslate nohighlight">\(\mathcal{X}^{'}\)</span> be the set of all nodes that are not
d-separated from <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> by <span class="math notranslate nohighlight">\(\mathcal{Z}\)</span>, and note
<span class="math notranslate nohighlight">\(\mathcal{X \subseteq}\mathcal{X}^{'}\)</span>. Let
<span class="math notranslate nohighlight">\(\mathcal{Y' = N\backslash}(\mathcal{X}^{'}\mathcal{\bigcup Z) \Rightarrow Y \subseteq Y'}\)</span>,
then by previous lemma we have
<span class="math notranslate nohighlight">\(\mathcal{X}^{'}\bot\mathcal{Y}^{'}\mathcal{|Z}\)</span>. By <em>Theorem 0‑1</em>
there must be functions
<span class="math notranslate nohighlight">\(f\left( \mathcal{X}^{'}\mathcal{,Z} \right),g(\mathcal{Z}^{'}\mathcal{,Y)}\)</span>
s.t.</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{X}^{'},\mathcal{Y}^{'}\mathcal{,Z} \right) = f\left( \mathcal{X}^{'}\mathcal{,Z} \right)g(\mathcal{Z,}\mathcal{Y}^{'})\]</div>
<p>Let
<span class="math notranslate nohighlight">\(\mathcal{X}^{''} = \mathcal{X}^{'}\mathcal{\backslash X,}\mathcal{Y}^{''}\mathcal{= Y'\backslash Y}\)</span>,
we have</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{X',Y',Z} \right) = f\left( \mathcal{X}^{''}\mathcal{,X,Z} \right)g\left( \mathcal{Z,}\mathcal{Y}^{''}\mathcal{,Y} \right)\]</div>
<p>Then</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{X,Y,Z} \right) = \sum_{\mathcal{X}^{''},\mathcal{Y}^{''}}^{}{\mathbb{P}\left( \mathcal{X}^{'},\mathcal{Y}^{'}\mathcal{,Z} \right)} = \sum_{\mathcal{X}^{''},\mathcal{Y}^{''}}^{}{f\left( \mathcal{X}^{''}\mathcal{,X,Z} \right)g\left( \mathcal{Z,}\mathcal{Y}^{''}\mathcal{,Y} \right)} = \left( \sum_{\mathcal{X}^{''}}^{}{f\left( \mathcal{X}^{''}\mathcal{,X,Z} \right)} \right)\left( \sum_{\mathcal{Y}^{''}}^{}{g\left( \mathcal{Z,}\mathcal{Y}^{''}\mathcal{,Y} \right)} \right)\]</div>
<p>We see
<span class="math notranslate nohighlight">\(\sum_{\mathcal{X}^{''}}^{}{f\left( \mathcal{X}^{''}\mathcal{,X,Z} \right)}\)</span>
is a function not dependent on
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>,<span class="math notranslate nohighlight">\(\sum_{\mathcal{Y}^{''}}^{}{g\left( \mathcal{Z,}\mathcal{Y}^{''}\mathcal{,Y} \right)}\)</span>
is function not dependent on <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, again by <em>Theorem 0‑1</em>
we have <span class="math notranslate nohighlight">\(\mathcal{X\bot Y|Z}\)</span>.</p>
<p>However, please note the converse might not be true. Conditionally
independent RVs might not be d-separated, due to that <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>
might respect multiple graphs. A simple example is <em>Figure 0‑1</em> <em>(a)</em>.
Any <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> of four random variables respects this graph,
representation of chain rule, even when <span class="math notranslate nohighlight">\(X_{2}\)</span> and <span class="math notranslate nohighlight">\(X_{3}\)</span>
are independent given <span class="math notranslate nohighlight">\(X_{1}\)</span>, however, <span class="math notranslate nohighlight">\(X_{3}\)</span> and
<span class="math notranslate nohighlight">\(X_{3}\)</span> are clearly not d-separated in <em>Figure 0‑1</em> <em>(a)</em> w.r.t.
<span class="math notranslate nohighlight">\(X_{1}\)</span>.</p>
<ul>
<li><p class="first">In a Bayesian network <span class="math notranslate nohighlight">\(\mathcal{N}\)</span>, the <strong>Markov blanket</strong> of
a node <span class="math notranslate nohighlight">\(X\)</span>, denoted by <span class="math notranslate nohighlight">\(\mathcal{b(}X)\)</span>, is the set of
RVs consisting of the parents of <span class="math notranslate nohighlight">\(X\)</span>, the children of
<span class="math notranslate nohighlight">\(X\)</span>, and the parents of children of <span class="math notranslate nohighlight">\(X\)</span>. The following
gives an example, the
<span class="math notranslate nohighlight">\(\mathcal{b}\left( I \right) = \left\{ E \right\}\bigcup\{ L,K\}\bigcup\{ J,H\}\)</span>,
where <span class="math notranslate nohighlight">\(\left\{ E \right\}\)</span> is the parent, <span class="math notranslate nohighlight">\(\{ L,K\}\)</span> are
the children, and <span class="math notranslate nohighlight">\(\{ J,H\}\)</span> are the parents of children. For a
set of RVs <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, define its Markov blanket as
<span class="math notranslate nohighlight">\(\mathcal{b}\left( \mathcal{X} \right) = \bigcup_{X \in \mathcal{X}}^{}{\mathcal{b(}X)}\)</span>.</p>
<p><a class="reference internal" href="media/image22.emf"><img alt="image22" src="media/image22.emf" style="width: 5.02765in; height: 2.38112in;" /></a></p>
<p><em>Figure</em> <em>0‑3 Illustration of a Markov blanket</em></p>
<p><em>Lemma</em> <em>0‑5</em> <span class="math notranslate nohighlight">\(\mathcal{b(X)}\)</span> d-separates <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>
from all other nodes. In order to reach a RV in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>,
a path can, as illustrated by <em>Figure 0‑4</em>,</p>
</li>
</ul>
<ol class="arabic">
<li><p class="first">go through a parent <span class="math notranslate nohighlight">\(P\)</span> of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, which is either
serially or divergently blocked by <span class="math notranslate nohighlight">\(P\)</span>;</p>
</div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></li><li><p class="first">go through a child <span class="math notranslate nohighlight">\(C\)</span> of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>,</p>
<ol class="loweralpha">
<li><p class="first">go through an outbound edge of <span class="math notranslate nohighlight">\(C\)</span>; such path is blocked by
the serial connection at <span class="math notranslate nohighlight">\(C\)</span>.</p>
</li>
<li><p class="first">first go through a parent <span class="math notranslate nohighlight">\(Q\)</span> of <span class="math notranslate nohighlight">\(C\)</span>, then go through
<span class="math notranslate nohighlight">\(C\)</span>; such path is either serially blocked by <span class="math notranslate nohighlight">\(Q\)</span>, or
divergently blocked by <span class="math notranslate nohighlight">\(Q\)</span>.</p>
<p><em>Figure</em> <em>0‑4 Markov blanket</em> <span class="math notranslate nohighlight">\(\mathcal{b(X)}\)</span> <em>d-separates</em>
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> <em>from other nodes</em></p>
<p><em>Theorem</em> <em>0‑3</em> A set of RVs <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is conditionally
independent of all other RVs given its Markov blanket. This
immediately follows from above lemma by d-separation theorem.</p>
</li>
</ol>
</li>
</ol>
<ul class="simple">
<li><em>Theorem</em> <em>0‑4</em> L<strong>ocal Markov Property for Bayesian Network</strong>: a
RV <span class="math notranslate nohighlight">\(X\)</span> is independent from all non-descendants given its
parents. The proof is similar to <em>Lemma 0‑5</em>. In order to reach
<span class="math notranslate nohighlight">\(X\)</span>, a path can, as illustrated by <em>Figure 0‑5</em> <em>(a)</em>,</li>
</ul>
<ol class="arabic simple">
<li>go through a parent <span class="math notranslate nohighlight">\(P\)</span> of <span class="math notranslate nohighlight">\(X\)</span>, which is either serially
or divergently blocked by <span class="math notranslate nohighlight">\(P\)</span>;</li>
<li>go through a node <span class="math notranslate nohighlight">\(S\)</span> that has an outbound edge to some
descendant, say <span class="math notranslate nohighlight">\(D\)</span>, of <span class="math notranslate nohighlight">\(X\)</span>, which has a convergent
connection at <span class="math notranslate nohighlight">\(D\)</span> (<span class="math notranslate nohighlight">\(D\)</span> cannot have any descendants in
<span class="math notranslate nohighlight">\(\mathcal{p(}X)\)</span>, otherwise there would be a cycle in the
graph).</li>
</ol>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><ol class="first last loweralpha simple">
<li></li>
</ol>
</td>
<td><ol class="first last loweralpha simple" start="2">
<li></li>
</ol>
</td>
</tr>
</tbody>
</table>
<p><em>Figure</em> <em>0‑5</em> <span class="math notranslate nohighlight">\(\mathcal{p(}X)\)</span> <em>d-separates</em> <span class="math notranslate nohighlight">\(X\)</span> <em>from
non-descendants</em></p>
<p>Note this theorem does not hold for a set <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, because
we cannot guarantee there is a cycle when <span class="math notranslate nohighlight">\(D\)</span> has a descendant in
<span class="math notranslate nohighlight">\(\mathcal{p(X)}\)</span>. As illustrated by <em>Figure 0‑5</em> <em>(b)</em>, <span class="math notranslate nohighlight">\(S\)</span>
is not independent from <span class="math notranslate nohighlight">\(X_{1}\)</span> given
<span class="math notranslate nohighlight">\(\mathcal{p(\{}X_{1},X_{2}\})\)</span>, since the convergent connection
<span class="math notranslate nohighlight">\(D\)</span> has a descendant <span class="math notranslate nohighlight">\(X_{2}\)</span>.</p>
<ul class="simple">
<li><em>Theorem</em> <em>0‑5</em> <strong>Factorization Theorem</strong>: the following three
statements are equivalent. Since d-separation is not straightforward,
the following equivalence validates the more intuitive local Markov
property as a modeling criterion.</li>
</ul>
<ol class="arabic simple">
<li><span class="math notranslate nohighlight">\(\mathbb{P}\)</span> respects graph <span class="math notranslate nohighlight">\(G\)</span>, or <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>
factorizes according to <span class="math notranslate nohighlight">\(G\)</span>, i.e.
<span class="math notranslate nohighlight">\(\mathbb{P}\left( G \right) = \prod_{X \in G}^{}{\mathbb{P(}X|\mathcal{p(}X))}\)</span>
where we overload <span class="math notranslate nohighlight">\(G\)</span> to also represent the RVs in the graph;</li>
<li><span class="math notranslate nohighlight">\(G\)</span> satisfies d-separation (global Markov property) according
w.r.t. <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>;</li><li><span class="math notranslate nohighlight">\(G\)</span> satisfies local Markov property according w.r.t.
<span class="math notranslate nohighlight">\(\mathbb{P}\)</span>.</li>
</ol>
<blockquote>
<div><em>Theorem 0‑2</em> guarantees 1) <span class="math notranslate nohighlight">\(\Rightarrow\)</span> 2) holds, and
<em>Theorem 0‑3</em> ensures 2) <span class="math notranslate nohighlight">\(\Rightarrow\)</span> 3), we need to prove 3)
<span class="math notranslate nohighlight">\(\Rightarrow\)</span> 1). We do this by induction. For one-node graph
<span class="math notranslate nohighlight">\(G_{1}\)</span>, 3) <span class="math notranslate nohighlight">\(\Rightarrow\)</span> 1) trivially holds. Now
consider that 3) <span class="math notranslate nohighlight">\(\Rightarrow\)</span> 1) holds for a graph
<span class="math notranslate nohighlight">\(G_{n - 1}\)</span> of <span class="math notranslate nohighlight">\(n - 1\)</span> nodes, then for graph
<span class="math notranslate nohighlight">\(G_{n}\)</span> of <span class="math notranslate nohighlight">\(n\)</span> nodes, and let the additional node be
<span class="math notranslate nohighlight">\(X\)</span>, which has to be a leaf, then by 3) <span class="math notranslate nohighlight">\(X\)</span> is
independent from all other nodes given <span class="math notranslate nohighlight">\(\mathcal{p(}X)\)</span>, and so</blockquote>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbb{P}\left( G_{n} \right)\mathbb{= P}\left( X,G_{n - 1} \right)\mathbb{= P}\left( G_{n - 1} \right)\mathbb{P}\left( X \middle| G_{n - 1} \right)\mathbb{= P}\left( G_{n - 1} \right)\mathbb{P}\left( X \middle| \mathcal{p(}X) \right)\\Since we assume :math:`\mathbb{P}\left( G_{n - 1} \right)` respects
:math:`G_{n - 1}`, then clearly
:math:`\mathbb{P}\left( G_{n} \right)` factorizes according to
:math:`G_{n}`.\end{aligned}\end{align} \]
<ul>
<li><p class="first">As mentioned <a class="reference external" href="#b10">above</a>, although d-separation implies
independence, independence does not necessarily imply d-separation.
Given a distribution <span class="math notranslate nohighlight">\(\mathbb{P(}V)\)</span> where <span class="math notranslate nohighlight">\(V\)</span> is a set
of RVs, if a DAG <span class="math notranslate nohighlight">\(G = (V,E)\)</span> satisfies the d-separation
theorem, then <span class="math notranslate nohighlight">\(G\)</span> is called an <strong>I-map</strong> of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>.
Clearly every Bayesian network is an I-map. On the contrary, if
independence always implies d-separation on <span class="math notranslate nohighlight">\(G\)</span>, then <span class="math notranslate nohighlight">\(G\)</span>
is a <strong>D-map</strong> of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>. <span class="math notranslate nohighlight">\(G\)</span> is a <strong>perfect map</strong>
of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> if it is both an I-map and a D-map.</p>
<p><em>Theorem</em> <em>0‑6</em> Adding an edge in an I-map results in another I-map;
deleting an edge in a D-map results in another D-map. Prove is FUTURE
WORK.</p>
</li>
</ul>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">REMARK: Pairwise (Marginal) Independence &amp; Mutual Independence</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><p class="first">It is well known that pairwise (marginal) independence does not imply
mutual independence. For example, suppose <span class="math notranslate nohighlight">\(X,Y\)</span> are two
independent tosses of coins, and <span class="math notranslate nohighlight">\(X,Y = 1\)</span> if they take head,
or <span class="math notranslate nohighlight">\(X,Y = 0\)</span> if they take tail. Let <span class="math notranslate nohighlight">\(Z\)</span> be a third RV
s.t. <span class="math notranslate nohighlight">\(Z = \left( X + Y \right)\ \text{mod}\ 2\)</span> (<span class="math notranslate nohighlight">\(Z\)</span> takes
<span class="math notranslate nohighlight">\(1\)</span> when exactly one of <span class="math notranslate nohighlight">\(X,Y\)</span> takes <span class="math notranslate nohighlight">\(1\)</span>). We see
that</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( Z = 1 \right)\mathbb{= P}\left( X = 1,Y =\]
<p>0 right)mathbb{+ P}left( X = 0,Y = 1 right) = frac{1}{2} Righta
rrow mathbb{P}left( Z = 0 right) = frac{1}{2}</p>
<p>Thus</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X = 1,Z = 1 \right)\mathbb{= P}\left( X =\]
<p>1,Y = 0 right) = frac{1}{4}mathbb{= P}left( X = 1 right)mathbb{
P(}Z = 1)</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X = 1,Z = 0 \right)\mathbb{= P}\left( X =\]
<p>1,Y = 1 right) = frac{1}{4}mathbb{= P}left( X = 1 right)mathbb{
P(}Z = 0)</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X = 0,Z = 1 \right)\mathbb{= P}\left( X =\]
<p>0,Y = 1 right) = frac{1}{4}mathbb{= P}left( X = 0 right)mathbb{
P(}Z = 1)</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X = 0,Z = 0 \right)\mathbb{= P}\left( X =\]
<p>0,Y = 0 right) = frac{1}{4}mathbb{= P}left( X = 0 right)mathbb{
P(}Z = 0)</p>
<p>which implies
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X,Z \right)\mathbb{= P}\left( X \right)\mathb
b{P(}Z)\)</span>.
It is simple to show
<span class="math notranslate nohighlight">\(\mathbb{P}\left( Y,Z \right)\mathbb{= P}\left( Y \right)\mathb
b{P(}Z)\)</span>
as well. However,</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X = 1,Y = 1,Z = 1 \right) = 0 \neq \mathbb\]
<dl class="docutils">
<dt>{P}left( X = 1 right)mathbb{P}left( Y = 1 right)mathbb{P}left(</dt>
<dd>Z = 1 right) = frac{1}{8}</dd>
</dl>
<p>Conversely, mutual independence always implies marginal independence.
Given a set of RVs <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, let
<span class="math notranslate nohighlight">\(\mathcal{Y \subseteq X}\)</span>, then</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{Y} \right) = \sum_{W \in \mathcal\]
<p>{Xbackslash Y}}^{}{mathbb{P}left( mathcal{X} right)} = sum_{W in mathcal{Xbackslash Y}}^{}{prod_{W in mathcal{X}}^{}{mathbb{P
(}W)}} = left( prod_{W in mathcal{Y}}^{}{mathbb{P}left( W righ
t)} right)left( sum_{W in mathcal{Xbackslash Y}}^{}{prod_{W i
n mathcal{Xbackslash Y}}^{}{mathbb{P}left( W right)}} right) =
left( prod_{W in mathcal{Y}}^{}{mathbb{P}left( W right)} righ
t)left( prod_{W in mathcal{Xbackslash Y}}^{}{sum_{W in mathca
l{Xbackslash Y}}^{}{mathbb{P}left( W right)}} right) = prod_{W
in mathcal{Y}}^{}{mathbb{P}left( W right)}</p>
<p><em>Theorem</em> <em>0‑7</em> We further claim that, a set of RVs
<span class="math notranslate nohighlight">\(\mathcal{N = (}X_{1},\ldots,X_{n})\)</span> are independent iff for
any <span class="math notranslate nohighlight">\(\mathcal{X \subseteq N,Y \subseteq N}\)</span>,
<span class="math notranslate nohighlight">\(\mathcal{X\bot Y}\)</span>. <em>Sufficiency</em> is simply by chain rule,</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X_{1},\ldots,X_{n} \right)\mathbb{= P}\lef\]
<p>t( X_{n} middle| X_{1},ldots,X_{n - 1} right)mathbb{ldots P}lef
t( X_{3} middle| X_{1},X_{2} right)mathbb{P}left( X_{2} middle|
X_{1} right)mathbb{P}left( X_{1} right)mathbb{= P(}X_{n}mathbb{
)ldots P(}X_{3}mathbb{)P(}X_{2}mathbb{)P}left( X_{1} right)</p>
<p class="last"><em>Necessity</em>.
<span class="math notranslate nohighlight">\(\mathbb{P}\left( \mathcal{X,Y} \right) = \prod_{W \in \mathcal
{X\bigcup Y}}^{}{\mathbb{P}\left( W \right)} = \prod_{W \in \mathcal{
X}}^{}{\mathbb{P}\left( W \right)}\prod_{W \in \mathcal{Y}}^{}{\mathb
b{P}\left( W \right)}\)</span>,
where
<span class="math notranslate nohighlight">\(\prod_{W \in \mathcal{X}}^{}{\mathbb{P}\left( W \right)}\)</span> is a
function only dependent on <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, and
<span class="math notranslate nohighlight">\(\prod_{W \in \mathcal{Y}}^{}{\mathbb{P}\left( W \right)}\)</span> is a
function only dependent on <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, thus
<span class="math notranslate nohighlight">\(\mathcal{X\bot Y}\)</span>.</p>
</td>
</tr>
</tbody>
</table>
<p>EX 1. Prove that if
<span class="math notranslate nohighlight">\(\mathcal{p}\left( \mathcal{X} \right) = \{ Y\}\)</span> is a singleton,
then <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> are mutually independent given <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>Key. For any two <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, say <span class="math notranslate nohighlight">\(X_{1},X_{2}\)</span>, either
there is no <span class="math notranslate nohighlight">\(X_{1}\sim X_{2}\)</span> a <span class="math notranslate nohighlight">\(X_{1}\sim X_{2}\)</span> path
either goes through a node in <span class="math notranslate nohighlight">\(\mathcal{p(X)}\)</span>, which is blocked,
or we claim the path must have a converging connection. If so, the
converging connection cannot have a descendant in
<span class="math notranslate nohighlight">\(\mathcal{p(}X)\)</span>, otherwise there would be a cycle.</p>
<p>An <span class="math notranslate nohighlight">\(X_{1}\sim X_{2}\)</span> path not going through <span class="math notranslate nohighlight">\(\mathcal{p(X)}\)</span>
must have the form
<span class="math notranslate nohighlight">\(X_{1} \rightarrow C_{1}\sim D \leftarrow X_{2}\)</span>. If
<span class="math notranslate nohighlight">\(C_{1} = D\)</span>, the above claim holds. If <span class="math notranslate nohighlight">\(C_{1} \neq D\)</span>, and
suppose there is no convergent connecting, then the path must have the
form
<span class="math notranslate nohighlight">\(X_{1} \rightarrow C_{1} \rightarrow C_{2}\sim D \leftarrow X_{2}\)</span>,
where <span class="math notranslate nohighlight">\(C_{2} \neq D\)</span> by assumption. Continue this construction the
path will be of infinite length. Thus a <span class="math notranslate nohighlight">\(X_{1}\sim X_{2}\)</span> path not
going through <span class="math notranslate nohighlight">\(\mathcal{p(X)}\)</span> must have a convergent connection.
As a result, <span class="math notranslate nohighlight">\(X_{1},X_{2}\)</span> are d-separated by <span class="math notranslate nohighlight">\(Y\)</span>. Let
<span class="math notranslate nohighlight">\(\mathcal{A,B}\)</span> be any two subsets of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, then
clearly <span class="math notranslate nohighlight">\(\mathcal{A,B}\)</span> are d-separated by <span class="math notranslate nohighlight">\(Y\)</span>, and hence
<span class="math notranslate nohighlight">\(\mathcal{A\bot B|}Y\)</span>. By <em>Theorem 0‑7</em>, <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> are
mutually independent given <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>EX 2. Let’s exercise on the following network about d-separation.</p>
<p><a class="reference internal" href="media/image26.emf"><img alt="image23" src="media/image26.emf" style="width: 5.2999in; height: 2.53147in;" /></a></p>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">cal{X}</p>
</th>
<th class="head"><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">cal{Y}</p>
</th>
<th class="head"><div class="first math notranslate nohighlight">
\[\math\]
<p class="last">cal{Z}</p>
</th>
<th class="head">d-separated?</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><div class="first last math notranslate nohighlight">
\[A\]
</td>
<td><div class="first last math notranslate nohighlight">
\[G\]
</td>
<td><div class="first math notranslate nohighlight">
\[\{ B,\]
<p class="last">M}</p>
</td>
<td>Yes. Any path
through
<span class="math notranslate nohighlight">\(G \right
arrow J \leftar
row F\)</span>
is blocked at
<span class="math notranslate nohighlight">\(J\)</span>; any
path through
<span class="math notranslate nohighlight">\(G \right
arrow I \righta
rrow L \leftarr
ow I\)</span>
is blocked at
<span class="math notranslate nohighlight">\(L\)</span>.</td>
</tr>
<tr class="row-odd"><td><div class="first last math notranslate nohighlight">
\[A\]
</td>
<td><div class="first last math notranslate nohighlight">
\[M\]
</td>
<td><div class="first math notranslate nohighlight">
\[\{ E,\]
<p class="last">K,L}</p>
</td>
<td>Yes. Any
<span class="math notranslate nohighlight">\(A\sim M\)</span>
path is blocked
at <span class="math notranslate nohighlight">\(K\)</span>,
since both
<span class="math notranslate nohighlight">\(I \right
arrow K \righta
rrow M\)</span>
and
<span class="math notranslate nohighlight">\(H \right
arrow K - M\)</span>
are serial.</td>
</tr>
<tr class="row-even"><td><div class="first last math notranslate nohighlight">
\[A\]
</td>
<td><div class="first math notranslate nohighlight">
\[\{ C,\]
<p class="last">F,G,J}</p>
</td>
<td><div class="first math notranslate nohighlight">
\[\varn\]
<p class="last">othing</p>
</td>
<td>Yes. Any
<span class="math notranslate nohighlight">\(A\sim\{
C,F,G,J\}\)</span>
path has to go
through a
converging
connection,
either
<span class="math notranslate nohighlight">\(E\)</span> or
<span class="math notranslate nohighlight">\(L\)</span>.</td>
</tr>
<tr class="row-odd"><td><div class="first last math notranslate nohighlight">
\[A\]
</td>
<td><div class="first math notranslate nohighlight">
\[\{ E,\]
<p class="last">I}</p>
</td>
<td><div class="first math notranslate nohighlight">
\[\{ B,\]
<p class="last">M}</p>
</td>
<td>No.
<span class="math notranslate nohighlight">\(A\sim H
\rightarrow K \
leftarrow I\)</span>
path is not
blocked at
<span class="math notranslate nohighlight">\(K\)</span> since
<span class="math notranslate nohighlight">\(M\)</span> is a
descendant of
the converging
connection
<span class="math notranslate nohighlight">\(K\)</span>.</td>
</tr>
<tr class="row-even"><td><div class="first math notranslate nohighlight">
\[\{ C,\]
<p class="last">L}</p>
</td>
<td><div class="first math notranslate nohighlight">
\[\{ B,\]
<p class="last">K}</p>
</td>
<td><div class="first math notranslate nohighlight">
\[\{ E,\]
<p class="last">I}</p>
</td>
<td>No.
<span class="math notranslate nohighlight">\(C \right
arrow E \leftar
row B\)</span>
path is not
blocked at
<span class="math notranslate nohighlight">\(E\)</span>.</td>
</tr>
</tbody>
</table>
<p>EX 3. Gives a counter example that
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X,Y \middle| Z \right)\mathbb{= P}\left( X \middle| Z \right)\mathbb{P(}Y|Z)\)</span>
does not imply
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X,Y \middle| Z,W \right)\mathbb{= P}\left( X \middle| Z,Z' \right)\mathbb{P(}Y|Z,W)\)</span>
for any <span class="math notranslate nohighlight">\(W \notin \{ X,Y\}\)</span>.</p>
<p>Key. In the network of our previous exercise, <span class="math notranslate nohighlight">\(I\bot J|C\)</span>, since
<span class="math notranslate nohighlight">\(I\sim C\sim J\ \)</span>path is divergently blocked by <span class="math notranslate nohighlight">\(C\)</span>, and
convergently blocked at <span class="math notranslate nohighlight">\(L\)</span>. However, <span class="math notranslate nohighlight">\(I,J\)</span> are clearly not
independent given <span class="math notranslate nohighlight">\(\{ C,L\}\)</span>.</p>
<p>A concrete example would be like the following, suppose
<span class="math notranslate nohighlight">\(X,Y,Z,W \in \{ 0,1\}\)</span>, and the distribution of
<span class="math notranslate nohighlight">\(\mathbb{P(}X,Y|Z)\)</span> and an illustration of the whole sample space
are given below,</p>
<table border="1" class="docutils">
<colgroup>
<col width="97%" />
<col width="3%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>&#160;</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<p>Clearly we have
<span class="math notranslate nohighlight">\(\mathbb{P}\left( X = x,Y = y \middle| Z = z \right)\mathbb{= P}\left( X = x \middle| Z = z \right)\mathbb{P}\left( Y = y \middle| Z = z \right) = 0.25,\ \forall x,y,z \in \{ 0,1\}\)</span>.
However, check that <span class="math notranslate nohighlight">\(W\)</span> gives information to <span class="math notranslate nohighlight">\(X,Y\)</span> and make
them dependent,</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X = 0,Y = 0 \middle| Z = 0,W = 0 \right) = 0.5\]
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( X = 0, \middle| Z = 0,W = 0 \right)\mathbb{= P}\left( Y = 0, \middle| Z = 0,W = 0 \right) = 0.75\]
<p>EX 4. In a Bayesian network, suppose siblings <span class="math notranslate nohighlight">\(X,Y\)</span> are
independent given
<span class="math notranslate nohighlight">\(\mathcal{p}\left( \left\{ X,Y \right\} \right)\)</span>. Would it be
possible that the independence is broken given additional RVs?</p>
<p>Key. Yes, it is possible by adding descendants. In the network of EX 2,
we see that
<span class="math notranslate nohighlight">\(F\bot E|\mathcal{p}\left( \left\{ F,E \right\} = C \right)\)</span>.
However, <span class="math notranslate nohighlight">\(F,E\)</span> are no longer independent given <span class="math notranslate nohighlight">\(\{ C,L\}\)</span>.
However, by local Markov property, adding any non-descendant will not
break independence.</p>
<p>Hidden Markov Model. <strong>Hidden Markov Model</strong> (HMM), which assumes the states are latent but yields some observable outputs, is an extension on Markov chain. Recall a Markov chain is characterized by <span class="math notranslate nohighlight">\((V,\mathbf{\mu},\mathbf{P})\)</span> where <span class="math notranslate nohighlight">\(V = \{ v_{1},\ldots,v_{m}\}\)</span> is the state space, <span class="math notranslate nohighlight">\(\mu\)</span> is the initial distribution, and <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> is the transition matrix. HMM extends this to a four tuple <span class="math notranslate nohighlight">\((V,\mathbf{\mu},\mathbf{P,}W,\mathbf{Q})\)</span> where <span class="math notranslate nohighlight">\(W = \{ w_{1},\ldots,w_{n}\}\)</span> is the set of all possible observations and <span class="math notranslate nohighlight">\(\mathbf{Q}\)</span> is an <span class="math notranslate nohighlight">\(m \times n\)</span> state-observation probability matrix, or <strong>emission distributions</strong>, where <span class="math notranslate nohighlight">\(\mathbf{Q}\left( i,j \right),i = 1,\ldots,m,j = 1,\ldots,n\)</span> is the probability of observing output <span class="math notranslate nohighlight">\(x_{j}\)</span> given state <span class="math notranslate nohighlight">\(z_{i}\)</span>. For a concrete simple example, suppose a machine can jump between two states <span class="math notranslate nohighlight">\(Z = \{ 1, - 1\}\)</span> but tend to maintain the current states, say the transition matrix is <span class="math notranslate nohighlight">\(\mathbf{P} = \begin{pmatrix}
0.9 &amp; 0.1 \\
0.1 &amp; 0.9 \\
\end{pmatrix}\)</span>. However, the current state of the machine is not directly observable, but it yields some observable output based on some Gaussian distribution, as illustrated in Figure 0‑1. Although the true states are assumed latent, they can be guessed from the output to a large extent.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><a href="#id61"><span class="problematic" id="id62">|E:\OneDrive\Pictures\figure_3.png|</span></a></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><em>Figure</em> <em>0‑1 A simple illustration of HMM. The red dots are observed
outputs. The blue dots are actual states which are assumed to be
unobservable.</em></td>
</tr>
</tbody>
</table>
<p>The Bayesian network representing the HMM is shown in <em>Figure 0‑2</em>,
where <span class="math notranslate nohighlight">\(Z = (Z_{1},\ldots,Z_{k})\)</span> are the latent states at time
<span class="math notranslate nohighlight">\(t = 1,\ldots,k\)</span>, and <span class="math notranslate nohighlight">\(X = (X_{1},\ldots,X_{k})\)</span> are the
observed outputs at each corresponding time. Here
<span class="math notranslate nohighlight">\(Z_{t} \in V,X_{t} \in W\)</span>. Also note this is not the graph
representation of the Markov chain, whose nodes are the states. The
factorization is given below, and our objective is to estimate the
probability of latent variables <span class="math notranslate nohighlight">\(Z\)</span> given observation <span class="math notranslate nohighlight">\(X\)</span>,
i.e. <span class="math notranslate nohighlight">\(\mathbb{P(}Z|X)\)</span>.</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( V \right)\mathbb{= P}\left( Z_{1} \right)\mathbb{P}\left( X_{1} \middle| Z_{1} \right)\prod_{t = 2}^{k}{\mathbb{P}\left( Z_{t} \middle| Z_{t - 1} \right)\mathbb{P(}X_{t}|Z_{t})} = \mathbf{\mu}(z_{1})\mathbf{Q}(z_{1},x_{1})\prod_{t = 2}^{k}{\mathbf{P}(z_{t - 1},z_{t})\mathbf{Q}(z_{t},x_{t})}\]
<p><em>Figure</em> <em>0‑2 Bayesian network of</em> HMM<em>, where shaded nodes are
observable RVs.</em></p>
<ul class="simple">
<li>If <span class="math notranslate nohighlight">\(\mathbf{P},\mathbf{Q},\mathbf{\mu}\)</span> are known, we can use
the so-called <strong>forward-backward algorithm</strong> to exactly compute
<span class="math notranslate nohighlight">\(\mathbb{P(}Z_{t}|X)\)</span> for every <span class="math notranslate nohighlight">\(t = 1,\ldots,k\)</span>, where
the <strong>forward part</strong> computes
<span class="math notranslate nohighlight">\(\mathbb{P(}Z_{t},X_{1},\ldots,X_{t})\)</span>, and the <strong>backward
part</strong> computes <span class="math notranslate nohighlight">\(\mathbb{P(}X_{t + 1},\ldots,X_{k}|Z_{t})\)</span>.
Denote <span class="math notranslate nohighlight">\(\left( X_{i},X_{i + 1},\ldots,X_{j} \right)\)</span> as
<span class="math notranslate nohighlight">\(X_{i:j}\)</span>, the reason for this algorithm is shown below,</li>
</ul>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbb{P}\left( Z_{t} \middle| X \right)\mathbb{\propto P}\left( Z_{t},X \right)\mathbb{= P}\left( X_{t + 1:k}|Z_{t},X_{1:t} \right)\mathbb{P}\left( Z_{t},X_{1:t} \right) = \mathbb{P}\left( X_{t + 1:k}|Z_{t} \right)\mathbb{P}\left( Z_{t},X_{1:t} \right)\\which is due to :math:`X_{1:t}\bot X_{t + 1:k}|Z_{t}` by d-separation
theorem. The forward part is a recursion shown below, which can be
solved by a simple dynamic programming algorithm.\end{aligned}\end{align} \]
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbb{P}\left( Z_{t},X_{1:t} \right) = \sum_{z_{t - 1} \in V}^{}{\mathbb{P(}Z_{t - 1},Z_{t},X_{1:t})} = \sum_{z_{t - 1} \in V}^{}{\mathbb{P}\left( X_{t} \middle| Z_{t - 1},Z_{t},X_{1:t - 1} \right)\mathbb{P}\left( Z_{t} \middle| Z_{t - 1},X_{1:t - 1} \right)\mathbb{P}\left( Z_{t - 1},X_{1:t - 1} \right)} = \sum_{z_{t - 1} \in V}^{}{\mathbb{P}\left( X_{t} \middle| Z_{t} \right)\mathbb{P}\left( Z_{t} \middle| Z_{t - 1} \right)\mathbb{P}\left( Z_{t - 1},X_{1:t - 1} \right)} = \sum_{z_{t - 1} \in V}^{}{\mathbf{Q}(z_{t},x_{t})\mathbf{P}(z_{t - 1},z_{t})\mathbb{P}\left( Z_{t - 1},X_{1:t - 1} \right)}\\where the recursion terminates at\end{aligned}\end{align} \]
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbb{P}\left( Z_{1},X_{1} \right)\mathbb{= P}\left( X_{1} \middle| Z_{1} \right)\mathbb{P}\left( Z_{1} \right) = \mathbf{Q}(z_{1},x_{1})\mathbf{\mu}(z_{1})\\The time complexity for the forward part is :math:`\Theta(km^{2})`,
since we need to compute
:math:`\mathbb{P}\left( Z_{t},X_{1:t} \right)` for each
:math:`t = 1,\ldots,k`, for each :math:`z_{t} \in V`, and sum over
each :math:`z_{t - 1} \in V`. Now we compute the backward part
:math:`\mathbb{P(}X_{t + 1:k}|Z_{t})`, and we also try to setup a
recursion,\end{aligned}\end{align} \]
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbb{P}\left( X_{t + 1:k} \middle| Z_{t} \right) = \sum_{z_{t + 1} \in V}^{}{\mathbb{P}\left( X_{t + 1:k},Z_{t + 1} \middle| Z_{t} \right)} = \sum_{z_{t + 1} \in V}^{}{\mathbb{P(}X_{t + 2:k}|X_{t + 1},Z_{t},Z_{t + 1}\mathbb{)P}\left( X_{t + 1} \middle| Z_{t},Z_{t + 1} \right)\mathbb{P}\left( Z_{t + 1} \middle| Z_{t} \right)} = \sum_{z_{t + 1} \in V}^{}{\mathbb{P(}X_{t + 2:k}|Z_{t + 1}\mathbb{)P}\left( X_{t + 1} \middle| Z_{t + 1} \right)\mathbb{P}\left( Z_{t + 1} \middle| Z_{t} \right)} = \sum_{z_{t + 1} \in V}^{}{\mathbb{P}\left( X_{t + 2:k} \middle| Z_{t + 1} \right)\mathbf{Q}(z_{t + 1}\mathbf{,}x_{t + 1}\mathbf{)P}(z_{t},z_{t + 1})}\\where the recursion terminates at\end{aligned}\end{align} \]
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbb{P}\left( X_{k} \middle| Z_{k - 1} \right) = \sum_{z_{k} \in V}^{}{\mathbb{P}\left( X_{k},Z_{k} \middle| Z_{k} \right)} = \sum_{z_{k} \in V}^{}{\mathbb{P}\left( X_{k} \middle| Z_{k} \right)} = \sum_{z_{k} \in V}^{}{\mathbf{Q}(z_{k},x_{k})}\\and this is a sum over the column :math:`\mathbf{Q}( \cdot ,x_{k})`.
The time complexity for backward part is also :math:`\Theta(km^{2})`,
since we need to compute
:math:`\mathbb{P(}X_{t + 1},\ldots,X_{k}|Z_{t})` for each
:math:`t = k,\ldots,1`, for each :math:`z_{t} \in V`, and sum over
each :math:`z_{t + 1} \in V`. Thus the time complexity for the whole
forward-backward algorithm is also :math:`\Theta(km^{2})`.\end{aligned}\end{align} \]
<p>Again, the forward-backward algorithm can find the conditional
distribution <span class="math notranslate nohighlight">\(\mathbb{P(}Z_{t}|X)\)</span> for any time <span class="math notranslate nohighlight">\(t\)</span>, and
therefore find
<span class="math notranslate nohighlight">\(z_{t}^{*} = \arg{\operatorname{}{\mathbb{P(}Z_{t} = z_{t}|X)}}\)</span>.
Note an important feature here is that <span class="math notranslate nohighlight">\(z_{t}^{*}\)</span> can be updated
when given more observations <span class="math notranslate nohighlight">\(X\)</span>. In applications like voice
recognition, we might update recognized words in the past after the
program collects more voice from user.</p>
<ul class="simple">
<li>Sometimes we want to find out
<span class="math notranslate nohighlight">\(\mathbf{z}_{1:t} = \arg{\operatorname{}{\mathbb{P(}Z_{1:t} = \mathbf{z}_{1:t}|X_{1:t})}}\)</span>.
An algorithm to find this is the <strong>Viterbi Algorithm</strong>. As before we
try to setup the recursion in the form</li>
</ul>
<div class="math notranslate nohighlight">
\[\arg{\operatorname{}{\mathbb{P(}Z_{1:t} = \mathbf{z}_{1:t}|X_{1:t})}} = \ldots\arg{\operatorname{}{\mathbb{P}\left( Z_{1:t} = \mathbf{z}_{1:t} \middle| X_{1:t} \right)}}\ldots\]
<p>The trick here is to fix <span class="math notranslate nohighlight">\(Z_{t} = z_{t}\)</span> for some
<span class="math notranslate nohighlight">\(z_{t} \in V\)</span>, then</p>
<div class="math notranslate nohighlight">
\[\arg{\operatorname{}{\mathbb{P(}Z_{1:t}|X_{1:t})}} = \arg{\operatorname{}{\mathbb{P(}Z_{1:t},X_{1:t}\ )}} = \arg{\operatorname{}{\mathbb{P(}X_{t}|Z_{1:t},X_{1:t - 1}\mathbb{)P(}Z_{t}|Z_{1:t - 1},X_{1:t - 1}\mathbb{)P(}Z_{1:t - 1},X_{1:t - 1})}} = \arg{\operatorname{}{\mathbb{P(}X_{t}|Z_{t}\mathbb{)P(}Z_{t}|Z_{t - 1}\mathbb{)P(}Z_{1:t - 1},X_{1:t - 1})}}\]
<p>Note for any function <span class="math notranslate nohighlight">\(f,g\)</span> we have</p>
<div class="math notranslate nohighlight">
\[\operatorname{}{f(a)g(a,b)} = \operatorname{}\left( \operatorname{}{f\left( a \right)g(a,b)} \right) = \operatorname{}\left( f\left( a \right)\operatorname{}{g(a,b)} \right)\]
<p>And thus we have</p>
<div class="math notranslate nohighlight">
\[\operatorname{}{\mathbb{P(}Z_{1:t} = \mathbf{z}_{1:t},X_{1:t})} = \operatorname{}{\mathbb{P(}X_{t}|Z_{t}\mathbb{)P(}Z_{t}|Z_{t - 1}\mathbb{)P(}Z_{1:t - 1},X_{1:t - 1})} = \operatorname{}{\mathbb{P(}X_{t}|Z_{t} = z_{t}\mathbb{)P(}Z_{t} = z_{t}|Z_{t - 1}\mathbb{)P(}Z_{1:t - 1} = \mathbf{z}_{1:t - 1},X_{1:t - 1})} = \operatorname{}\left( \mathbb{P}\left( X_{t} \middle| Z_{t} = z_{t} \right)\mathbb{P}\left( Z_{t} = z_{t} \middle| Z_{t - 1} \right)\operatorname{}{\mathbb{P}\left( Z_{1:t - 1} = \mathbf{z}_{1:t - 1},X_{1:t - 1} \right)} \right) = \operatorname{}\left( \mathbf{Q}\left( z_{t},x_{t} \right)\mathbf{P}\left( z_{t - 1},z_{t} \right)\operatorname{}{\mathbb{P}\left( Z_{1:t - 1} = \mathbf{z}_{1:t - 1},X_{1:t - 1} \right)} \right)\]
<p>This is a valid recursion since the original problem is reduced to
<span class="math notranslate nohighlight">\(\operatorname{}{\mathbb{P(}Z_{1:t - 1} = \mathbf{z}_{1:t - 1},X_{1:t - 1})}\)</span>
by fixing <span class="math notranslate nohighlight">\(Z_{t - 1} = z_{t - 1}\)</span>. The recursion stops when
<span class="math notranslate nohighlight">\(t = 2\)</span>,</p>
<div class="math notranslate nohighlight">
\[\operatorname{}{\mathbb{P(}Z_{1},Z_{2},X_{1},X_{2})} = \operatorname{}(\mathbf{Q}(z_{1},x_{1})\mathbf{P}(z_{1},z_{2})\mathbf{Q}(z_{2},x_{2})) = \operatorname{}(\mathbf{Q}(z_{1},x_{1})\mathbf{P}(z_{1},z_{2}))\]
<p>where the last identity is a due to <span class="math notranslate nohighlight">\(\mathbf{Q}(z_{2},x_{2})\)</span> is
constant since <span class="math notranslate nohighlight">\(z_{2},x_{2}\)</span> are given. We can visualize the above
recursion by <strong>maximum probability paths</strong> shown below,</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">&#160;</th>
<th class="head"><p class="first"><em>(1) For every</em>
<span class="math notranslate nohighlight">\(z_{2} \in V\)</span><em>, find</em></p>
<div class="math notranslate nohighlight">
\[z_{1}^{*}(z_{2}) = \arg\]
<p>{operatorname{}{mathbb{P(}Z_{1:
2},X_{1:2})}}</p>
<p class="last"><em>and draw a line from</em>
<span class="math notranslate nohighlight">\(z_{2}\)</span> <em>to</em>
<span class="math notranslate nohighlight">\(z_{1}^{*}\)</span><em>. Store the
maximum values</em>
<span class="math notranslate nohighlight">\(z_{1}^{*}(z_{2})\)</span> <em>at
corresponding</em> <span class="math notranslate nohighlight">\(z_{2}\)</span>
<em>node.</em></p>
</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>&#160;</td>
<td><p class="first"><em>(2) For every</em>
<span class="math notranslate nohighlight">\(z_{3} \in V\)</span><em>, find</em></p>
<div class="math notranslate nohighlight">
\[z_{2}^{*}\left( z_{3} \\]
<p>right) = arg{operatorname{}{ma
thbb{P}left( Z_{1:3},X_{1:3} ri
ght)}} = operatorname{}left( m
athbf{Q}left( z_{3},x_{3} right
)mathbf{P}left( z_{2},z_{3} ri
ght)z_{1}^{*}(z_{2}) right)</p>
<p class="last"><em>and draw a line from</em>
<span class="math notranslate nohighlight">\(z_{3}\)</span> <em>to</em>
<span class="math notranslate nohighlight">\(z_{2}^{*}\)</span><em>. We simply
use the previously found max
values stored at each</em>
<span class="math notranslate nohighlight">\(z_{2}\)</span> <em>node, and do not
need to compute the full
recursion. Store the maximum
values</em>
<span class="math notranslate nohighlight">\(z_{2}^{*}\left( z_{3} \rig
ht)\)</span>
<em>at corresponding</em> <span class="math notranslate nohighlight">\(z_{3}\)</span>
<em>node.</em></p>
</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td><p class="first"><em>(3) Continue until for every</em>
<span class="math notranslate nohighlight">\(z_{t} \in V\)</span><em>we find</em></p>
<div class="math notranslate nohighlight">
\[z_{t - 1}^{*}(z_{t}) =\]
<p>operatorname{}left( mathbf{Q}left( z_{t},x_{t} right)mathbf{
P}left( z_{t - 1},z_{t} right)z
_{t - 2}^{*}(z_{t - 1}) right)</p>
<p><em>Then simply find</em>
:math:<a href="#id49"><span class="problematic" id="id50">`</span></a>z_{t}^{*} = arg{max{z_{t</p>
<blockquote>
<div><ul class="simple">
<li>1}^{*}(z_{t})}}`</li></ul></blockquote>
<p class="last"><em>and the corresponding path as
our optimal solution of</em>
<span class="math notranslate nohighlight">\(\mathbf{z}_{1:t} = \arg{\o
peratorname{}{\mathbb{P(}Z_{1:t}
= \mathbf{z}_{1:t}|X_{1:t})}}\)</span>*
.*</p>
</td>
</tr>
</tbody>
</table>
<p>The time complexity is <span class="math notranslate nohighlight">\(tm^{2}\)</span>, since at the <span class="math notranslate nohighlight">\(i\)</span>th step
we need to maximize over <span class="math notranslate nohighlight">\(z_{i} \in V\)</span> for every
<span class="math notranslate nohighlight">\(z_{i + 1} \in V\)</span>, and there are total <span class="math notranslate nohighlight">\(t\)</span> steps; and space
complexity is clearly <span class="math notranslate nohighlight">\(\text{tm}\)</span>.</p>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">REMARK: Underflow Problem</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><p class="first">In general, to compute <span class="math notranslate nohighlight">\(\log{\sum_{i}^{}e^{- a_{i}}}\)</span> for large
<span class="math notranslate nohighlight">\(a_{i}\)</span>, if we brutally add them up, some terms would be so
small that they are truncated when running the sum on a computer.
Although one truncation of small quantity might be negligible,
truncations of many such small quantities could be significant when
added up. A solution is to extract <span class="math notranslate nohighlight">\(b = \max{\{ a_{i}\}}\)</span> from
the sum, which is called the <strong>log-sum-exp trick</strong>.</p>
<div class="math notranslate nohighlight">
\[\log{\sum_{i}^{}e^{- a_{i}}} = \log{e^{- b}\sum_{i}^{}e^{b\]
<ul class="simple">
<li>a_{i}}} = - b + log{sum_{i}^{}e^{b - a_{i}}}</li>
</ul>
<p>For example, the following codes would yield slightly different
results in python, where the first one using log-sum-exp trick yields
more accurate result.</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><p class="first">print&nbsp;\</p>
<p>(</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;-30&nbsp;+&nbsp;\</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;math.log(math.exp(30&nbsp;-&nbsp;2)
+&nbsp;\</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;1000000&nbsp;*&nbsp;math.exp(30&nbsp;-&nbsp;30
))&nbsp;\</p>
<p class="last">)</p>
</th>
<th class="head"><p class="first">b&nbsp;=&nbsp;math.exp(-2)</p>
<p>for&nbsp;i&nbsp;in&nbsp;range(0,1000000):</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;b&nbsp;+=&nbsp;math.exp(-30)</p>
<p class="last">print(math.log(b))</p>
</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><em>output: -1.999999308560227</em></td>
<td><em>output: -1.9999993086502585</em></td>
</tr>
<tr class="row-odd"><td><a href="#id51"><span class="problematic" id="id52">*</span></a>true value:
-1.999999308560228350513703368
44588381767981954557023664913…
*</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<p>In the forward-backward algorithm, the probabilities
<span class="math notranslate nohighlight">\(\mathbb{P}\left( Z_{t},X_{1},\ldots,X_{t} \right)\)</span> and
<span class="math notranslate nohighlight">\(\mathbb{P(}X_{t + 1},\ldots,X_{k}|Z_{t})\)</span> could be very small
when <span class="math notranslate nohighlight">\(m,n\)</span> are very large s.t. the probability is distributed
over large matrices <span class="math notranslate nohighlight">\(\mathbf{P},\mathbf{Q}\)</span>.
<span class="math notranslate nohighlight">\(\mathbb{P}\left( Z_{t},X_{1},\ldots,X_{t} \right)\)</span> could also
be very small when <span class="math notranslate nohighlight">\(t\)</span> approaches <span class="math notranslate nohighlight">\(k\)</span> if <span class="math notranslate nohighlight">\(k\)</span> is
very large, and <span class="math notranslate nohighlight">\(\mathbb{P(}X_{t + 1},\ldots,X_{k}|Z_{t})\)</span>
could also be very small when <span class="math notranslate nohighlight">\(t\)</span> approaches <span class="math notranslate nohighlight">\(1\)</span> if
<span class="math notranslate nohighlight">\(k\)</span> are very large. Taking the forward part for example, let
<span class="math notranslate nohighlight">\(\mathbb{P}\left( Z_{t},X_{1},\ldots,X_{t} \right) = p_{t}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{Q}\left( z_{t},x_{t} \right)\mathbf{P}\left( z_{t - 1}
,z_{t} \right) = c_{t}\)</span>,
then</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( Z_{t},X_{1},\ldots,X_{t} \right) = \sum_{z\]
<p>_{t - 1} in V}^{}{mathbf{Q}left( z_{t},x_{t} right)mathbf{P}lef
t( z_{t - 1},z_{t} right)mathbb{P}left( Z_{t - 1},X_{1},ldots,X_{
t - 1} right)} Rightarrow p_{t} = sum_{z_{t - 1} in V}^{}{c_{t}p_
{t - 1}}</p>
<p>The underflow problem happens when some <span class="math notranslate nohighlight">\(c_{t}p_{t - 1}\)</span> are
very small and truncated by the sum when running a computer program.
In this case, we can use the above log-sum-exp trick to cope with the
small probability problem. Let
<span class="math notranslate nohighlight">\(b = \operatorname{}{\{\log c_{t} + \log p_{t - 1}\}}\)</span>, and we
have</p>
<div class="math notranslate nohighlight">
\[\log p_{t} = \log{\sum_{z_{t - 1} \in V}^{}{c_{t}p_{t - 1}}\]
<p class="last">} = log{sum_{z_{t - 1} in V}^{}e^{log{c_{t}p_{t - 1}}}} = log{s
um_{z_{t - 1} in V}^{}e^{log c_{t} + log p_{t - 1}}} = b + log{s
um_{z_{t - 1} in V}^{}e^{log c_{t} + log p_{t - 1} - b}}</p>
</td>
</tr>
</tbody>
</table>
<div class="section" id="markov-random-fields">
<h4><strong>Markov Random Fields</strong><a class="headerlink" href="#markov-random-fields" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="stochastic-block-mode">
<h3>Stochastic Block Mode<a class="headerlink" href="#stochastic-block-mode" title="Permalink to this headline">¶</a></h3>
<div class="section" id="the-standard-model">
<h4><strong>The Standard Model</strong><a class="headerlink" href="#the-standard-model" title="Permalink to this headline">¶</a></h4>
<p><strong>Stochastic Block Model</strong> (SBM) is a probabilistic generative model
that clusters vertexes of a graph <span class="math notranslate nohighlight">\(G = (V,E)\)</span> into <span class="math notranslate nohighlight">\(k\)</span>
groups by modeling generation of the graph edges <span class="math notranslate nohighlight">\(E\)</span>, i.e. in this
model when all parameters are given, the probability of a particular
edge set is determined. Here <span class="math notranslate nohighlight">\(k\)</span> is pre-defined, each group is
also named a <strong>block</strong> or a <strong>community</strong>, and the finite sample space
for this model is all possible edge set. The sample space is very large,
of size <span class="math notranslate nohighlight">\(2^{\left| V \right|^{2} - |V|}\)</span> for a directed graph or
<span class="math notranslate nohighlight">\(2^{\left| V \right|^{2} - \left| V \right| - 1}\)</span> for an
undirected graph. WLOG, let the vertexes in <span class="math notranslate nohighlight">\(V\)</span> be integers
<span class="math notranslate nohighlight">\(V = \{ 1,\ldots,|V|\}\)</span>, then the model parameters include</p>
<ol class="arabic">
<li><p class="first">A membership vector
<span class="math notranslate nohighlight">\(\mathbf{z} = \left( z_{1},\ldots,z_{\left| V \right|} \right)\)</span>
s.t.
<span class="math notranslate nohighlight">\(z_{u} \in \left\{ 1,\ldots,k \right\},\forall u = 1,\ldots,\left| V \right|\)</span>,
indicating the membership of each vertex, i.e. <span class="math notranslate nohighlight">\(u\)</span> is in group
<span class="math notranslate nohighlight">\(z_{u}\)</span>.</p>
</div></div></div></div></div></div></div></div></div></li><li><p class="first">A <span class="math notranslate nohighlight">\(k \times k\)</span> matrix named <strong>stochastic block matrix</strong>
<span class="math notranslate nohighlight">\(\mathbf{P}\)</span> s.t. <span class="math notranslate nohighlight">\(\mathbf{P}(i,j)\)</span> is the probability of
a vertex in group <span class="math notranslate nohighlight">\(i\)</span> has an edge with a vertex in group
<span class="math notranslate nohighlight">\(j\)</span>. If <span class="math notranslate nohighlight">\(i = j\)</span>, we call <span class="math notranslate nohighlight">\(\mathbf{P}(i,j)\)</span> as the
<strong>intra-group edge occurrence probability</strong>; if <span class="math notranslate nohighlight">\(i \neq j\)</span>, we
call <span class="math notranslate nohighlight">\(\mathbf{P}(i,j)\)</span> as the <strong>inter-group edge occurrence
probability</strong>. Note <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> is not a stochastic matrix
although it has the word “stochastic” in its name, but we do have
<span class="math notranslate nohighlight">\(\sum_{i}^{}{\mathbf{P}(i,j)} \leq 1\)</span>, because
<span class="math notranslate nohighlight">\(1 - \sum_{i}^{}{\mathbf{P}(i,j)}\)</span> is the probability that a
vertex in group <span class="math notranslate nohighlight">\(i\)</span> has no edge with other nodes.</p>
<p>For undirected graph, <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> should be symmetric. In this
case, the event that “a vertex in group <span class="math notranslate nohighlight">\(i\)</span> is connected with a
vertex in group <span class="math notranslate nohighlight">\(j\)</span>”, whose probability is specified by
<span class="math notranslate nohighlight">\(\mathbf{P}(i,j)\)</span>, is identical to the event that “a vertex in
group <span class="math notranslate nohighlight">\(j\)</span> is connected with a vertex in group <span class="math notranslate nohighlight">\(i\)</span>”,
whose probability is specified by <span class="math notranslate nohighlight">\(\mathbf{P}(j,i)\)</span>, then
<span class="math notranslate nohighlight">\(\mathbf{P}\)</span> should clearly be a symmetric matrix in order for
the two events to have the same probability.</p>
</li>
</ol>
<p>Assume edge formation between every pair of vertexes are independent.
Then <span class="math notranslate nohighlight">\(E\)</span> can be viewed as being generalized by this process: for
every pair of vertexes <span class="math notranslate nohighlight">\(u,v\)</span>, let <span class="math notranslate nohighlight">\(\left( u,v \right) \in E\)</span>
by probability <span class="math notranslate nohighlight">\(\mathbf{P}(z_{u},z_{v})\)</span>. Now given
<span class="math notranslate nohighlight">\(\mathbf{z}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>, the likelihood function
<span class="math notranslate nohighlight">\(\mathcal{L}\left( \mathbf{z},\mathbf{P} \right)\mathbb{= P}\left( E|\mathbf{z},\mathbf{P} \right) = \prod_{\left( u,v \right) \in E}^{}{\mathbf{P}(z_{u},z_{v})}\prod_{\left( u,v \right) \notin E}^{}\left( 1 - \mathbf{P}\left( z_{u},z_{v} \right) \right)\)</span>
will be determined for any <span class="math notranslate nohighlight">\(E\)</span>, thus and we have finished the
modeling.</p>
<p>Let <span class="math notranslate nohighlight">\(C_{i},i = 1,\ldots,k\)</span> be the set of all nodes in group
<span class="math notranslate nohighlight">\(i\)</span> and let <span class="math notranslate nohighlight">\(n_{i} = |C_{i}|\)</span>. The number of all possible
edges from group <span class="math notranslate nohighlight">\(i\)</span> to group <span class="math notranslate nohighlight">\(j\)</span> would be
<span class="math notranslate nohighlight">\(n_{i,j} = \left\{ \begin{matrix}
n_{i}n_{j} &amp; i \neq j \\
\begin{pmatrix}
n_{i} \\
2 \\
\end{pmatrix} &amp; i = 1 \\
\end{matrix} \right.\ \)</span> for undirected graph and
<span class="math notranslate nohighlight">\(n_{i,j} = \left\{ \begin{matrix}
n_{i}n_{j} &amp; i \neq j \\
2\begin{pmatrix}
n_{i} \\
2 \\
\end{pmatrix} &amp; i = 1 \\
\end{matrix} \right.\ \)</span> for directed graph. Let <span class="math notranslate nohighlight">\(e_{i,j}\)</span> be the
number of actual edges between group <span class="math notranslate nohighlight">\(i\)</span> and group <span class="math notranslate nohighlight">\(j\)</span>. Note
all <span class="math notranslate nohighlight">\(n_{i,j}\)</span> and <span class="math notranslate nohighlight">\(e_{i,j}\)</span> are functions of
<span class="math notranslate nohighlight">\(\mathbf{z}\)</span>. We can in addition let
<span class="math notranslate nohighlight">\(\mathbf{E} = \left( e_{i,j} \right),\mathbf{N} = (n_{i,j})\)</span> be
two <span class="math notranslate nohighlight">\(k \times k\)</span> matrices to store above-mentioned values, and let
<span class="math notranslate nohighlight">\(\mathbf{n} = (n_{i})\)</span> be a vector of length <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>Under the independence assumption, the order of edge formations does not
matter, thus we can first form edges between a pair <span class="math notranslate nohighlight">\(C_{i},C_{j}\)</span>
altogether, and then form edges between another pair, then we have</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathcal{L(\]
<p>}mathbf{z},mathbf{P
}mathbb{) = P}left(</p>
<blockquote>
<div>E|mathbf{z},mathbf</blockquote>
<p>{P} right) = prod_{
i,j in { 1,ldots,k
}}^{}{{mathbf{P}(i,
j)}^{e_{i,j}}left( 1</p>
<blockquote>
<div><ul class="simple">
<li>mathbf{P}(i,j) r</li></ul></blockquote>
<p class="last">ight)^{n_{i,j} - e_{i
,j}}}</p>
</td>
<td>&#160;</td>
<td>(17‑1)</td>
</tr>
</tbody>
</table>
<p>Each formation is a Bernoulli experiment governed by probability
<span class="math notranslate nohighlight">\(\mathbf{P}\left( i,j \right)\)</span>, represented by one factor
<span class="math notranslate nohighlight">\({\mathbf{P}\left( i,j \right)}^{e_{i,j}}\left( 1 - \mathbf{P}\left( i,j \right) \right)^{n_{i,j} - e_{i,j}}\)</span>
in the above product, and it is easy to verify that MLE for
<span class="math notranslate nohighlight">\(\mathbf{P}\left( i,j \right)\)</span> in above <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is
<span class="math notranslate nohighlight">\(\widehat{\mathbf{P}}\left( i,j \right) = \frac{e_{i,j}}{n_{i,j}}\)</span>
by EX 5, which is a function of <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>, and we can restrict
the original <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> to
<span class="math notranslate nohighlight">\(\mathcal{L(}\mathbf{z},\widehat{\mathbf{P}})\)</span>,</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathcal{L}\]
<p>left( mathbf{z},wi
dehat{mathbf{P}} ri
ght) = prod_{i,j in</p>
<blockquote>
<div>left{ 1,ldots,k </blockquote>
<p>right}}^{}left( fr
ac{e_{i,j}}{n_{i,j}}
right)^{e_{i,j}}lef
t( 1 - frac{e_{i,j}}
{n_{i,j}} right)^{<a href="#id77"><span class="problematic" id="id78">n_</span></a>
{i,j} - e_{i,j}} Rig
htarrow lnmathcal{L
} = sum_{i,j in le
ft{ 1,ldots,k righ
t}}^{}{e_{i,j}left(</p>
<blockquote>
<div>ln e_{i,j} - ln <a href="#id79"><span class="problematic" id="id80">n_</span></a></blockquote>
<p>{i,j} right) + left
( n_{i,j} - e_{i,j} right)left( lnleft
( n_{i,j} - e_{z_{i},
z_{j}} right) - ln
n_{i,j} right)} = s
um_{i,j in left{ 1
,ldots,k right}}^{
}{e_{i,j}ln e_{i,j}
- e_{i,j}ln n_{i,j}
+ left( n_{i,j} - <a href="#id81"><span class="problematic" id="id82">e_</span></a>
{i,j} right)lnleft
( n_{i,j} - e_{i,j} right) - n_{i,j}ln n
_{i,j} + e_{i,j}ln n
_{i,j}} = sum_{i,j in left{ 1,ldots,k</p>
<blockquote>
<div>right}}^{}{e_{i,j}</blockquote>
<p>ln e_{i,j} - n_{i,j}
ln n_{i,j} + left(
n_{i,j} - e_{i,j} ri
ght)lnleft( n_{i,j}</p>
<blockquote class="last">
<div><ul class="simple">
<li>e_{i,j} right)}</li></ul></blockquote>
</td>
<td>&#160;</td>
<td>(17‑2)</td>
</tr>
</tbody>
</table>
<p>To solve <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>, the basic approach is coordinate ascent.
First, we initialize <span class="math notranslate nohighlight">\(\mathbf{z},\mathbf{P}\)</span> as
<span class="math notranslate nohighlight">\(\mathbf{z}^{\left( 0 \right)},\mathbf{P}^{(0)}\)</span>, which could be
random or based on some heuristics. Then we will have the first
component of <span class="math notranslate nohighlight">\(\mathbf{z}^{(0)}\)</span> updated and have
<span class="math notranslate nohighlight">\(\mathbf{z}^{(1)}\)</span>, which might be equal to
<span class="math notranslate nohighlight">\(\mathbf{z}^{(0)}\)</span> or differ from <span class="math notranslate nohighlight">\(\mathbf{z}^{(0)}\)</span> only at
its first component. We then go on to update the 2<sup>nd</sup>,
3<sup>rd</sup>, … component in order and have
<span class="math notranslate nohighlight">\(\mathbf{z}^{\left( 2 \right)},\mathbf{z}^{(3)}\)</span>,… At the end of
one sweep of updating all components of <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> and having
<span class="math notranslate nohighlight">\(\mathbf{z}^{(|V|)}\)</span>, we will then update <span class="math notranslate nohighlight">\(\mathbf{P}^{(0)}\)</span>
as <span class="math notranslate nohighlight">\(\mathbf{P}^{(1)}\)</span> based on <span class="math notranslate nohighlight">\(\mathbf{z}^{(|V|)}\)</span>,
although we will then show updating <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> is not necessary
except for the end. The entire process will repeat again and again until
there is no significant change in both <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{z}\)</span>, or equivalently there is no significant increase in
<span class="math notranslate nohighlight">\(\ln\mathcal{L}\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(s = (t\ \text{mod}\ |V|)\)</span>, and let <span class="math notranslate nohighlight">\(\mathbf{z}^{(t,r)}\)</span>
be derived from replacing the <span class="math notranslate nohighlight">\(s\)</span>th component of
<span class="math notranslate nohighlight">\(\mathbf{z}^{(t - 1)}\)</span> by <span class="math notranslate nohighlight">\(r\)</span>. Let <span class="math notranslate nohighlight">\(n_{i,j}^{(t,r)}\)</span>
and <span class="math notranslate nohighlight">\(e_{i,j}^{(t,r)}\)</span> be the counts based on
<span class="math notranslate nohighlight">\(\mathbf{z}^{(t,r)}\)</span>, then the update formula would simply be</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbf{z}^\]
<p>{(t)} = operatorname
{}{operatorname{}{m
athcal{L}left( math
bf{z}^{left( t,r ri
ght)},mathbf{P}^{le
ft( leftlfloor fra
c{t}{left| V right|
} rightrfloor righ
t)} right)}} = oper
atorname{}{operatorn
ame{}left( sum_{i,j</p>
<blockquote>
<div>in left{ 1,ldots</blockquote>
<p>,k right}}^{}{e_{i,
j}^{(t,r)}ln e_{i,j}
^{(t,r)} - n_{i,j}^{(
t,r)}ln n_{i,j}^{(t,
r)} + left( n_{i,j}^
{(t,r)} - e_{i,j}^{(t
,r)} right)lnleft(</p>
<blockquote>
<div>n_{i,j}^{(t,r)} - <a href="#id83"><span class="problematic" id="id84">e_</span></a></blockquote>
<p class="last">{i,j}^{(t,r)} right)
} right)}</p>
</td>
<td>&#160;</td>
<td>(17‑3)</td>
</tr>
</tbody>
</table>
<p>Now we want to derive the time complexity for computing above
maximization. Assume we keep track of the values of matrix
<span class="math notranslate nohighlight">\(\mathbf{E}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{N}\)</span>, and the group vertex count
vector <span class="math notranslate nohighlight">\(\mathbf{n}\)</span>, which costs space complexity
<span class="math notranslate nohighlight">\(\Theta(2k^{2} + k)\)</span>. For simplicity denote
<span class="math notranslate nohighlight">\(r^{'} = z_{s}^{(t - 1)}\)</span>, and again, we attempt to change the
membership assignment of <span class="math notranslate nohighlight">\(v_{s}\)</span> from <span class="math notranslate nohighlight">\(r^{'}\)</span> to
<span class="math notranslate nohighlight">\(r \in \{ 1,\ldots,k\}\)</span> s.t. the re-assignment maximally increases
<span class="math notranslate nohighlight">\(\ln\mathcal{L}\)</span>.</p>
<p>We need to re-compute some <span class="math notranslate nohighlight">\(e_{i,j}\)</span>s and <span class="math notranslate nohighlight">\(n_{i,j}\)</span>s in
order to calculate the new <span class="math notranslate nohighlight">\(\ln\mathcal{L}\)</span>. There is no change in
<span class="math notranslate nohighlight">\(\ln\mathcal{L}\)</span> when <span class="math notranslate nohighlight">\(r^{'} = r\)</span>, so we only consider the
case of <span class="math notranslate nohighlight">\(r^{'} \neq r\)</span>.</p>
<ol class="arabic">
<li><p class="first"><em>The first term</em>
<span class="math notranslate nohighlight">\(\sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{i,j}}\)</span>.
Recall <span class="math notranslate nohighlight">\(e_{i,j}\)</span> is the actually number of edges between group
<span class="math notranslate nohighlight">\(i\)</span> and group <span class="math notranslate nohighlight">\(j\)</span>. Let <span class="math notranslate nohighlight">\(\mathcal{N}_{o}(v_{s})\)</span>
denote the out-neighborhood of <span class="math notranslate nohighlight">\(v_{s}\)</span>, i.e.
<span class="math notranslate nohighlight">\(\mathcal{N}_{o}\left( v_{s} \right) = \{ v \in V:\left( v_{s},v \right) \in E\}\)</span>,
and let
<span class="math notranslate nohighlight">\(\mathcal{K}_{o}\left( v_{s} \right) = \{ z_{v}:v \in \mathcal{N}_{o}\left( v_{s} \right)\}\)</span>
be the out-neighboring groups of <span class="math notranslate nohighlight">\(v_{s}\)</span>. It is easy to see the
re-assignment only affects <span class="math notranslate nohighlight">\(e_{r^{'},j}\)</span> and <span class="math notranslate nohighlight">\(e_{r,j}\)</span>
s.t. <span class="math notranslate nohighlight">\(j \in \mathcal{K}_{o}\left( v_{s} \right)\)</span>. For example,
as shown below, suppose <span class="math notranslate nohighlight">\(k = 4\)</span> and we change the membership of
<span class="math notranslate nohighlight">\(v_{s}\)</span> from <span class="math notranslate nohighlight">\(r^{'} = 1\)</span> to <span class="math notranslate nohighlight">\(r = 2\)</span>. If
<span class="math notranslate nohighlight">\(v_{s}\)</span> has two outbound edges as shown in the graph, then the
affected <span class="math notranslate nohighlight">\(e_{i,j}\)</span> are <span class="math notranslate nohighlight">\(e_{1,2},e_{1,3},e_{2,2},e_{2,3}\)</span>,
because group 1 and 4 are neighboring groups of node <span class="math notranslate nohighlight">\(v_{s}\)</span>.</p>
<p><a class="reference internal" href="media/image34.png"><img alt="image25" src="media/image34.png" style="width: 5.33081in; height: 1.94in;" /></a></p>
<p><em>Figure</em> <em>17‑1 Illustration of membership re-assignment affects
cross-group edge counts</em> <span class="math notranslate nohighlight">\(e_{i,j}\)</span><em>.</em></p>
<p>For the same argument, we similarly define the in-neighborhood as
<span class="math notranslate nohighlight">\(\mathcal{N}_{i}\left( v_{s} \right) = \{ v \in V:\left( v,v_{s} \right) \in E\}\)</span>
and in-neighboring groups as
<span class="math notranslate nohighlight">\(\mathcal{K}_{i}\left( v_{s} \right) = \{ z_{v}:v \in \mathcal{N}_{i}\left( v_{s} \right)\}\)</span>,
then the re-assignment only affects <span class="math notranslate nohighlight">\(e_{i,r^{'}}\)</span> and
<span class="math notranslate nohighlight">\(e_{i,r}\)</span> s.t.
<span class="math notranslate nohighlight">\(i \in \mathcal{K}_{i}\left( v_{s} \right)\)</span>. In above example,
the re-assignment affect <span class="math notranslate nohighlight">\(e_{1,1},e_{1,2}\)</span>. Thus, in total, the
we need re-computation of
<span class="math notranslate nohighlight">\(2\left| \mathcal{N}_{o}\left( v_{s} \right) \right| + 2\left| \mathcal{N}_{i}\left( v_{s} \right) \right| \leq 2\left( \operatorname{}v_{s} + \operatorname{}v_{s} \right) = 2\deg v_{s}\)</span>
of those <span class="math notranslate nohighlight">\(e_{i,j}\)</span>s and corresponding change in
<span class="math notranslate nohighlight">\(e_{i,j}\ln e_{i,j}\)</span>, where <span class="math notranslate nohighlight">\(\operatorname{}v_{s}\)</span> is the
out-degree of <span class="math notranslate nohighlight">\(v_{s}\)</span>, <span class="math notranslate nohighlight">\(\operatorname{}v_{s}\)</span> is the
in-degree of <span class="math notranslate nohighlight">\(v_{s}\)</span>, and
<span class="math notranslate nohighlight">\(\deg v_{s} = \operatorname{}v_{s} + \operatorname{}v_{s}\)</span>.</p>
</li><li><p class="first"><em>The remaining terms</em>
“<span class="math notranslate nohighlight">\(\sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{- n_{i,j}\ln n_{i,j} + \left( n_{i,j} - e_{i,j} \right)\ln\left( n_{i,j} - e_{i,j} \right)}\)</span>”.
For <span class="math notranslate nohighlight">\(n_{i,j}\)</span>, the re-assignment requires re-computation of all
<span class="math notranslate nohighlight">\(n_{r^{'},j},n_{r,j},n_{i,r^{'}},n_{i,r}\)</span> where
<span class="math notranslate nohighlight">\(i,j \in \{ 1,\ldots,k\}\)</span>. It is re-computing two rows and two
columns of matrix <span class="math notranslate nohighlight">\(\mathbf{N}\)</span>, and it is easy to see there are
<span class="math notranslate nohighlight">\(2k + \left( 2k - 4 \right) = 4k - 4 \leq 4k\)</span> times of
re-computations.</p>
</li>
</ol>
<p>The maximum is computed over <span class="math notranslate nohighlight">\(r \in \{ 1,\ldots,k\}\)</span>. As a result,
decision on the best <span class="math notranslate nohighlight">\(r\)</span> for <span class="math notranslate nohighlight">\(\mathbf{z}^{(t)}\)</span> requires at
most <span class="math notranslate nohighlight">\(k\deg v_{s} + 4k^{2}\)</span> time complexity, and thus sweep of
coordinate ascent requires at most
<span class="math notranslate nohighlight">\(k\sum_{v \in V}^{}{\deg v} + 4k^{2}\left| V \right| = 2k\left| E \right| + 4k^{2}\left| V \right| = O\left( k\left| E \right| + k^{2}\left| V \right| \right)\)</span>.
For a big graph, usually we have
<span class="math notranslate nohighlight">\(\frac{\left| E \right|}{|V|} \ll k\)</span>, i.e. the average graph
degree is far smaller than <span class="math notranslate nohighlight">\(k\)</span>, then
<span class="math notranslate nohighlight">\(k\left| E \right| \ll k^{2}|V|\)</span> and
<span class="math notranslate nohighlight">\(O\left( k\left| E \right| + k^{2}\left| V \right| \right) \approx O\left( k^{2}\left| V \right| \right)\)</span>.</p>
<p>The update of <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> is not necessary since
<span class="math notranslate nohighlight">\(\mathbf{P}\)</span> has been represented by <span class="math notranslate nohighlight">\(e_{i,j}\)</span>s and
<span class="math notranslate nohighlight">\(n_{i,j}\)</span>s and is never directly used in updating
<span class="math notranslate nohighlight">\(\mathbf{z}\)</span>. We only need to update <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> once based
on <span class="math notranslate nohighlight">\(\mathbf{P}\left( i,j \right) = \frac{e_{i,j}}{n_{i,j}}\)</span> at the
end of the whole algorithm. Thus, one sweep of above-defined coordinate
ascent takes <span class="math notranslate nohighlight">\(O\left( k^{2}|V| \right)\)</span> time, which is in practice
a very high running time. If we let <span class="math notranslate nohighlight">\(k = \sqrt{|V|}\)</span>, we can see
one sweep requires <span class="math notranslate nohighlight">\(O(\left| V \right|^{2})\)</span> time. If we assume
the convergence at least takes <span class="math notranslate nohighlight">\(k\)</span> rounds, then this Gibbs
sampling would require at least <span class="math notranslate nohighlight">\(O(\left| V \right|^{2.5})\)</span> time.</p>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><p class="first">For the second term,
<span class="math notranslate nohighlight">\(\sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{n_{i,j}\ln n_{i,
j}}\)</span>,
the time complexity cannot be reduced by expanding it. For directed
graph, we have</p>
<div class="math notranslate nohighlight">
\[\sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{n_{i,j}\ln n_\]
<p>{i,j}} = sum_{i = 1}^{k}{n_{i}(n_{i} - 1)ln{n_{i}(n_{i} - 1)}} + s
um_{i neq j}^{}{n_{i}n_{j}ln n_{i}} + sum_{i neq j}^{}{n_{i}n_{j}
ln n_{j}}</p>
<p>Although we only need to update <span class="math notranslate nohighlight">\(n_{r^{'}},n_{r}\)</span> to re-compute
the above sum, we still need to re-compute
<span class="math notranslate nohighlight">\(2 + 2k - 1 + 2k - 1 = 4k\)</span> addends in the sum.</p>
<p class="last">As we can see, the culprit that drags down the time complexity is
<span class="math notranslate nohighlight">\(n_{i,j}\)</span> (not <span class="math notranslate nohighlight">\(\ln n_{i,j}\)</span>, which can be decomposed
into <span class="math notranslate nohighlight">\(\ln n_{i} + \ln n_{j}\)</span>), since the membership
reassignment will always affect <span class="math notranslate nohighlight">\(2k - 1\)</span> such quantities. In
the <a class="reference external" href="#_The_Poisson_Variant">next section</a>, we will develop a
log-likelihood without this quantity.</p>
</td>
</tr>
</tbody>
</table>
<p>A random initialization of <span class="math notranslate nohighlight">\(\mathbf{z}^{\mathbf{(}0\mathbf{)}}\)</span>
takes <span class="math notranslate nohighlight">\(O(|V|)\)</span>, and computing of <span class="math notranslate nohighlight">\(e_{i,j}\)</span>s and
<span class="math notranslate nohighlight">\(n_{i,j}\)</span>s can be done by iterating through the outbound edges
<span class="math notranslate nohighlight">\(\{\left( v,u \right):\left( v,u \right) \in E\}\)</span> of each node
<span class="math notranslate nohighlight">\(v \in V\)</span>, and hence take <span class="math notranslate nohighlight">\(O(|E|)\)</span> time. Altogether the
initialization takes
<span class="math notranslate nohighlight">\(O\left( \max\left( \left| V \right|,\left| E \right| \right) \right) = O(|E|)\)</span>
time since usually <span class="math notranslate nohighlight">\(\left| V \right| &lt; |E|\)</span>. The space complexity
is
<span class="math notranslate nohighlight">\(O\left( \max\left\{ 3k^{2},\left| V \right| \right\} \right) = O(|V|)\)</span>
for storage of <span class="math notranslate nohighlight">\(\mathbf{z},\mathbf{P},e_{i,j},n_{i,j}\)</span> since
usually <span class="math notranslate nohighlight">\(k \ll \left| V \right|\)</span>.</p>
<p>EX 5. Given i.i.d. sample <span class="math notranslate nohighlight">\(X_{1},\ldots,X_{n} \in \{ 0,1\}\)</span>, show
the MLE for the parameter <span class="math notranslate nohighlight">\(p\)</span> of a Bernoulli distribution
<span class="math notranslate nohighlight">\(\text{Bernoulli}(p)\)</span> is
<span class="math notranslate nohighlight">\(\widehat{p} = \frac{\sum_{i = 1}^{n}X_{i}}{n}\)</span>.</p>
<p>Key. The likelihood function is</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}\left( p \right)\mathbb{= P}\left( X_{1},\ldots,X_{n} \middle| p \right) = p^{\sum_{i = 1}^{n}X_{i}}\left( 1 - p \right)^{n - \sum_{i = 1}^{n}X_{i}}\]
<p>When <span class="math notranslate nohighlight">\(p \in (0,1)\)</span>, the log-likelihood is</p>
<div class="math notranslate nohighlight">
\[\ln\mathcal{L} = \left( \sum_{i = 1}^{n}X_{i} \right)\ln p + \left( n - \sum_{i = 1}^{n}X_{i} \right)\ln{(1 - p)}\]
<p>Taking derivative of <span class="math notranslate nohighlight">\(\ln\mathcal{L}\)</span> w.r.t. <span class="math notranslate nohighlight">\(p\)</span> and we have</p>
<div class="math notranslate nohighlight">
\[\frac{\partial\ln\mathcal{L}}{\partial p} = 0 \Rightarrow \frac{\sum_{i = 1}^{n}X_{i}}{p} - \frac{n - \sum_{i = 1}^{n}X_{i}}{1 - p} = 0 \Rightarrow \widehat{p} = \frac{\sum_{i = 1}^{n}X_{i}}{n}\]
<p>meaning <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is a concave function w.r.t. <span class="math notranslate nohighlight">\(p\)</span>. Thus
<span class="math notranslate nohighlight">\(\widehat{p} = \frac{\sum_{i = 1}^{n}X_{i}}{n}\)</span> is indeed a
maximum for <span class="math notranslate nohighlight">\(p \in (0,1)\)</span>. It is easy to verify this holds for the
special cases when <span class="math notranslate nohighlight">\(p \in \{ 0,1\}\)</span>.</p>

<div class="section" id="the-poisson-variant">
<h4><strong>The Poisson Variant</strong><a class="headerlink" href="#the-poisson-variant" title="Permalink to this headline">¶</a></h4>
<p>We now start developing a slightly different version. In this version,
we allow every two nodes in the graph <span class="math notranslate nohighlight">\(G = (V,E)\)</span> to have multiple
edges, and we also allow self-loops, i.e. the graph is a <strong>multi-graph</strong>
or <strong>pseudo-graph</strong>. In this case, it is not appropriate to view
<span class="math notranslate nohighlight">\(E\)</span> as set, but it can be viewed as a
<span class="math notranslate nohighlight">\(E:V \times V\mathbb{\rightarrow N}\)</span> function, where
<span class="math notranslate nohighlight">\(E(u,v)\)</span> is the number of edges between <span class="math notranslate nohighlight">\(u,v\)</span>, and
“<span class="math notranslate nohighlight">\((u,v) \in E\)</span>” can be viewed as a notation for
<span class="math notranslate nohighlight">\(E\left( u,v \right) &gt; 0\)</span>, and
“<span class="math notranslate nohighlight">\(\left( u,v \right) \notin E\)</span>” means
<span class="math notranslate nohighlight">\(E\left( u,v \right) = 0\)</span>, and
<span class="math notranslate nohighlight">\(\left| E \right| = \sum_{u,v \in V}^{}{E(u,v)}\)</span>.</p>
<p>We keep <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> as the membership vector, but change the
meaning of stochastic block matrix <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>. If one node
<span class="math notranslate nohighlight">\(u\)</span> comes from group <span class="math notranslate nohighlight">\(i\)</span>, i.e. <span class="math notranslate nohighlight">\(\mathbf{z}_{u} = i\)</span>,
and the othe node <span class="math notranslate nohighlight">\(v\)</span> comes from group <span class="math notranslate nohighlight">\(j\)</span>, i.e.
<span class="math notranslate nohighlight">\(\mathbf{z}_{v}\mathbf{=}j\)</span>, then the number of edges between
<span class="math notranslate nohighlight">\(u,v\)</span> obeys Poisson distribution parameterized by
<span class="math notranslate nohighlight">\(\mathbf{P}(i,j)\)</span>. Recall the Poisson parameter is the mean of the
distribution, then<span class="math notranslate nohighlight">\(\mathbf{\ }\mathbf{P}(i,j)\)</span> is the mean of
number of edges between a node from group <span class="math notranslate nohighlight">\(i\)</span>, and a node from
group <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p>In comparison, recall that in the standard model, multi-edges and
self-loops are not allowed, and every model <span class="math notranslate nohighlight">\(\mathbf{P}(i,j)\)</span> is
the parameter of the Bernoulli experiments on edge formation between the
two groups. In the new setup, the probability of observing <span class="math notranslate nohighlight">\(E\)</span>
given <span class="math notranslate nohighlight">\(\mathbf{z},\mathbf{P}\)</span> becomes</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}\left( \mathbf{z},\mathbf{P} \right)\mathbb{= P}\left( E|\mathbf{z},\mathbf{P} \right) = \prod_{u,v \in V}^{}{\frac{\left( \mathbf{P}\left( z_{u},z_{v} \right) \right)^{E\left( u,v \right)}}{E\left( u,v \right)!}e^{- \mathbf{P}\left( z_{u},z_{v} \right)}} = \frac{1}{\prod_{u,v \in V}^{}{E\left( u,v \right)!}}\prod_{i,j \in \{ 1,\ldots,k\}}^{}{\left( \mathbf{P}\left( i,j \right) \right)^{e_{i,j}}e^{- n_{i,j}\mathbf{P}(i,j)}}\]
<p>Here <span class="math notranslate nohighlight">\(e_{i,j}\)</span> is the actual number of edges between group
<span class="math notranslate nohighlight">\(i\)</span> and group <span class="math notranslate nohighlight">\(j\)</span>, just as in the standard model, and
<span class="math notranslate nohighlight">\(n_{i,j}\)</span> is the maximum possible number of “unique edges” between
group <span class="math notranslate nohighlight">\(i\)</span> and group <span class="math notranslate nohighlight">\(j\)</span>, i.e.
<span class="math notranslate nohighlight">\(n_{i,j} = \left\{ \begin{matrix}
n_{i}n_{j} &amp; i \neq j \\
n_{i} + \begin{pmatrix}
n_{i} \\
2 \\
\end{pmatrix} &amp; i = j \\
\end{matrix} \right.\ \)</span> for undirected graphs and
<span class="math notranslate nohighlight">\(n_{i,j} = n_{i}n_{j}\)</span> for directed graphs, where <span class="math notranslate nohighlight">\(n_{i}\)</span> is
the number of nodes in group <span class="math notranslate nohighlight">\(i\)</span>. The formula for <span class="math notranslate nohighlight">\(n_{i,i}\)</span>
is slightly different from the standard model since we now allow
self-loops. Ignore the constant coefficient, and take the logarithm, we
have</p>
<div class="math notranslate nohighlight">
\[\ln\mathcal{L} = \sum_{i,j \in \{ 1,\ldots,k\}}^{}{e_{i,j}\ln{\mathbf{P}\left( i,j \right)} - n_{i,j}\mathbf{P}(i,j)}\]</div>
<p>Recall the meaning of <span class="math notranslate nohighlight">\(\mathbf{P}(i,j)\)</span> is the Poisson parameter
of the Poisson distribution of the number of edges between a node from
group <span class="math notranslate nohighlight">\(i\)</span> and a node from group <span class="math notranslate nohighlight">\(j\)</span>, then by EX 6 the MLE
for <span class="math notranslate nohighlight">\(\mathbf{P}(i,j)\)</span> is the average number of edges between a
node from group <span class="math notranslate nohighlight">\(i\)</span> and a node from group <span class="math notranslate nohighlight">\(j\)</span>, i.e.</p>
<div class="math notranslate nohighlight">
\[\widehat{\mathbf{P}}\left( i,j \right) = \frac{e_{i,j}}{n_{i,j}}\]</div>
<p>which is the same as the standard SBM. Again, just like what we did for
the standard, we can plug this back in <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> and have</p>
<div class="math notranslate nohighlight">
\[\ln\mathcal{L} = \sum_{i,j \in \{ 1,\ldots,k\}}^{}{e_{i,j}\ln\frac{e_{i,j}}{n_{i,j}} - n_{i,j}\frac{e_{i,j}}{n_{i,j}}} = \left( \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln\frac{e_{i,j}}{n_{i,j}}} \right) - \left( \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}e_{i,j} \right)\]</div>
<p>Note <span class="math notranslate nohighlight">\(\sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}e_{i,j} = |E|\)</span>
is the total number of edges in the graph, and hence a constant given
<span class="math notranslate nohighlight">\(E\)</span>, thus <span class="math notranslate nohighlight">\(\ln\mathcal{L}\)</span> can be further simplified as</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\ln\mathcal\]</div>
<p class="last">{L} = sum_{i,j in left{ 1,ldots,k ri
ght}}^{}{e_{i,j}lnfrac{e_{i,j}}{n_{i,j}
}}</p>
</td>
<td>&#160;</td>
<td>(17‑4)</td>
</tr>
</tbody>
</table>
<p>This is an even simpler form than the one in standard SBM. The
membership vector <span class="math notranslate nohighlight">\(z\)</span> can be inferred using the same coordinate
ascent process as <a class="reference external" href="file:///F:Machine%20Learning%2091.docx#SBM_coordiante_ascent">previously
described</a>,
with less time complexity as shown below. For directed graph
<span class="math notranslate nohighlight">\(n_{i,j} = n_{i}n_{j}\)</span></p>
<div class="math notranslate nohighlight">
\[\sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln\frac{e_{i,j}}{n_{i,j}}} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{i,j}} - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln n_{i}} - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln n_{j}} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{i,j}} - \sum_{i = 1}^{k}{\ln n_{i}\sum_{j = 1}^{k}e_{i,j}} - \sum_{j = 1}^{k}{\ln n_{j}\sum_{i = 1}^{k}e_{i,j}} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{i,j}} - \sum_{i = 1}^{k}{e_{i,*}\ln n_{i}} - \sum_{j = 1}^{k}{e_{*,j}\ln n_{j}}\]</div>
<p>When computing the maximum like, after an attempt of membership
re-assignment of some vertex <span class="math notranslate nohighlight">\(v\)</span> from group <span class="math notranslate nohighlight">\(r'\)</span> to group
<span class="math notranslate nohighlight">\(r\)</span>, the first term along with <span class="math notranslate nohighlight">\(e_{i,*},e_{*,j}\)</span> (just sums
of <span class="math notranslate nohighlight">\(e_{i,j}\)</span>) require only at most <span class="math notranslate nohighlight">\(\deg v\)</span> re-computations
of the addends, as shown
<a class="reference external" href="file:///F:Machine%20Learning%2091.docx#SBM_standard_time_complexity">earlier</a>;
the second term and the third term only requires updating
<span class="math notranslate nohighlight">\(n_{r^{'}},n_{r}\)</span>. Recall the culprit dragging down the time
complexity is <span class="math notranslate nohighlight">\(n_{i,j}\)</span> in the standard model, which is not
present in the above sum.</p>
<p>As a result, the time complexity for one membership re-assignment is at
most <span class="math notranslate nohighlight">\(O(k\deg v)\)</span> and the time complexity of one sweep of
coordinate ascent is decreased to
<span class="math notranslate nohighlight">\(O\left( k\left| E \right| \right)\)</span>. For a large graph where
<span class="math notranslate nohighlight">\(k \gg \frac{\left| E \right|}{|V|}\)</span>, we have
<span class="math notranslate nohighlight">\(O\left( k\left| E \right| \right) = O\left( k\frac{\left| E \right|}{\left| V \right|}\left| V \right| \right) \approx O(k\left| V \right|)\)</span>.</p>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">REMARK: Connection to KL-Divergence</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><p class="first">Given a set of vertexes <span class="math notranslate nohighlight">\(V\)</span>, suppose we know there are
<span class="math notranslate nohighlight">\(\left| E \right|\)</span> edges, and the edges are generated in the
following fashion: for the <span class="math notranslate nohighlight">\(i\)</span>th edge, randomly choose one
<span class="math notranslate nohighlight">\(\mathcal{U}_{i} \in V\)</span> and then randomly choose one
<span class="math notranslate nohighlight">\(\mathcal{V}_{i} \in V\)</span> where
<span class="math notranslate nohighlight">\(\mathcal{U}_{i},\mathcal{V}_{i}\)</span> are random variables and
<span class="math notranslate nohighlight">\(i = 1,\ldots,\left| E \right|\)</span>. Since it is pseudo-graph with
self-loops, then each choice of vertex can be assumed to have no
impact on other choices, i.e. all choices of vertexes are mutual
independent, then the generation of these edges are also independent
since mutual independence implies pairwise independence. Check that</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{U}_{1} = u_{1},\mathcal{V}_{1} =\]</div>
<p>v_{1},ldots,mathcal{U}_{m} = u_{m},mathcal{V}_{m} = v_{m} right)
= prod_{i = 1}^{m}{mathbb{P}left( mathcal{U}_{i} = u_{i} right)mathbb{P}left( mathcal{V}_{i} = v_{i} right)} = prod_{i = 1}^{m}{
mathbb{P}left( mathcal{U}_{i} = u_{i},mathcal{V}_{i} = v_{i} rig
ht)} = left( frac{1}{left| V right|^{2}} right)^{2}</p>
<p>Now randomly draw an edge <span class="math notranslate nohighlight">\(\mathcal{(U,V)}\)</span> from the generated
graph, it is easy to see
<span class="math notranslate nohighlight">\(\mathbb{P}\left( \mathcal{U =}u,\mathcal{V =}v \right) = \frac
{1}{\left| V \right|^{2}}\)</span>
due to independence. We know the vertexes and the total number of
edges <span class="math notranslate nohighlight">\(\left| E \right|\)</span>. When in addition we can observe
membership assignment
<span class="math notranslate nohighlight">\(\mathbf{z}\mathbf{= (}z_{1}\mathbf{,\ldots,}z_{|V|}\mathbf{)}\)</span>
where
<span class="math notranslate nohighlight">\(z_{i} \in \left\{ 1,\ldots,k \right\},\forall i = 1,\ldots,|V|
`,
then we will have the knowledge of
:math:`n_{i},\forall i = 1,\ldots,k\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{N} = \left( n_{i,j} \right)\)</span> where
<span class="math notranslate nohighlight">\(n_{i,j} = \sum_{u,v \in V}^{}\mathbb{I}_{z_{u} = i,z_{v} = j}\)</span>
is the number of all possible “unique” edges between group <span class="math notranslate nohighlight">\(i\)</span>
and group <span class="math notranslate nohighlight">\(j\)</span>. Note we assume the vertex membership
<span class="math notranslate nohighlight">\(\mathbf{z}\)</span> is independent from edge generation and sampling,
that is</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{ \begin{matrix}
\mathbb{P}\left( E|\mathbf{z} \right)\mathbb{= P(}E) \\
\mathbb{P}\left( \mathcal{U =}u,\mathcal{V =}v|\mathbf{z} \right)\\end{split}\]</div>
<dl class="docutils">
<dt>mathbb{= P}left( mathcal{U =}u,mathcal{V =}v right) \</dt>
<dd>mathbb{P}left( mathcal{U =}u,mathcal{V =}v,E|mathbf{z} right</dd>
<dt>)mathbb{= P}left( mathcal{U =}u,mathcal{V =}v,E right) \</dt>
<dd>end{matrix} right.</dd>
</dl>
<p>so then the probability of
<span class="math notranslate nohighlight">\(\mathcal{U \in}C_{i}\mathcal{,V \in}C_{j}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( z_{\mathcal{U}} = i,z_{\mathcal{V}} = j \m\]</div>
<p>iddle| mathbf{z} right) = sum_{u,v in V}^{}{mathbb{P}left( mat
hcal{U =}u,mathcal{V =}v,z_{u} = i,z_{v} = j middle| mathbf{z} ri
ght)} = sum_{u,v in V}^{}{mathbb{P}left( mathcal{U =}u,mathcal{
V =}v|mathbf{z} right)mathbb{I}_{z_{u} = i,z_{v} = j}} = sum_{u,v</p>
<blockquote>
<div>in V}^{}{mathbb{P}left( mathcal{U =}u,mathcal{V =}v right)mat</div></blockquote>
<dl class="docutils">
<dt>hbb{I}_{z_{u} = i,z_{v} = j}} = sum_{u,v in V}^{}{frac{1}{left| V</dt>
<dd>right|^{2}}mathbb{I}_{z_{u} = i,z_{v} = j}} = frac{n_{i,j}}{left</dd>
</dl>
<div class="line-block">
<div class="line">V right|^{2}}</div>
</div>
<p>If we further observe the entire edge set <span class="math notranslate nohighlight">\(E\)</span>, and hence have
the knowledge <span class="math notranslate nohighlight">\(\mathbf{E} = \left( e_{i,j} \right)\)</span> for all
<span class="math notranslate nohighlight">\(i,j\)</span>, where
<span class="math notranslate nohighlight">\(e_{i,j} = \sum_{(u,v) \in E}^{}{E\left( u,v \right)\mathbb{I}_
{z_{u} = i,z_{v} = j}}\)</span>
is the number of actual edges between group <span class="math notranslate nohighlight">\(i\)</span> and group
<span class="math notranslate nohighlight">\(j\)</span>. Note</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{U =}u,\mathcal{V =}v,z_{u} = i,z_\]</div>
<p>{v} = j middle| mathbf{z},E right) = 0,forallleft( u,v right) notin E</p>
<p>as well as by the assumption that <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> is independent
from <span class="math notranslate nohighlight">\(E,\mathcal{U,V}\)</span>
<a class="reference external" href="file:///F:Machine%20Learning%2091.docx#b207">above</a></p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{U =}u,\mathcal{V =}v|\mathbf{z},E
\right)\mathbb{= P}\left( \mathcal{U =}u,\mathcal{V =}v|E \right)\]</div>
<p>and use the fact that</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{U =}u,\mathcal{V =}v|E \right) =\]</div>
<p>frac{Eleft( u,v right)}{<a href="#id63"><span class="problematic" id="id64">|E|</span></a>}</p>
<p>then</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( z_{\mathcal{U}} = i,z_{\mathcal{V}} = j \m\]</div>
<p>iddle| mathbf{z},E right) = sum_{left( u,v right) in E}^{}{mat
hbb{P}left( mathcal{U =}u,mathcal{V =}v,z_{u} = i,z_{v} = j middl
e| mathbf{z},E right)} = sum_{left( u,v right) in E}^{}{mathbb
{P}left( mathcal{U =}u,mathcal{V =}v|mathbf{z},E right)mathbb{I
}_{z_{u} = i,z_{v} = j}} = sum_{left( u,v right) in E}^{}{mathbb
{P}left( mathcal{U =}u,mathcal{V =}v|E right)mathbb{I}_{z_{u} =
i,z_{v} = j}} = sum_{left( u,v right) in E}^{}{frac{Eleft( u,v
right)}{left| E right|}mathbb{I}_{z_{u} = i,z_{v} = j}} = frac{e
_{i,j}}{left| E right|}</p>
<p>Now rewrite (17‑4) as (adding those denominators is just scaling
<span class="math notranslate nohighlight">\(\ln\mathcal{L}\)</span>)</p>
<div class="math notranslate nohighlight">
\[\ln\mathcal{L} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}\]</div>
<p>^{}{frac{e_{i,j}}{<a href="#id65"><span class="problematic" id="id66">|E|</span></a>}lnfrac{frac{e_{i,j}}{<a href="#id67"><span class="problematic" id="id68">|E|</span></a>}}{frac{n_{i,j}}{left| V right|^{2}}}} = sum_{i,j in left{ 1,ldots,k right}}^{
}{mathbb{P}left( z_{mathcal{U}} = i,z_{mathcal{V}} = j middle| mathbf{z},E right)lnfrac{mathbb{P}left( z_{mathcal{U}} = i,z_{mathcal{V}} = j middle| mathbf{z},E right)}{mathbb{P}left( z_{m
athcal{U}} = i,z_{mathcal{V}} = j middle| mathbf{z} right)}}</p>
<p class="last">which is the KL-divergence between two distributions
<span class="math notranslate nohighlight">\(\mathbb{P}\left( z_{\mathcal{U}},z_{\mathcal{V}} \middle| \mat
hbf{z},E \right)\)</span>
and
<span class="math notranslate nohighlight">\(\mathbb{P}\left( z_{\mathcal{U}},z_{\mathcal{V}} \middle| \mat
hbf{z} \right)\)</span>.
Recall KL-divergence measures the distance between two distributions,
if the distance between
<span class="math notranslate nohighlight">\(\mathbb{P}\left( z_{\mathcal{U}},z_{\mathcal{V}} \middle| \mat
hbf{z},E \right)\)</span>
and
<span class="math notranslate nohighlight">\(\mathbb{P}\left( z_{\mathcal{U}},z_{\mathcal{V}} \middle| \mat
hbf{z} \right)\)</span>
is small, that means observation of <span class="math notranslate nohighlight">\(E\)</span> does not bring much new
information. Thus, the goal of optimizing the MLE over all possible
<span class="math notranslate nohighlight">\(\mathbf{z}\)</span> is equivalent to maximizing the “information gain”
of observing <span class="math notranslate nohighlight">\(E\)</span> given the above model.</p>
</td>
</tr>
</tbody>
</table>
<p>EX 6. Given i.i.d. sample <span class="math notranslate nohighlight">\(X_{1},\ldots,X_{n}\mathbb{\in N}\)</span>, show
the MLE for the parameter <span class="math notranslate nohighlight">\(\lambda\)</span> of a Poisson distribution
<span class="math notranslate nohighlight">\(\text{Poisson}(\lambda)\)</span> is
<span class="math notranslate nohighlight">\(\widehat{\lambda} = \frac{\sum_{i = 1}^{n}X_{i}}{n}\)</span>.</p>
<p>Key. The likelihood function is</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}\left( \lambda \right)\mathbb{= P}\left( X_{1},\ldots,X_{n} \middle| \lambda \right) = \prod_{i = 1}^{n}{\frac{\lambda^{X_{i}}}{X_{i}!}e^{- \lambda}} = \frac{1}{\prod_{i = 1}^{n}X_{i}}\prod_{i = 1}^{n}{\lambda^{X_{i}}e^{- \lambda}}\]</div>
<p>Ignore the coefficient <span class="math notranslate nohighlight">\(\frac{1}{\prod_{i = 1}^{n}X_{i}}\)</span> and take
logarithm of <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[\ln\mathcal{L} = \sum_{i = 1}^{n}\left( \left( X_{i}\ln\lambda \right) - \lambda \right) = \left( \ln\lambda\sum_{i = 1}^{n}X_{i} \right) - n\lambda\]</div>
<p>Thus</p>
<div class="math notranslate nohighlight">
\[\frac{\partial\ln\mathcal{L}}{\partial\lambda} = \frac{\sum_{i = 1}^{n}X_{i}}{\lambda} - n \Rightarrow \widehat{\lambda} = \frac{\sum_{i = 1}^{n}X_{i}}{n}\]</div>
<p>Taking second derivative of <span class="math notranslate nohighlight">\(\ln\mathcal{L}\)</span> w.r.t. <span class="math notranslate nohighlight">\(p\)</span> and
we have</p>
<div class="math notranslate nohighlight">
\[\frac{\partial^{2}\ln\mathcal{L}}{\partial\lambda^{2}} = - \left( \sum_{i = 1}^{n}X_{i} \right)\lambda^{- 2} - n &lt; 0\]</div>
<p>meaning <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is a concave function w.r.t.
<span class="math notranslate nohighlight">\(\lambda\)</span>. Thus
<span class="math notranslate nohighlight">\(\widehat{\lambda} = \frac{\sum_{i = 1}^{n}X_{i}}{n}\)</span> is indeed
the MLE for <span class="math notranslate nohighlight">\(\text{Poisson}(\lambda)\)</span>.</p>
</div>
<div class="section" id="degree-corrected-sbm">
<h4><strong>Degree Corrected SBM</strong><a class="headerlink" href="#degree-corrected-sbm" title="Permalink to this headline">¶</a></h4>
<p>We now introduce the degree-corrected SBM. It not only finds an MLE
model for the SBM, moreover it finds a model under which the expected
degrees of vertices are exactly the degrees observed in <span class="math notranslate nohighlight">\(E\)</span>, and
thus “better fit” (although possibly over-fit) the data.</p>
<p>Randomly draw one edge <span class="math notranslate nohighlight">\(\mathcal{(U,V)}\)</span> from <span class="math notranslate nohighlight">\(E\)</span>, then
<span class="math notranslate nohighlight">\(U,V\)</span> are both random variables ranging over <span class="math notranslate nohighlight">\(V\)</span>. For
directed graph, we have
<span class="math notranslate nohighlight">\(\mathbb{P}\left( \mathcal{U =}u \middle| E \right) = \frac{\operatorname{}u}{|E|}\)</span>
and
<span class="math notranslate nohighlight">\(\mathbb{P}\left( \mathcal{V =}v \middle| E \right) = \frac{\operatorname{}v}{|E|}\)</span>,
where <span class="math notranslate nohighlight">\(\operatorname{}u\)</span> is the out-degree of <span class="math notranslate nohighlight">\(u\)</span> and
<span class="math notranslate nohighlight">\(\operatorname{}v\)</span> is the in-degree of <span class="math notranslate nohighlight">\(v\)</span>. Recall we use
<span class="math notranslate nohighlight">\(C_{i},i = 1,\ldots,k\)</span> to denote the set of vertexes in group
<span class="math notranslate nohighlight">\(i\)</span>. Note
<span class="math notranslate nohighlight">\(\sum_{x \in C_{z_{u}}}^{}{\operatorname{}x} = \sum_{j = 1,\ldots,k}^{}e_{z_{u},j}\)</span>,
and we further have</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{U =}u \middle| z_{\mathcal{U}} = z_{u},E \right) = \frac{\operatorname{}u}{\sum_{x \in C_{z_{u}}}^{}{\operatorname{}x}} = \frac{\operatorname{}u}{\sum_{j = 1,\ldots,k}^{}e_{z_{u},j}}\]</div>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{V =}v \middle| z_{V} = z_{v},E \right) = \frac{\operatorname{}v}{\sum_{x \in C_{z_{v}}}^{}{\operatorname{}x}} = \frac{\operatorname{}v}{\sum_{i = 1,\ldots,k}^{}e_{i,z_{v}}}\]</div>
<p>For undirected graph, we do not distinguish start point and end point,
and we
have<span class="math notranslate nohighlight">\(\mathbb{\text{\ P}}\left( U = v \middle| E \right)\mathbb{= P}\left( V = v \middle| E \right) = \frac{\deg v}{2|E|}\)</span>
and</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( U = v \middle| z_{U} = z_{v},E \right)\mathbb{= P}\left( V = v \middle| z_{V} = z_{v},E \right) = \frac{\deg v}{\sum_{x \in C_{z_{v}}}^{}{\deg x}} = \frac{\deg v}{\sum_{j = 1,\ldots,k}^{}e_{z_{v},j}}\]</div>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( U = v \middle| z_{U} = z_{v},E \right)\mathbb{= P}\left( V = v \middle| z_{V} = z_{v},E \right) = \frac{\deg v}{\sum_{x \in C_{z_{v}}}^{}{\deg x}} = \frac{\deg v}{\sum_{j = 1,\ldots,k}^{}e_{z_{v},j}}\]</div>
<p>For generality, we mainly consider directed graph and the result
immediately extends to undirected graph. For simplicity, denote</p>
<div class="math notranslate nohighlight">
\[e_{i, \cdot} = \sum_{j = 1}^{k}e_{i,j} = \sum_{x \in C_{i}}^{}{\operatorname{}x} = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\mathbb{I}_{z_{u} = i}}\]</div>
<div class="math notranslate nohighlight">
\[e_{\cdot ,j} = \sum_{i = 1}^{k}e_{i,j} = \sum_{x \in C_{z_{v}}}^{}{\operatorname{}x} = \sum_{v \in V}^{}{\left( \operatorname{}v \right)\mathbb{I}_{z_{v} = i}}\]</div>
<p>as the total out-degree of nodes in group <span class="math notranslate nohighlight">\(i\)</span> and the total
in-degree of nodes in group <span class="math notranslate nohighlight">\(i\)</span> respectively. Now given two nodes
<span class="math notranslate nohighlight">\(u,v\)</span>, we assume
<span class="math notranslate nohighlight">\(E\left( u,v \right)\sim Poisson(\theta_{u}^{\left( o \right)}\theta_{v}^{(i)}\mathbf{P}(z_{u},z_{v}))\)</span>
where</p>
<div class="math notranslate nohighlight">
\[\theta_{u}^{\left( o \right)}\mathbb{= P}\left( U = u \middle| z_{U} = z_{u},E \right) = \frac{\operatorname{}u}{e_{z_{u}, \cdot}},\theta_{v}^{(i)}\mathbb{= P}\left( V = v \middle| z_{V} = z_{v},E \right) = \frac{\operatorname{}v}{e_{\cdot ,z_{v}}}\]</div>
<p>Recall in previous setup,
<span class="math notranslate nohighlight">\(\mathbb{E}\left\lbrack E\left( u,v \right) \right\rbrack = \mathbf{P}(z_{u},z_{v})\)</span>,
i.e. the expected number of edges between every pair of nodes in
<span class="math notranslate nohighlight">\(C_{i} \times C_{j}\)</span> will all equal to <span class="math notranslate nohighlight">\(\mathbf{P}(i,j)\)</span>. In
the new setup, this expectation is not constant across
<span class="math notranslate nohighlight">\(C_{i} \times C_{j}\)</span> because they are also dependent on
node-specific degree information. Now the likelihood is</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}\left( \mathbf{z},\mathbf{P} \right)\mathbb{= P}\left( E|\mathbf{z},\mathbf{P} \right) = \prod_{u,v \in V}^{}{\frac{\left( \theta_{u}^{\left( o \right)}\theta_{v}^{(i)}\mathbf{P}\left( z_{u},z_{v} \right) \right)^{E\left( u,v \right)}}{E\left( u,v \right)!}\exp\left( - \theta_{u}^{\left( o \right)}\theta_{v}^{\left( i \right)}\mathbf{P}\left( z_{u},z_{v} \right) \right)} = \frac{1}{\prod_{u,v \in V}^{}{E\left( u,v \right)!}}\prod_{u \in V}^{}\left( \theta_{u}^{\left( o \right)} \right)^{\operatorname{}u}\prod_{v \in V}^{}\left( \theta_{v}^{\left( i \right)} \right)^{\operatorname{}v}\prod_{i,j \in \{ 1,\ldots,k\}}^{}\left( \mathbf{P}\left( i,j \right) \right)^{e_{i,j}}\prod_{u,v \in V}^{}{\exp\left( - \theta_{u}^{\left( o \right)}\theta_{v}^{\left( i \right)}\mathbf{P}\left( z_{u},z_{v} \right) \right)}\]</div>
<p>As before, dropping the coefficient and take logarithm, and we have</p>
<div class="math notranslate nohighlight">
\[\ln\mathcal{L} = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln\theta_{u}^{\left( o \right)}} + \sum_{v \in V}^{}{\left( \operatorname{}v \right)\ln\theta_{v}^{\left( i \right)}} + \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}\left( e_{i,j}\ln{\mathbf{P}\left( i,j \right)} - \mathbf{P}(i,j) \right)\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\ln{\prod_{u,v \in V}^{}e^{- \theta_{u}^{\left( o \right)}\theta_{v}^{(i)}\mathbf{P}\left( z_{u},z_{v} \right)}} = - \sum_{u,v \in V}^{}{\theta_{u}^{\left( o \right)}\theta_{v}^{\left( i \right)}\mathbf{P}\left( z_{u},z_{v} \right)} = - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{\sum_{u \in C_{i}}^{}{\sum_{v \in C_{j}}^{}{\theta_{u}^{\left( o \right)}\theta_{v}^{\left( i \right)}\mathbf{P}\left( i,j \right)}}} = - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{\mathbf{P}\left( i,j \right)\sum_{u \in C_{i}}^{}\theta_{u}^{\left( o \right)}\sum_{v \in C_{j}}^{}\theta_{v}^{\left( i \right)}} = - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{\mathbf{P}\left( i,j \right)}\]</div>
<p>since
<span class="math notranslate nohighlight">\(\sum_{u \in C_{i}}^{}\theta_{u}^{\left( o \right)} = \sum_{u \in C_{i}}^{}\frac{\operatorname{}u}{\sum_{x \in C_{i}}^{}{\operatorname{}x}} = 1\)</span>
and <span class="math notranslate nohighlight">\(\sum_{v \in C_{j}}^{}\theta_{v}^{\left( i \right)} = 1\)</span> as
well. Now it is easy to see</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left\{ \begin{matrix}
\frac{\partial\ln\mathcal{L}}{\partial\mathbf{P}(i,j)} = 0 \Rightarrow \frac{e_{i,j}}{\mathbf{P}\left( i,j \right)} = 1 \\
\frac{\partial^{2}\ln\mathcal{L}}{\partial\left( \mathbf{P}\left( i,j \right) \right)^{2}} = - e_{i,j}\mathbf{P}^{- 2}\left( i,j \right) &lt; 0 \\
\end{matrix} \right.\  \Rightarrow \widehat{\mathbf{P}}\left( i,j \right) = e_{i,j}\end{split}\]</div>
<p>Plug this back into <span class="math notranslate nohighlight">\(\ln\mathcal{L}\)</span> and dropped the last constant
term <span class="math notranslate nohighlight">\(\sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}e_{i,j} = |E|\)</span>,
then</p>
<div class="math notranslate nohighlight">
\[\ln\mathcal{L} = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln\theta_{u}^{\left( o \right)}} + \sum_{v \in V}^{}{\left( \operatorname{}v \right)\ln\theta_{v}^{\left( i \right)}} + \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{i,j}}\]</div>
<p>We now legitimize our above choice of</p>
<div class="math notranslate nohighlight">
\[\theta_{u}^{\left( o \right)} = \frac{\operatorname{}u}{\sum_{x \in C_{z_{u}}}^{}{\operatorname{}x}},\theta_{v}^{(i)} = \frac{\operatorname{}v}{\sum_{x \in C_{z_{v}}}^{}{\operatorname{}x}}\]</div>
<p>by showing <span class="math notranslate nohighlight">\(\theta_{u}^{\left( o \right)},\theta_{v}^{(i)}\)</span> are
actually the MLE of <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> with restriction
<span class="math notranslate nohighlight">\(\sum_{u \in C_{i}}^{}\theta_{u}^{\left( o \right)} = 1,\forall i = 1,\ldots,k\)</span>
and
<span class="math notranslate nohighlight">\(\sum_{v \in C_{j}}^{}\theta_{v}^{\left( i \right)} = 1,\forall j = 1,\ldots,k\)</span>.
To see this, for every <span class="math notranslate nohighlight">\(i \in 1,\ldots,k\)</span>, using Lagrange
multiplier <span class="math notranslate nohighlight">\(\lambda\)</span> for the summation over <span class="math notranslate nohighlight">\(u \in C_{i}\)</span>
and then taking derivative w.r.t. <span class="math notranslate nohighlight">\(\theta_{u}^{\left( o \right)}\)</span>
for every <span class="math notranslate nohighlight">\(u \in C_{i}\)</span>, we have the following,</p>
<div class="math notranslate nohighlight">
\[\sum_{u \in C_{i}}^{}{\left( \operatorname{}u \right)\ln\theta_{u}^{\left( o \right)}} = \lambda\left( \sum_{u \in C_{i}}^{}\theta_{u}^{\left( o \right)} - 1 \right) \Rightarrow \frac{\operatorname{}u}{\theta_{u}^{\left( o \right)}} = \lambda,\forall u \in C_{i} \Rightarrow \sum_{u \in C_{z_{u}}}^{}{\operatorname{}u} = \lambda\sum_{u \in C_{z_{u}}}^{}\theta_{u}^{\left( o \right)} = \lambda \Rightarrow \frac{\operatorname{}u}{\theta_{u}^{\left( o \right)}} = \sum_{u \in C_{z_{u}}}^{}{\operatorname{}u} \Rightarrow \widehat{\theta_{u}^{\left( o \right)}} = \frac{\operatorname{}u}{\sum_{u \in C_{z_{u}}}^{}{\operatorname{}u}}\]</div>
<p>Proof for
<span class="math notranslate nohighlight">\(\widehat{\theta_{v}^{\left( i \right)}} = \frac{\operatorname{}v}{\sum_{x \in C_{z_{v}}}^{}{\operatorname{}x}}\)</span>
is the same. Now we do further simplification as the following, note
<span class="math notranslate nohighlight">\(e_{i, \cdot} = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\mathbb{I}_{z_{u} = i}}\)</span>
as well</p>
<div class="math notranslate nohighlight">
\[\sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln\theta_{u}^{\left( o \right)}} = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln\frac{\operatorname{}u}{e_{z_{u}, \cdot}}} = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln{\operatorname{}u}} - \sum_{u \in V}^{}{\left( \operatorname{}u \right)\left( \ln e_{z_{u}, \cdot} \right)} = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln{\operatorname{}u}} - \sum_{u \in V}^{}{\left( \operatorname{}u \right)\sum_{i = 1}^{k}{\mathbb{I}_{z_{u} = i}\left( \ln e_{i, \cdot} \right)}} = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln{\operatorname{}u}} - \sum_{u \in V}^{}{\sum_{i = 1}^{k}{\left( \operatorname{}u \right)\mathbb{I}_{z_{u} = i}\ln e_{i, \cdot}}} = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln{\operatorname{}u}} - \sum_{i = 1}^{k}\left( \ln e_{i, \cdot}\sum_{u \in V}^{}{\left( \operatorname{}u \right)\mathbb{I}_{z_{u} = i}} \right) = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln{\operatorname{}u}} - \sum_{i = 1}^{k}{e_{i, \cdot}\ln e_{i, \cdot}}\]</div>
<p>Similarly,</p>
<div class="math notranslate nohighlight">
\[\sum_{v \in V}^{}{\left( \operatorname{}v \right)\ln\theta_{v}^{\left( i \right)}} = \sum_{v \in V}^{}{\left( \operatorname{}v \right)\ln{\operatorname{}v}} - \sum_{v \in V}^{}{\left( \operatorname{}v \right)\left( \ln e_{\cdot ,z_{v}} \right)} = \sum_{v \in V}^{}{\left( \operatorname{}v \right)\ln{\operatorname{}v}} - \sum_{j = 1}^{k}{e_{\cdot ,j}\ln e_{\cdot ,j}}\]</div>
<p>As a result</p>
<div class="math notranslate nohighlight">
\[\sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln\theta_{u}^{\left( o \right)}} + \sum_{v \in V}^{}{\left( \operatorname{}v \right)\ln\theta_{v}^{\left( i \right)}} = \sum_{u \in V}^{}{\left( \operatorname{}u \right)\ln{\operatorname{}u}} + \sum_{v \in V}^{}{\left( \operatorname{}v \right)\ln{\operatorname{}v}} - \sum_{i = 1}^{k}{e_{i, \cdot}\ln e_{i, \cdot}} - \sum_{j = 1}^{k}{e_{\cdot ,j}\ln e_{\cdot ,j}} = \left( \sum_{v \in V}^{}{\left( \operatorname{}v \right)\ln{\operatorname{}v} + \left( \operatorname{}v \right)\ln{\operatorname{}v}} \right) - \sum_{i = 1}^{k}{e_{i, \cdot}\ln e_{i, \cdot}} - \sum_{j = 1}^{k}{e_{\cdot ,j}\ln e_{\cdot ,j}}\]</div>
<p>Plug above back into <span class="math notranslate nohighlight">\(\ln\mathcal{L}\)</span> and note the first term of
above equation is a constant given the edge set <span class="math notranslate nohighlight">\(E\)</span>, so it can be
dropped, then</p>
<div class="math notranslate nohighlight">
\[\ln\mathcal{L} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{i,j}} - \sum_{i = 1}^{k}{e_{i, \cdot}\ln e_{i, \cdot}} - \sum_{j = 1}^{k}{e_{\cdot ,j}\ln e_{\cdot ,j}}\]</div>
<p>Last, observe that</p>
<div class="math notranslate nohighlight">
\[\sum_{i = 1}^{k}{e_{i, \cdot}\ln e_{i, \cdot}} = \sum_{i = 1}^{k}\left( \left( \sum_{j = 1}^{k}e_{i,j} \right)\ln e_{i, \cdot} \right) = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{i, \cdot}}\]</div>
<p>and similarly,
<span class="math notranslate nohighlight">\(\sum_{j = 1}^{k}{e_{\cdot ,j}\ln e_{\cdot ,j}} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{\cdot ,j}}\)</span>,
then finally</p>
<div class="math notranslate nohighlight">
\[\ln\mathcal{L} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{i,j}} - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{i,*}} - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{*,j}} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln e_{i,j}} - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln{e_{i,*}e_{*,j}}} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln\frac{e_{i,j}}{e_{i,*}e_{*,j}}}\]</div>
<p>That is our final log-likelihood function has a very simple form. In
comparison with (17‑4) the only difference is the numerator of the
logarithm “<span class="math notranslate nohighlight">\(n_{i,j}\)</span>” is replaced by
“<span class="math notranslate nohighlight">\(e_{i,*}e_{*,j}\)</span>”.</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\ln\mathcal\]</div>
<p class="last">{L} = sum_{i,j in left{ 1,ldots,k ri
ght}}^{}{e_{i,j}lnfrac{e_{i,j}}{e_{i,*}
e_{<a href="#id53"><span class="problematic" id="id54">*</span></a>,j}}}</p>
</td>
<td>&#160;</td>
<td>(17‑5)</td>
</tr>
</tbody>
</table>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><p class="first">This equation also has a KL-divergence interpretation (see earlier
<a class="reference external" href="file:///F:Machine%20Learning%2091.docx#REMARK_Connection_to_KL_Divergence">remark</a>).
Suppose we cannot observe <span class="math notranslate nohighlight">\(E\)</span> but instead degrees of each node,
denoted by <span class="math notranslate nohighlight">\(D\)</span>. Then given the fact that</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \mathcal{U =}u,\mathcal{V =}v|D \right) =\]</div>
<p>frac{operatorname{}u}{sum_{x in V}^{}{operatorname{}x}}frac{op
eratorname{}v}{sum_{x in V}^{}{operatorname{}x}}</p>
<p>Then</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( z_{\mathcal{U}} = i,z_{\mathcal{V}} = j \m\]</div>
<p>iddle| mathbf{z},D right) = sum_{u,v in V}^{}{mathbb{P}left( m
athcal{U =}u,mathcal{V =}v,z_{u} = i,z_{v} = j middle| mathbf{z},D</p>
<blockquote>
<div>right)} = sum_{u,v in V}^{}{mathbb{P}left( mathcal{U =}u,math</div></blockquote>
<p>cal{V =}v|D right)mathbb{I}_{z_{u} = i,z_{v} = j}} = sum_{u in <a href="#id85"><span class="problematic" id="id86">C_</span></a>
{i},v in C_{j}}^{}{frac{operatorname{}u}{sum_{x in V}^{}{operat
orname{}x}}frac{operatorname{}v}{sum_{x in V}^{}{operatorname{}x
}}} = sum_{u in C_{i}}^{}left( frac{operatorname{}u}{sum_{x in</p>
<blockquote>
<div>V}^{}{operatorname{}x}}sum_{v in C_{j}}^{}frac{operatorname{}v}</div></blockquote>
<p>{sum_{x in V}^{}{operatorname{}x}} right) = frac{e_{i,*}}{sum_{
x in V}^{}{operatorname{}x}}frac{e_{<a href="#id55"><span class="problematic" id="id56">*</span></a>,j}}{sum_{x in V}^{}{opera
torname{}x}}</p>
<p>Thus, we can re-write (17‑5) as</p>
<div class="math notranslate nohighlight">
\[\ln\mathcal{L} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}\]</div>
<p>^{}{frac{e_{i,j}}{<a href="#id69"><span class="problematic" id="id70">|E|</span></a>}lnfrac{frac{e_{i,j}}{left| E right|}}{fr
ac{e_{i,*}}{sum_{x in V}^{}{operatorname{}x}}frac{e_{<a href="#id57"><span class="problematic" id="id58">*</span></a>,j}}{sum_{
x in V}^{}{operatorname{}x}}}} = sum_{i,j in left{ 1,ldots,k right}}^{}{mathbb{P}left( z_{mathcal{U}} = i,z_{mathcal{V}} = j
middle| mathbf{z},E right)lnfrac{mathbb{P}left( z_{mathcal{U}
} = i,z_{mathcal{V}} = j middle| mathbf{z},E right)}{mathbb{P}l
eft( z_{mathcal{U}} = i,z_{mathcal{V}} = j middle| mathbf{z},D r
ight)}}</p>
<p class="last">Now the degree-corrected model is maximizing the “information gain”
of observing the whole edge set <span class="math notranslate nohighlight">\(E\)</span> over observing just the
degree information <span class="math notranslate nohighlight">\(D\)</span>.</p>
</td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><strong>Property</strong> <strong>17‑1</strong> The expected number of edges between group
<span class="math notranslate nohighlight">\(i\)</span> and group <span class="math notranslate nohighlight">\(j\)</span> for graphs generated by the
degree-corrected Poisson SBM is
<span class="math notranslate nohighlight">\(\mathbb{E}e_{i,j}\mathbf{= P}(i,j)\)</span>, since</li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbb{E}e_{i,j} = \sum_{u \in C_{i},v \in C_{j}}^{}{\mathbb{E\lbrack}E(u,v)\rbrack} = \sum_{u \in C_{i},v \in C_{j}}^{}{\theta_{u}^{\left( o \right)}\theta_{v}^{\left( i \right)}\mathbf{P}(i,j)} = \mathbf{P}(i,j)\]</div>
<ul class="simple">
<li><strong>Property</strong> <strong>17‑2</strong> The expected out-degree or in-degree of a
vertex <span class="math notranslate nohighlight">\(v\)</span> for graphs generated by the degree-corrected Poisson
SBM is
<span class="math notranslate nohighlight">\(\mathbb{E}\left\lbrack \operatorname{}v \right\rbrack = \theta_{u}^{\left( o \right)}\sum_{j = 1,\ldots,k}^{}{\mathbf{P}(z_{u},j)}\)</span>
and
<span class="math notranslate nohighlight">\(\mathbb{E}\left\lbrack \operatorname{}v \right\rbrack = \theta_{v}^{\left( i \right)}\sum_{j = 1,\ldots,k}^{}{\mathbf{P}(i,z_{v})}\)</span>,
since</li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left\lbrack \operatorname{}u \right\rbrack = \sum_{v \in V}^{}{\theta_{u}^{\left( o \right)}\theta_{v}^{\left( i \right)}\mathbf{P}(z_{u},z_{v})} = \theta_{u}^{\left( o \right)}\sum_{j = 1,\ldots,k}^{}{\sum_{v \in C_{i}}^{}{\theta_{v}^{\left( i \right)}\mathbf{P}(z_{u},j)}} = \theta_{u}^{\left( o \right)}\sum_{j = 1,\ldots,k}^{}{\mathbf{P}(z_{u},j)}\]</div>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left\lbrack \operatorname{}v \right\rbrack = \sum_{u \in V}^{}{\theta_{u}^{\left( o \right)}\theta_{v}^{\left( i \right)}\mathbf{P}(z_{u},z_{v})} = \theta_{v}^{\left( i \right)}\sum_{j = 1,\ldots,k}^{}{\sum_{u \in C_{i}}^{}{\theta_{u}^{\left( o \right)}\mathbf{P}(i,z_{v})}} = \theta_{v}^{\left( i \right)}\sum_{j = 1,\ldots,k}^{}{\mathbf{P}(i,z_{v})}\]</div>
<p>As a special case, for the MLE model we have
<span class="math notranslate nohighlight">\(\mathbb{E}\left\lbrack \operatorname{}u \right\rbrack = \operatorname{}{\lbrack u|E\rbrack}\mathbb{,E}\left\lbrack \operatorname{}v \right\rbrack = \operatorname{}{\lbrack v|E\rbrack}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left\lbrack \operatorname{}u \right\rbrack = \frac{\operatorname{}{\lbrack u|E\rbrack}}{\sum_{u \in C_{z_{u}}}^{}{\operatorname{}{\lbrack u|E\rbrack}}}\sum_{j = 1,\ldots,k}^{}{\lbrack e_{z_{u},j}|E\rbrack} = \operatorname{}{\lbrack u|E\rbrack}\]</div>
<div class="math notranslate nohighlight">
\[\mathbb{E}\left\lbrack \operatorname{}v \right\rbrack = \frac{\operatorname{}{\lbrack v|E\rbrack}}{\sum_{x \in C_{z_{v}}}^{}{\operatorname{}{\lbrack x|E\rbrack}}}\sum_{i = 1,\ldots,k}^{}{\lbrack e_{i,z_{v}}|E\rbrack} = \operatorname{}{\lbrack v|E\rbrack}\]</div>
<p>where we use <span class="math notranslate nohighlight">\(\lbrack \cdot |E\rbrack\)</span> to denote an object or
quantity from the observation of <span class="math notranslate nohighlight">\(E\)</span>. Thus, the degree corrected
model not only just finds an MLE model, moreover it finds a model under
which the expected degrees are exactly the degrees observed in
<span class="math notranslate nohighlight">\(E\)</span>.</p>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">INTUITION</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><p class="first">The main purpose of degree correction is to prevent “weakly
connected” vertexes of large degrees to be clustered together. For
real-world networks, in most situations, such weakly connected
large-degree nodes is intuitively more likely to be placed in
different groups. For example, in social network, avid supporters of
two different political opinions might occasionally exchange some
words, but they still belong to two groups.</p>
<p>Consider the standard models without degree correction, where the
expected number of edges between two groups are completely controlled
by <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> when <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> is fixed. Suppose we
are currently reassigning the membership of a high-degree node
<span class="math notranslate nohighlight">\(u\)</span>, and <span class="math notranslate nohighlight">\(u\)</span> has an edge <span class="math notranslate nohighlight">\((u,v)\)</span> where <span class="math notranslate nohighlight">\(v\)</span> is
also a high-degree node. Assignment of some <span class="math notranslate nohighlight">\(z_{u} \neq z_{v}\)</span>
will have high impact on <span class="math notranslate nohighlight">\(\mathbf{P}(z_{u}, \cdot )\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{P}( \cdot ,z_{u})\)</span> since it introduces many edges to
the group <span class="math notranslate nohighlight">\(C_{z_{u}}\)</span>. This would sometimes make the
observations of other edges from or into <span class="math notranslate nohighlight">\(C_{z_{u}}\)</span> become
less likely, and therefore the maximization might suggest
<span class="math notranslate nohighlight">\(z_{u} = z_{v}\)</span>. Once the high-degree node <span class="math notranslate nohighlight">\(u\)</span> is
assigned to <span class="math notranslate nohighlight">\(z_{v}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{P}(z_{v}, \cdot )\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{P}( \cdot ,z_{v})\)</span> will be adjusted to be more
accommodating to large-degree nodes (e.g. many numbers in
both<span class="math notranslate nohighlight">\(\mathbf{\text{\ P}}(z_{v}, \cdot )\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{P}( \cdot ,z_{v})\)</span> will increase), and hence absorb
even more large-degree nodes in the future and expels low-degree
nodes from the group. As a result, high-degree nodes will form a
group itself in the long run.</p>
<p>In the degree-corrected version, it is the same that assigning
<span class="math notranslate nohighlight">\(u\)</span> to <span class="math notranslate nohighlight">\(z_{u} \neq z_{v}\)</span> will introduce many
<span class="math notranslate nohighlight">\((u,w)\)</span> or <span class="math notranslate nohighlight">\((w,u)\)</span> edges to group <span class="math notranslate nohighlight">\(z_{u}\)</span>, but the
additional relatively large factor
“<span class="math notranslate nohighlight">\(\theta_{u}^{\left( \text{out} \right)}\)</span>” in
“<span class="math notranslate nohighlight">\(\theta_{u}^{\left( \text{out} \right)}\theta_{w}^{\left( \t
ext{in} \right)}\mathbf{P}\left( z_{u},z_{w} \right)\)</span>”
and “<span class="math notranslate nohighlight">\(\theta_{u}^{\left( \text{out} \right)}\)</span>” in
“<span class="math notranslate nohighlight">\(\theta_{w}^{\left( \text{out} \right)}\theta_{\text{in}}^{\
left( \text{in} \right)}\mathbf{P}\left( z_{w},z_{u} \right)\)</span>”
mitigate the impact of <span class="math notranslate nohighlight">\(u\)</span> and hence the adjustment of
<span class="math notranslate nohighlight">\(\mathbf{P}\left( z_{u}, \cdot \right)\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{P}\left( \cdot ,z_{u} \right)\)</span> will be less
significant, which in turn has less influence on other edges, and
hence “<span class="math notranslate nohighlight">\(z_{u} \neq z_{v}\)</span>” becomes more likely in
comparison to the standard models. Even if the maximization decides
<span class="math notranslate nohighlight">\(z_{u} = z_{v}\)</span>, similarly due to the relatively large factor
“<span class="math notranslate nohighlight">\(\theta_{u}^{\left( \text{out} \right)}\theta_{v}^{\left( \t
ext{in} \right)}\)</span>”
in
“<span class="math notranslate nohighlight">\(\theta_{u}^{\left( \text{out} \right)}\theta_{v}^{\left( \t
ext{in} \right)}\mathbf{P}\left( z_{u},z_{v} \right)\)</span>”,
the change of <span class="math notranslate nohighlight">\(\mathbf{P}\left( z_{v}, \cdot \right)\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{P}\left( \cdot ,z_{v} \right)\)</span> will also be less
significant.</p>
<p class="last">For a concrete example, consider</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="the-entropy-interpretation-of-sbm">
<h4><strong>The Entropy Interpretation of SBM</strong><a class="headerlink" href="#the-entropy-interpretation-of-sbm" title="Permalink to this headline">¶</a></h4>
<p>We start with simple graphs where no multiple edges and self-loops are
allowed. Let <span class="math notranslate nohighlight">\(\Omega_{i,j}\)</span> denote the set of all possible edge
sets between group <span class="math notranslate nohighlight">\(i\)</span> and group <span class="math notranslate nohighlight">\(j\)</span>, and let <span class="math notranslate nohighlight">\(\Omega\)</span>
denote the sample space of the SBM model, i.e. the set of all different
possible <span class="math notranslate nohighlight">\(E\)</span>, then use <span class="math notranslate nohighlight">\(\Omega|X\)</span> denote the subspace
conditioned on <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>Given membership <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> and
<span class="math notranslate nohighlight">\(\mathbf{E} = \left( e_{i,j} \right)\)</span>, the number of all possible
edges sets between group <span class="math notranslate nohighlight">\(i\)</span> and group <span class="math notranslate nohighlight">\(j\)</span> is denoted as
<span class="math notranslate nohighlight">\(\mathcal{E}_{i,j} = |\Omega_{i,j}| = \begin{pmatrix}
n_{i,j} \\
e_{i,j} \\
\end{pmatrix}\)</span>, and the number of different graphs conditioned by
<span class="math notranslate nohighlight">\(\mathbf{z},\mathbf{E}\)</span> is denoted as</p>
<div class="math notranslate nohighlight">
\[\mathcal{E =}\left| \left( \Omega \middle| \mathbf{z},\mathbf{E} \right) \right| = \prod_{i,j \in \{ 1,\ldots,k\}}^{}\mathcal{E}_{i,j}\]</div>
<p>Check the standard model and (17‑1) again and verify that every graph in
<span class="math notranslate nohighlight">\(\Omega|\mathbf{z},\mathbf{E}\)</span> has equal probability
<span class="math notranslate nohighlight">\(\mathbb{P}\left( E \middle| \mathbf{z},\mathbf{E} \right) = \prod_{i,j \in \{ 1,\ldots,k\}}^{}{{\mathbf{P}(i,j)}^{e_{i,j}}\left( 1 - \mathbf{P}(i,j) \right)^{n_{i,j} - e_{i,j}}}\)</span>
regardless of the values of <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>.</p>
<ul class="simple">
<li><strong>Lemma</strong> <strong>17‑1</strong> <span class="math notranslate nohighlight">\(\ln\begin{pmatrix}
n \\
m \\
\end{pmatrix} = nH\left( \frac{m}{n} \right) + O(n)\)</span> as
<span class="math notranslate nohighlight">\(m \rightarrow \infty,n \rightarrow \infty,\frac{m}{n} \rightarrow 0\)</span>,
where <span class="math notranslate nohighlight">\(H\)</span> is the binary entropy function
<span class="math notranslate nohighlight">\(H\left( x \right) = - x\ln x - \left( 1 - x \right)\ln{(1 - x)}\)</span>.
It is not hard to verify
<span class="math notranslate nohighlight">\(\frac{m}{n} \rightarrow 0 \Longleftrightarrow n - m \rightarrow \infty\)</span>
through <span class="math notranslate nohighlight">\(\epsilon\)</span>-argument, then by Stirling’s formula,</li>
</ul>
<div class="math notranslate nohighlight">
\[\ln\left( \frac{n}{m} \right)\sim\ln\frac{\sqrt{2\pi n}\left( \frac{n}{e} \right)^{n}}{\sqrt{2\pi m}\left( \frac{m}{e} \right)^{m}\sqrt{2\pi\left( n - m \right)}\left( \frac{n - m}{e} \right)^{n - m}}\  = \ln\left( \sqrt{\frac{n}{2\pi m\left( n - m \right)}}\frac{n^{n}e^{m}e^{n - m}}{m^{m}e^{n}\left( n - m \right)^{n - m}} \right) = \frac{1}{2}\left( \ln n - \ln m - \ln\left( n - m \right) - \ln{2\pi} \right) + n\ln n - m\ln m - \left( n - m \right)\ln{(n - m)}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\frac{1}{2}\left( \ln n - \ln m - \ln\left( n - m \right) - \ln{2\pi} \right) = O(n)\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[n\ln n - m\ln m - \left( n - m \right)\ln\left( n - m \right) = - m\ln m + m\ln n + n\ln n - m\ln n - \left( n - m \right)\ln\left( n - m \right) = - m\ln\frac{m}{n} - \left( n - m \right)\ln\frac{n - m}{n} = nH\left( \frac{m}{n} \right)\]</div>
<p>Recall that given a finite sample space <span class="math notranslate nohighlight">\(\Omega\)</span>, if every element
in <span class="math notranslate nohighlight">\(\Omega\)</span> has the same probability to occur w.r.t. some
probability measure <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>, then the entropy of
<span class="math notranslate nohighlight">\(\mathbb{P}\)</span> is simply <span class="math notranslate nohighlight">\(\ln{|\Omega|}\)</span>. As before, let
<span class="math notranslate nohighlight">\(\mathbb{P}\)</span> measures the probability of the edge sets, then the
entropy of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> conditioned on
<span class="math notranslate nohighlight">\(\mathbf{z},\mathbf{E}\)</span>, denoted by
<span class="math notranslate nohighlight">\(\mathbb{H}\left\lbrack \mathbb{P} \middle| \mathbf{z},\mathbf{E} \right\rbrack\)</span>,
is simply <span class="math notranslate nohighlight">\(\ln\mathcal{E}\)</span> since every edge set in
<span class="math notranslate nohighlight">\(\Omega|\mathbf{z},\mathbf{E}\)</span> has the same probability to occur,
i.e.</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbb{H}\left\lb\]</div>
<p>rack mathbb{P} midd
le| mathbf{z},mathb
f{E} rightrbrack =
sum_{i,j in { 1,l
dots,k}}^{}{lnmath
cal{E}_{i,j}} = sum_
{i,j in { 1,ldots,
k}}^{}{lnbegin{pma
trix}</p>
<blockquote>
<div>n_{i,j} \
e_{i,j} \
end{pmatrix}} ap</div></blockquote>
<p>prox sum_{i,j in l
eft{ 1,ldots,k rig
ht}}^{}{n_{i,j}Hlef
t( frac{e_{i,j}}{n_{
i,j}} right)} = sum
_{i,j in left{ 1,ldots,k right}}^{}{
- e_{i,j}lnfrac{e_{
i,j}}{n_{i,j}} - lef
t( n_{i,j} - e_{i,j}
right)lnfrac{n_{i,
j} - e_{i,j}}{n_{i,j}
}} = sum_{i,j in l
eft{ 1,ldots,k rig
ht}}^{}{- e_{i,j}le
ft( ln e_{i,j} - ln</p>
<blockquote>
<div>n_{i,j} right) - l</div></blockquote>
<p>eft( n_{i,j} - e_{i,j
} right)lnleft( <a href="#id87"><span class="problematic" id="id88">n_</span></a>
{i,j} - e_{i,j} righ
t)} + left( n_{i,j}
- e_{i,j} right)ln
n_{i,j} = sum_{i,j in left{ 1,ldots,k</p>
<blockquote>
<div>right}}^{}{- e_{i,</div></blockquote>
<p>j}ln e_{i,j} + e_{i,
j}ln n_{i,j} - left
( n_{i,j} - e_{i,j} right)lnleft( n_{i,
j} - e_{i,j} right)}</p>
<blockquote>
<div><ul class="simple">
<li>n_{i,j}ln n_{i,j}</li>
</ul>
<ul class="simple">
<li>e_{i,j}ln n_{i,j}</li>
</ul>
<p>= sum_{i,j in lef</p>
</div></blockquote>
<p class="last">t{ 1,ldots,k right
}}^{}{- e_{i,j}ln e
_{i,j} + n_{i,j}ln n
_{i,j} - left( n_{i,
j} - e_{i,j} right)lnleft( n_{i,j} - <a href="#id89"><span class="problematic" id="id90">e_</span></a>
{i,j} right)}</p>
</td>
<td>&#160;</td>
<td>(17‑6)</td>
</tr>
</tbody>
</table>
<p>where we <em>assume</em></p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[n_{i,j} \ri\]</div>
<p class="last">ghtarrow infty,e_{i,
j} rightarrow infty
,frac{e_{i,j}}{n_{i,
j}} rightarrow 0,fo
rall i,j in { 1,ld
ots,k}</p>
</td>
<td>&#160;</td>
<td>(17‑7)</td>
</tr>
</tbody>
</table>
<p>This assumption is very important as all approximations discussed here
are based on this. Equation (17‑6) is exactly the log-likelihood of the
standard SBM we derived in (17‑2) except for the sign, and thus
maximizing (17‑2) is approximately equivalent to minimizing
<span class="math notranslate nohighlight">\(\mathbb{H}\left\lbrack \mathbb{P} \middle| \mathbf{z},\mathbf{E} \right\rbrack\)</span>.
Recall Taylor expansion</p>
<div class="math notranslate nohighlight">
\[\ln{(1 - x)} = - \sum_{n = 1}^{\infty}\frac{x^{n}}{n},\forall\left| x \right| &lt; 1 \Rightarrow H\left( x \right) = - x\ln x + \left( 1 - x \right)\sum_{n = 1}^{\infty}\frac{x^{n}}{n} = - x\ln x + \sum_{n = 1}^{\infty}\frac{x^{n}}{n} - \sum_{n = 1}^{\infty}\frac{x^{n + 1}}{n} = - x\ln x + \left( x + \frac{x^{2}}{2} + \frac{x^{3}}{3} + \frac{x^{4}}{4} + \ldots \right) - \left( x^{2} + \frac{x^{3}}{2} + \frac{x^{4}}{3} + \ldots \right) = - x\ln x + x - \sum_{n = 1}^{\infty}\frac{x^{n + 1}}{n(n + 1)}\]</div>
<p>Then since <span class="math notranslate nohighlight">\(0 \leq \frac{e_{i,j}}{n_{i,j}} \leq 1\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[\mathbb{H}\left\lbrack \mathbb{P} \middle| \mathbf{z},\mathbf{E} \right\rbrack = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{n_{i,j}\left( - \frac{e_{i,j}}{n_{i,j}}\ln\frac{e_{i,j}}{n_{i,j}} + \frac{e_{i,j}}{n_{i,j}} - \sum_{n = 1}^{\infty}\frac{\left( \frac{e_{i,j}}{n_{i,j}} \right)^{n + 1}}{n(n + 1)} \right)} = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}\left( - e_{i,j}\ln\frac{e_{i,j}}{n_{i,j}} + e_{i,j} - n_{i,j}\sum_{n = 1}^{\infty}\frac{\left( \frac{e_{i,j}}{n_{i,j}} \right)^{n + 1}}{n\left( n + 1 \right)} \right) = \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}e_{i,j} - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln\frac{e_{i,j}}{n_{i,j}}} - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}\left( \frac{n_{i,j}}{n\left( n + 1 \right)}\sum_{n = 1}^{\infty}\left( \frac{e_{i,j}}{n_{i,j}} \right)^{n + 1} \right) = \left| E \right| - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}{e_{i,j}\ln\frac{e_{i,j}}{n_{i,j}}} - \sum_{i,j \in \left\{ 1,\ldots,k \right\}}^{}\left( \frac{1}{n\left( n + 1 \right)}\sum_{n = 1}^{\infty}\frac{e_{i,j}^{n + 1}}{n_{i,j}^{n}} \right)\]</div>
<p>Observe the terms in the last sum in above expansion is of order
<span class="math notranslate nohighlight">\(O\left( \frac{e_{i,j}^{2}}{n_{i,j}} \right),\forall i,j\)</span> w.r.t.
assumption (17‑7), since the first term of the sum is
<span class="math notranslate nohighlight">\(\frac{1}{n\left( n + 1 \right)}\frac{e_{i,j}^{2}}{n_{i,j}}\)</span>.
Also, it is easy to verify that
<span class="math notranslate nohighlight">\(\frac{\frac{e_{i,j}^{2}}{n_{i,j}}}{e_{i,j}\ln\frac{e_{i,j}}{n_{i,j}}} = \frac{e_{i,j}}{n_{i,j}\ln\frac{e_{i,j}}{n_{i,j}}} = O\left( \frac{e_{i,j}}{n_{i,j}} \right) \rightarrow 0\)</span>,
or intuitively as a graph grows very larger and the average number of
edges between group <span class="math notranslate nohighlight">\(i,j\)</span> becomes very small, the last sum becomes
unimportant in comparison to the previous sum. As a result, w.r.t.
assumption (17‑7), we can write</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><div class="first math notranslate nohighlight">
\[\mathbb{H}\\]</div>
<p>leftlbrack mathbb{P
} middle| mathbf{z}
,mathbf{E} rightrb
rack approx left| E</p>
<blockquote>
<div>right| - sum_{i,j</div></blockquote>
<p class="last">in left{ 1,ldots,
k right}}^{}{e_{i,j
}lnfrac{e_{i,j}}{<a href="#id91"><span class="problematic" id="id92">n_</span></a>
{i,j}}}</p>
</td>
<td>&#160;</td>
<td>(17‑8)</td>
</tr>
</tbody>
</table>
<p>If we remove the constant term <span class="math notranslate nohighlight">\(|E|\)</span> in above formula, it
surprisingly looks exactly like the log-likelihood for the
degree-uncorrected multi-graph SBM we derived in (17‑4). Thus,
optimizing (17‑4) is approximately equivalent to minimizing
<span class="math notranslate nohighlight">\(\mathbb{H}\left\lbrack \mathbb{P} \middle| \mathbf{z},\mathbf{E} \right\rbrack\)</span>.</p>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>Note <span class="math notranslate nohighlight">\(O\left( \frac{e_{i,j}}{n_{i,j}} \right)\)</span> means the
vanishing speed is dependent on how fast
<span class="math notranslate nohighlight">\(\frac{e_{i,j}}{n_{i,j}}\)</span> goes to zero. So if
<span class="math notranslate nohighlight">\(\frac{e_{i,j}}{n_{i,j}} \rightarrow 0\)</span> is slow, we might need
to consider keeps some leading terms in the last summation.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="section" id="neural-networks">
<h1>Neural Networks<a class="headerlink" href="#neural-networks" title="Permalink to this headline">¶</a></h1>
<div class="section" id="preliminaries-1">
<span id="id59"></span><h2><strong>Preliminaries</strong><a class="headerlink" href="#preliminaries-1" title="Permalink to this headline">¶</a></h2>
<div class="section" id="feed-forward-network">
<h3>Feed-forward Network<a class="headerlink" href="#feed-forward-network" title="Permalink to this headline">¶</a></h3>
<div class="section" id="feed-forward-network-1">
<span id="id60"></span><h4><strong>Feed-forward Network</strong><a class="headerlink" href="#feed-forward-network-1" title="Permalink to this headline">¶</a></h4>
<p>Like many classic statistical or machine learning models, a neural
network is a model with parameters <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> trained over
labelled data <span class="math notranslate nohighlight">\(\left( \mathbf{X},\mathbf{y} \right)\)</span> and gives
regression <span class="math notranslate nohighlight">\(\widehat{\mathbf{y}}\)</span>. For each new data
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span> with unknown label, the model gives a prediction
<span class="math notranslate nohighlight">\(\widehat{y}\)</span>. One can refer to introduction of
<a class="reference external" href="#linear-regression">regression</a> and
<a class="reference external" href="#linear-discriminant-analysis">classification</a> for details. We
denote a general neural network as
<span class="math notranslate nohighlight">\(\mathcal{n}\left( \mathbf{x};\mathbf{w} \right)\)</span>. A neural
network is intended to approximate complicated problems</p>
<p>The most basic type of neural network is named <strong>feed-forward network</strong>
(FFN), whose mathematically nature is straightforward – a multiple
composition of various chosen linear and non-linear functions. The chart
of FFN reflects this nature; a simple illustration is given in . We use
superscript like “<span class="math notranslate nohighlight">\(\left( \cdot \right)^{\left( i \right)}\)</span>”
to indicate a parameter is used for the <span class="math notranslate nohighlight">\(i\)</span>th layer. The network
represents two-layer composition of linear functions, where the first
layer is a <span class="math notranslate nohighlight">\(\mathbb{R}^{2} \rightarrow \mathbb{R}^{4}\)</span> function
<span class="math notranslate nohighlight">\(\mathcal{L}^{\left( 1 \right)}\left( \mathbf{x} \right) = \left( \left( \mathbf{w}_{1}^{\left( 1 \right)} \right)^{T}\mathbf{x,}\left( \mathbf{w}_{2}^{\left( 1 \right)} \right)^{T}\mathbf{x,}\left( \mathbf{w}_{3}^{\left( 1 \right)} \right)^{T}\mathbf{x,}\left( \mathbf{w}_{4}^{\left( 1 \right)} \right)^{T}\mathbf{x} \right)^{T}\)</span>,
and the second layer is a <span class="math notranslate nohighlight">\(\mathbb{R}^{4}\mathbb{\rightarrow R}\)</span>
function
<span class="math notranslate nohighlight">\(\mathcal{L}^{\left( 2 \right)}\left( \mathbf{x} \right) = \mathbf{w}^{\left( 2 \right)}\mathbf{x}\)</span>.
The network is itself a linear function because composition of linear
functions is linear; therefore, it can used for the purpose of linear
regression.</p>
<table border="1" class="docutils">
<colgroup>
<col width="85%" />
<col width="15%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><a class="reference internal" href="media/image35.png"><img alt="image26" src="media/image35.png" style="width: 3.67755in; height: 2.14653in;" /></a></th>
<th class="head">&#160;</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>&#160;</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<p>The general concept of <strong>back-propagation</strong> is simply running an
iterative optimization process on a chosen loss function to adjust model
parameters, so the model can gradually yield better performance (better
prediction, regression, etc.). Typically, this can be done by gradient
descent. Recall a gradient descent has the general form</p>
<div class="math notranslate nohighlight">
\[\mathbf{w}^{\left( k + 1 \right)} = \mathbf{w}^{\left( k \right)} - \alpha_{k}\mathbf{D}_{k}\nabla_{\mathbf{w}}\mathcal{n}\]</div>
<p>calculating the partial derivative of the loss function w.r.t. each
individual parameter and do gradient descent.</p>
<p>This is the same as what we did for many classic models. In practice,
one typically way for ba</p>
<p>simply taking derivatives against each parameter and</p>
<p>Suppose we have designed a network
<span class="math notranslate nohighlight">\(\mathcal{n}\left( \mathbf{x},\mathbf{w} \right)\)</span></p>
</div>
<div class="section" id="tensorflow-basics">
<h4><strong>Tensorflow Basics</strong><a class="headerlink" href="#tensorflow-basics" title="Permalink to this headline">¶</a></h4>
<p>Network construction requires input definitions. Tensorflow uses
<strong>tf.placeholder</strong> to declare input variables before a session is run.
The placeholders are not real input data, but symbols for the data to
input.</p>
<table border="1" class="docutils">
<colgroup>
<col width="100%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><p class="first">tf.placeholder(dtype, #defines the type of values in the tensor</p>
<p>shape=None, #a tuple to indicate sizes of each dimension</p>
<p class="last">name=None) #a string reference to the ph, so the ph can be retrieved
by this name later</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="section" id="text-learning">
<h2><strong>Text Learning</strong><a class="headerlink" href="#text-learning" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="graph-learning">
<h2><strong>Graph Learning</strong><a class="headerlink" href="#graph-learning" title="Permalink to this headline">¶</a></h2>
<p>Again, we review some basic notions for a graph. Given a set
<span class="math notranslate nohighlight">\(V = \left\{ v_{1},\ldots,v_{n} \right\}\)</span>, define another set of
tuples <span class="math notranslate nohighlight">\(E = \left\{ \left( u,v \right):u,v \in V \right\}\)</span>, then
the tuple of sets <span class="math notranslate nohighlight">\(\left( V,E \right)\)</span> is named a <strong>graph</strong>,
<span class="math notranslate nohighlight">\(V\)</span> is named the <strong>vertex set</strong>, and <span class="math notranslate nohighlight">\(E\)</span> is named the <strong>edge
set</strong>. For convenience, let <span class="math notranslate nohighlight">\(n = \left| V \right|\)</span> be the size of
vertex set, <span class="math notranslate nohighlight">\(m = \left| E \right|\)</span> be the size of edge set. A
graph can be represented by a <span class="math notranslate nohighlight">\(n \times n\)</span> <strong>adjacency matrix</strong>
<span class="math notranslate nohighlight">\(\mathbf{A}\)</span> s.t.
<span class="math notranslate nohighlight">\(\mathbf{A}\left( i,j \right) = \left\{ \begin{matrix}
1 &amp; \left( v_{i},v_{j} \right) \in E \\
0 &amp; \left( v_{i},v_{j} \right) \notin E \\
\end{matrix} \right.\ \)</span>. A weighted graph</p>
<div class="section" id="graph-convolutional-network">
<h3><strong>Graph Convolutional Network</strong><a class="headerlink" href="#graph-convolutional-network" title="Permalink to this headline">¶</a></h3>
<p>It is not appropriate to consider an infrequent subgraph as an anomaly,
because larger subgraphs are infrequent.</p>
<p>autoencoder: find representation, reduce dimension</p>
<p>reduce is better than fold for long sequence</p>
<p>graph convolution, share parameter</p>


<div class="section" id="computer-vision">
<h2><strong>Computer Vision</strong><a class="headerlink" href="#computer-vision" title="Permalink to this headline">¶</a></h2>

<div class="section" id="anomaly-learning">
<h2><strong>Anomaly Learning</strong><a class="headerlink" href="#anomaly-learning" title="Permalink to this headline">¶</a></h2>




           
           
          
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, tony_chen.

    </p>
  
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        
      

    </section>

  
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.0.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>